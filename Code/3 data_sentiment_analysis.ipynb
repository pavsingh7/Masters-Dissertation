{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "# <a id='toc5_'></a>[Sentiment Analysis](#toc0_)\n",
    "\n",
    "We perform sentiment analysis on the reviewText column. We conduct one types of sentiment analysis: \n",
    "\n",
    "1. Sentiment Analysis using Lexicon-based Methods\n",
    "\n",
    "\n",
    "We apply this sentiment analysis for each set of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the working directory\n",
    "%reset -f\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from csv file\n",
    "# amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set1_data_cleaned.csv')\n",
    "\n",
    "# # load data - Set 1\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set1_data_cleaned.csv')\n",
    "\n",
    "# # load data - Set 2\n",
    "# amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data_cleaned.csv')\n",
    "\n",
    "# # load data - Set 3\n",
    "# amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set3_data_cleaned.csv')\n",
    "\n",
    "# load data - Set 4\n",
    "# amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set4_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data view\n",
    "display(amz_data.head(3))\n",
    "print(\"Shape of the data: \", amz_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data summary\n",
    "print(\"Shape of data =>\", amz_data.shape)\n",
    "print(\"Number of unique products =>\", amz_data['asin'].nunique())\n",
    "print(\"Number of unique users =>\", amz_data['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Change to list of words for: filtered_tokens_revText\n",
    "amz_data['filtered_tokens_revText'] = amz_data['filtered_tokens_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: stemmed_words_revText\n",
    "amz_data['stemmed_words_revText'] = amz_data['stemmed_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: lemmatized_words_revText\n",
    "amz_data['lemmatized_words_revText'] = amz_data['lemmatized_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# view data\n",
    "amz_data.head(4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc5_1_'></a>[Sentiment Analysis using Lexicon-based Methods](#toc0_)\n",
    "\n",
    "First we use lexicon-based methods to perform sentiment analysis. Lexicon-based methods use a lexicon, or a collection of words and phrases associated with emotions, to assign sentiment scores to a body of text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[VADER](#toc0_)\n",
    "\n",
    "We use the VADER (Valence Aware Dictionary and Sentiment Reasoner) lexicon to perform sentiment analysis on the reviewText column. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "VADER utilizes a sentiment lexicon containing words with sentiment scores. However, VADER goes beyond simply assigning positive or negative labels to words. It considers the intensity of sentiment and incorporates linguistic rules to handle negations, intensifiers, and other linguistic features. This makes VADER particularly suitable for analyzing sentiment in social media text, where linguistic nuances and context play a significant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# instance of the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through tokenized reviews and analyze the sentiment for each one\n",
    "sentiments_vader_revText = []\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):  # Check if the review is a string\n",
    "        sentiment = sia.polarity_scores(review)\n",
    "    else:\n",
    "        sentiment = sia.polarity_scores('')  # Replace NaN with an empty string\n",
    "    sentiments_vader_revText.append(sentiment)\n",
    "\n",
    "# store the sentiment scores in the dataframe\n",
    "amz_data['sentiments_vader_revText'] = sentiments_vader_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see some results\n",
    "amz_data.sentiments_vader_revText.head(4).values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy array containing sentiment analysis results. Each element in the array represents the sentiment scores for a single review. These sentiment scores are generated by VADER (Valence Aware Dictionary and sEntiment Reasoner), which is a popular rule-based model used for sentiment analysis. The scores are typically between -1 and 1, where values closer to 1 indicate more positive sentiment, values closer to -1 indicate more negative sentiment, and values around 0 indicate neutral sentiment. The compound score represents an overall sentiment intensity, combining the individual sentiment scores. The compound score in VADER sentiment analysis typically varies between -1 and 1. A compound score of 1 indicates extremely positive sentiment, while a score of -1 indicates extremely negative sentiment. Scores close to 0 represent more neutral or balanced sentiment.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dataframe\n",
    "amz_data[['reviewerID', 'asin', 'reviewText', 'overall', 'sentiments_vader_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_2_'></a>[TextBlob](#toc0_)\n",
    "\n",
    "We also use the TextBlob library to perform sentiment analysis on the reviewText column. TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob is built on top of NLTK and Pattern and provides an easy-to-use interface to the NLTK library. We use the sentiment analysis functionality of TextBlob to calculate the polarity and subjectivity scores for each review in the reviewText column. \n",
    "\n",
    "TextBlob's sentiment analysis algorithm is based on a pre-trained model that has been trained on a large dataset. The model uses a combination of linguistic rules, pattern matching, and machine learning techniques like Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiments_textblob_revText = []\n",
    "subjectivities_textblob_revText = []\n",
    "\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):\n",
    "        blob = TextBlob(review)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "    else:\n",
    "        blob = TextBlob('')\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    sentiments_textblob_revText.append(sentiment)\n",
    "    subjectivities_textblob_revText.append(subjectivity)\n",
    "\n",
    "amz_data['sentiments_textblob_revText'] = sentiments_textblob_revText\n",
    "amz_data['subjectivities_textblob_revText'] = subjectivities_textblob_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see some results - sentiment\n",
    "print(amz_data.sentiments_textblob_revText.head(4).values)\n",
    "\n",
    "# see some results - subjectivity\n",
    "print(amz_data.subjectivities_textblob_revText.head(4).values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob's sentiment analysis is based on a machine learning algorithm trained on a large dataset of labeled data. The algorithm learns patterns and linguistic features from the data to classify text into different sentiment categories, such as positive, negative, or neutral.\n",
    "\n",
    "**Polarity**: It indicates the sentiment of the text on a scale from -1 to 1. A polarity score close to -1 indicates negative sentiment, a score close to 1 indicates positive sentiment, and a score around 0 indicates neutral sentiment.\n",
    "\n",
    "**Subjectivity**: It measures the subjectivity of the text on a scale from 0 to 1. A subjectivity score of 0 means the text is objective and factual, while a score of 1 means the text is highly subjective and opinionated.\n",
    "\n",
    "**TextBlob uses a trained model to analyze the sentiment of the input text based on the learned patterns and features. It takes into account not only individual words but also the context and grammar of the text.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc5_1_3_'></a>[Bing, AFINN, and NRC](#toc0_)\n",
    "\n",
    "The BING lexicon, for example, classifies words as either positive or negative. bing assigns a numerical sentiment score to words, where a positive score indicates positive sentiment and a negative score indicates negative sentiment. NRC extends this approach by providing a more comprehensive list of words and associating them with multiple sentiment dimensions, such as anger, joy, fear, etc.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lexicons in\n",
    "afinn = pd.read_csv('/Users/pavansingh/Desktop/Afinn.csv')\n",
    "\n",
    "# AFINN\n",
    "print(\"Shape of AFINN:\", afinn.shape)\n",
    "print(\"Unique Sentiments:\", afinn.value.unique())\n",
    "display(afinn.head(3))\n",
    "afinn_dict = dict(zip(afinn['word'], afinn['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each review using AFINN\n",
    "sentiment_scores_afinn = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(afinn_dict.get(word, 0) for word in review_tokens)\n",
    "    sentiment_scores_afinn.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_afinn_revText'] = sentiment_scores_afinn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID', 'reviewText', 'overall', 'sentiment_score_afinn_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "bing = pd.read_csv('/Users/pavansingh/Desktop/Bing.csv')\n",
    "\n",
    "# BING\n",
    "print(\"Shape of Bing:\", bing.shape)\n",
    "print(\"Unique Sentiments:\", bing.sentiment.unique())\n",
    "display(bing.head(3))\n",
    "bing_dict = dict(zip(bing['word'], bing['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each review using bing\n",
    "sentiment_scores_bing_revText = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(-1 if bing_dict.get(word, '') == 'negative' else 1 if bing_dict.get(word, '') == 'positive' else 0 for word in review_tokens)\n",
    "    sentiment_scores_bing_revText.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_bing_revText'] = sentiment_scores_bing_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID', 'reviewText', 'overall','sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "nrc = pd.read_csv('/Users/pavansingh/Desktop/NRC.csv')\n",
    "\n",
    "# NRC\n",
    "print(\"Shape of NRC:\", nrc.shape)\n",
    "print(\"Unique Sentiments:\", nrc.sentiment.unique())\n",
    "display(nrc.head(3))\n",
    "nrc_dict = dict(zip(nrc['word'], nrc['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sentiments = ['trust', 'fear', 'negative', 'sadness', 'anger', 'surprise', 'positive', 'disgust', 'joy', 'anticipation']\n",
    "\n",
    "# Get the sentiment score for each review using NRC\n",
    "sentiment_scores_nrc_revText = []\n",
    "\n",
    "# Calculate sentiment score and overall sentiment for each review using NRC lexicon\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    review_sentiment_scores = {sentiment: 0 for sentiment in unique_sentiments}\n",
    "    for word in review_tokens:\n",
    "        word_sentiments = nrc_dict.get(word, [])\n",
    "        for sentiment in unique_sentiments:\n",
    "            if sentiment in word_sentiments:\n",
    "                review_sentiment_scores[sentiment] += 1\n",
    "\n",
    "    overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "    sentiment_scores_nrc_revText.append(overall_sentiment)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_nrc_revText'] = sentiment_scores_nrc_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_data[['reviewerID', 'reviewText', 'overall', 'sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Data Frame with BING, AFINN and NRC Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data \n",
    "amz_data[['reviewerName',  'reviewText','overall', 'sentiment_score_afinn_revText',\n",
    "        'sentiment_score_bing_revText',  'sentiment_score_nrc_revText']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data as csv - data set 1\n",
    "amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set1_data_sentiment.csv\", index=False)\n",
    "\n",
    "# # save data as csv - data set 2\n",
    "# amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data_sentiment.csv\", index=False)\n",
    "\n",
    "# # save data as csv - data set 3\n",
    "# amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set3_data_sentiment.csv\", index=False)\n",
    "\n",
    "# save data as csv - data set 4\n",
    "# amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set4_data_sentiment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
