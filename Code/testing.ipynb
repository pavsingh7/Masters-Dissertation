{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/7wlh6jzj03185p7x7ggqb_280000gn/T/ipykernel_33175/2736403722.py:2: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/Users/pavansingh/Desktop/all_revs_1.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 17, 2016</td>\n",
       "      <td>A34SO74JEYQXZW</td>\n",
       "      <td>B0012Y0ZG2</td>\n",
       "      <td>{'Size:': ' 39'}</td>\n",
       "      <td>Jose</td>\n",
       "      <td>Sally's stop selling this great shampoo for fu...</td>\n",
       "      <td>Fuller Hair</td>\n",
       "      <td>1458172800</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 13, 2014</td>\n",
       "      <td>A2TZW7B0YG2ZJQ</td>\n",
       "      <td>B0009RF9DW</td>\n",
       "      <td>{'Size:': ' 258'}</td>\n",
       "      <td>flavio sanchez</td>\n",
       "      <td>i am ok with this adidas hair and body 3 activ...</td>\n",
       "      <td>i love it</td>\n",
       "      <td>1394668800</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 26, 2013</td>\n",
       "      <td>A4DEEDXZK8L78</td>\n",
       "      <td>B000URXP6E</td>\n",
       "      <td>{'Size:': ' 205'}</td>\n",
       "      <td>Gloria Karimi</td>\n",
       "      <td>This is a beautiful scented lotion.  Very mois...</td>\n",
       "      <td>Beautiful Scent</td>\n",
       "      <td>1382745600</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 15, 2017</td>\n",
       "      <td>A1X15KWJ11IC1P</td>\n",
       "      <td>B0012Y0ZG2</td>\n",
       "      <td>{'Size:': ' 144'}</td>\n",
       "      <td>Mert Ozer</td>\n",
       "      <td>Lovely product and works great, except the art...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1513296000</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 7, 2014</td>\n",
       "      <td>A3RGQCA2GSFLX2</td>\n",
       "      <td>B000URXP6E</td>\n",
       "      <td>{'Size:': ' 169'}</td>\n",
       "      <td>self</td>\n",
       "      <td>hard to find a lab coat the fits nice.  this o...</td>\n",
       "      <td>Love the fit of the lab coat......</td>\n",
       "      <td>1391731200</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171241</th>\n",
       "      <td>9031018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 1, 2016</td>\n",
       "      <td>A28CR7BR4LGT0W</td>\n",
       "      <td>B0006Z7NN6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kraal</td>\n",
       "      <td>Like product as we have been using braggs  ami...</td>\n",
       "      <td>Like product as we have been using braggs amin...</td>\n",
       "      <td>1475280000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171242</th>\n",
       "      <td>9031019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 9, 2015</td>\n",
       "      <td>A2MNB77YGJ3CN0</td>\n",
       "      <td>B000GW241K</td>\n",
       "      <td>{'Size:': ' 2.6 Ounce ( Pack of 4)', 'Flavor:'...</td>\n",
       "      <td>L. Mountford</td>\n",
       "      <td>I've been a fan of Jack Link's products for a ...</td>\n",
       "      <td>Tasty hit of protein, but a bit salty</td>\n",
       "      <td>1444348800</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171243</th>\n",
       "      <td>9031020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>03 20, 2016</td>\n",
       "      <td>A22RZG1NQ0WAUX</td>\n",
       "      <td>B01AK44MOK</td>\n",
       "      <td>{'Size:': ' 6 Pouches', 'Flavor:': ' Sweet Pot...</td>\n",
       "      <td>K. L. Burchett</td>\n",
       "      <td>Tasty. Almost as thick as sweet potato fluff. ...</td>\n",
       "      <td>Tasty</td>\n",
       "      <td>1458432000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171244</th>\n",
       "      <td>9031021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 5, 2015</td>\n",
       "      <td>A14NSDI5HZX9G5</td>\n",
       "      <td>B00FFFTIP8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ret.Pet Pro</td>\n",
       "      <td>Not what I was looking to receive. I was tryin...</td>\n",
       "      <td>Great Northern Popcorn 5 Pounds Bulk GNP...</td>\n",
       "      <td>1420416000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171245</th>\n",
       "      <td>9031022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2014</td>\n",
       "      <td>A3K0OWGS5G12L4</td>\n",
       "      <td>B000FL08B0</td>\n",
       "      <td>{'Size:': ' 11.75-Ounce, 6-Count'}</td>\n",
       "      <td>C.B. Lee</td>\n",
       "      <td>What's there to say..?  Damn good!</td>\n",
       "      <td>Damn good!</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9171246 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  overall  verified   reviewTime      reviewerID  \\\n",
       "0                 0      5.0      True  03 17, 2016  A34SO74JEYQXZW   \n",
       "1                 1      5.0      True  03 13, 2014  A2TZW7B0YG2ZJQ   \n",
       "2                 2      5.0      True  10 26, 2013   A4DEEDXZK8L78   \n",
       "3                 3      5.0      True  12 15, 2017  A1X15KWJ11IC1P   \n",
       "4                 4      5.0      True   02 7, 2014  A3RGQCA2GSFLX2   \n",
       "...             ...      ...       ...          ...             ...   \n",
       "9171241     9031018      5.0     False   10 1, 2016  A28CR7BR4LGT0W   \n",
       "9171242     9031019      4.0     False   10 9, 2015  A2MNB77YGJ3CN0   \n",
       "9171243     9031020      5.0     False  03 20, 2016  A22RZG1NQ0WAUX   \n",
       "9171244     9031021      3.0      True   01 5, 2015  A14NSDI5HZX9G5   \n",
       "9171245     9031022      5.0      True  12 16, 2014  A3K0OWGS5G12L4   \n",
       "\n",
       "               asin                                              style  \\\n",
       "0        B0012Y0ZG2                                   {'Size:': ' 39'}   \n",
       "1        B0009RF9DW                                  {'Size:': ' 258'}   \n",
       "2        B000URXP6E                                  {'Size:': ' 205'}   \n",
       "3        B0012Y0ZG2                                  {'Size:': ' 144'}   \n",
       "4        B000URXP6E                                  {'Size:': ' 169'}   \n",
       "...             ...                                                ...   \n",
       "9171241  B0006Z7NN6                                                NaN   \n",
       "9171242  B000GW241K  {'Size:': ' 2.6 Ounce ( Pack of 4)', 'Flavor:'...   \n",
       "9171243  B01AK44MOK  {'Size:': ' 6 Pouches', 'Flavor:': ' Sweet Pot...   \n",
       "9171244  B00FFFTIP8                                                NaN   \n",
       "9171245  B000FL08B0                 {'Size:': ' 11.75-Ounce, 6-Count'}   \n",
       "\n",
       "           reviewerName                                         reviewText  \\\n",
       "0                  Jose  Sally's stop selling this great shampoo for fu...   \n",
       "1        flavio sanchez  i am ok with this adidas hair and body 3 activ...   \n",
       "2         Gloria Karimi  This is a beautiful scented lotion.  Very mois...   \n",
       "3             Mert Ozer  Lovely product and works great, except the art...   \n",
       "4                  self  hard to find a lab coat the fits nice.  this o...   \n",
       "...                 ...                                                ...   \n",
       "9171241           Kraal  Like product as we have been using braggs  ami...   \n",
       "9171242    L. Mountford  I've been a fan of Jack Link's products for a ...   \n",
       "9171243  K. L. Burchett  Tasty. Almost as thick as sweet potato fluff. ...   \n",
       "9171244     ret.Pet Pro  Not what I was looking to receive. I was tryin...   \n",
       "9171245        C.B. Lee                 What's there to say..?  Damn good!   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "0                                              Fuller Hair      1458172800   \n",
       "1                                                i love it      1394668800   \n",
       "2                                          Beautiful Scent      1382745600   \n",
       "3                                               Five Stars      1513296000   \n",
       "4                       Love the fit of the lab coat......      1391731200   \n",
       "...                                                    ...             ...   \n",
       "9171241  Like product as we have been using braggs amin...      1475280000   \n",
       "9171242              Tasty hit of protein, but a bit salty      1444348800   \n",
       "9171243                                              Tasty      1458432000   \n",
       "9171244        Great Northern Popcorn 5 Pounds Bulk GNP...      1420416000   \n",
       "9171245                                         Damn good!      1418688000   \n",
       "\n",
       "                         category vote image  \n",
       "0                          beauty  NaN   NaN  \n",
       "1                          beauty  NaN   NaN  \n",
       "2                          beauty  NaN   NaN  \n",
       "3                          beauty  NaN   NaN  \n",
       "4                          beauty  NaN   NaN  \n",
       "...                           ...  ...   ...  \n",
       "9171241  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171242  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171243  grocery_and_gourmet_food  8.0   NaN  \n",
       "9171244  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171245  grocery_and_gourmet_food  NaN   NaN  \n",
       "\n",
       "[9171246 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('/Users/pavansingh/Desktop/all_revs_1.csv')\n",
    "data.shape\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If We Wanted to Binarise the Results\n",
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)\n",
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If predicted rating is greater than or equal to 3.5, then 1, else 0\n",
      "\n",
      "Predicted Ratings: [5.   4.03 4.4  4.4  5.   5.   4.35 4.35 4.59 4.59 5.   5.   4.83 4.83\n",
      " 4.5  5.   3.79 3.79 3.9  3.9  4.89 4.89 4.26 4.26 4.03 4.03 4.37 4.37\n",
      " 4.26 4.26 4.95 4.95 4.52 4.52 5.   5.   4.45 4.45 4.9  4.9  4.91 4.91\n",
      " 4.53 4.53 4.72 4.72 4.3  4.3  4.85 4.85 3.89 3.89 4.17 4.17 4.15 4.15\n",
      " 4.   4.   4.42 4.42 2.94 2.94 3.7  3.7  4.5  4.5  4.21 4.21 4.76 4.76\n",
      " 4.28 4.28 4.07 4.07 4.05 4.05 4.59 4.59 3.95 3.95 4.66 4.66 4.17 4.17\n",
      " 4.   4.   4.68 4.68 4.61 4.61 4.52 4.52 3.72 3.72 4.81 4.81 4.28 4.28\n",
      " 4.24 4.24 4.11 4.11 4.07 4.07 4.71 4.71 4.55 4.55 4.8  4.8  4.87 4.87\n",
      " 4.89 4.89 4.5  4.5  4.4  4.4  4.16 4.16 4.72 4.72 4.38 4.38 4.67 4.67\n",
      " 4.37 4.37 4.   3.85 5.   5.   4.37 4.37 4.18 4.18 4.42 4.42 3.72 3.72\n",
      " 4.59 4.59 4.92 4.92 4.15 4.15 4.83 4.83 4.63 4.63 4.39 4.39 4.06 4.06\n",
      " 4.62 4.62 4.41 4.41 4.52 4.52 4.56 4.56 4.83 4.83 4.12 4.12 3.8  3.8\n",
      " 3.89 3.89 4.12 4.12 4.44 4.44 4.39 4.39 4.22 4.22 4.21 4.21 4.46 4.46\n",
      " 4.6  4.6  4.57 4.57 4.81 5.   4.59 4.   4.7  4.7  4.48 4.48 4.75 4.75\n",
      " 4.95 4.95 5.   5.   4.17 4.17 4.63 4.63 3.33 3.33 4.93 4.93 4.41 4.41\n",
      " 4.07 4.07 3.27 3.27 4.53 4.53 3.42 3.42 3.78 3.78 4.58 4.58 4.6  4.6\n",
      " 4.73 4.73 3.94 3.94 3.   3.   4.68 4.68 4.32 4.32 4.21 4.21 4.44 4.44\n",
      " 4.17 4.17 4.04 4.04 3.94 3.94 4.54 4.54 3.85 3.85 3.79 3.79 4.56 4.56\n",
      " 3.73 3.73 4.16 4.16 3.99 3.99 3.71 3.71 4.38 4.38 4.57 4.57 4.38 4.38\n",
      " 4.4  4.4  4.71 4.71 4.41 4.41 3.46 3.46 4.28 4.28 4.62 4.62 4.58 4.58\n",
      " 4.7  4.7  4.27 5.   3.44 3.44 4.71 4.71 4.33 4.33 4.14 4.14 4.53 4.53\n",
      " 4.   4.   4.25 4.25 4.56 4.56 3.11 3.11 4.28 4.28 2.81 2.81 4.45 4.45\n",
      " 3.9  3.9  4.47 4.47 4.74 4.74 4.9  4.9  4.   4.   4.2  4.2  4.83 5.\n",
      " 4.68 4.68 4.1  4.1  4.35 4.35 3.74 3.74 4.18 4.18 5.   5.   4.35 4.35\n",
      " 4.77 4.77 4.7  4.7  3.85 3.85 4.52 4.52 3.75 3.75 4.13 4.13 4.6  4.6\n",
      " 4.59 4.59 4.57 5.   4.15 4.15 3.9  3.9  4.96 4.96 4.27 4.27 4.89 4.89\n",
      " 4.14 5.   4.16 4.16 4.75 4.75 3.9  3.9  4.5  4.5  5.   5.   4.67 4.67\n",
      " 3.64 3.64 4.   4.   3.55 3.55 4.55 4.55 4.84 4.84 4.43 4.43 4.59 4.59\n",
      " 4.65 4.65 1.57 1.57 4.32 4.32 4.12 4.12 4.05 4.05 5.   5.   4.19 4.19\n",
      " 3.77 3.77 4.36 4.36 4.67 4.67 4.32 4.32 5.   5.   4.1  4.1  4.11 4.11\n",
      " 4.07 4.07 4.56 4.56 4.42 4.42 4.72 4.72 4.69 4.69 4.8  4.8  4.95 4.95\n",
      " 4.52 4.52 5.   5.   4.05 4.05 4.   4.   4.94 4.94 4.52 4.52 3.26 3.26\n",
      " 3.95 3.95 4.83 4.83 4.36 4.36 4.7  4.7  4.06 4.06 3.3  3.3  3.77 3.77\n",
      " 5.   5.   4.   4.   4.44 4.44 4.   4.   4.45 4.45 4.39 4.39 4.32 4.32\n",
      " 4.17 5.   3.65 3.65 4.73 4.73 4.39 4.39 4.49 4.49 3.79 3.79 2.64 3.3\n",
      " 4.79 4.79 4.58 4.58 4.39 4.39 4.32 4.32 4.5  4.5  3.86 3.86 4.67 4.67\n",
      " 4.58 4.58 3.79 3.79 4.24 4.24 4.75 4.75 3.92 3.92 4.45 4.45 4.24 4.24\n",
      " 4.24 4.24 4.55 4.55 4.58 4.58 4.   4.   4.94 4.94 4.27 4.27 4.17 4.17\n",
      " 4.34 4.34 5.   5.   4.87 4.87 4.63 4.63 3.84 3.84 4.72 4.72 4.52 4.52\n",
      " 4.67 4.67 4.95 4.95 4.66 4.66 4.48 5.   4.94 4.94 3.14 3.14 5.   5.\n",
      " 4.97 4.97 4.52 4.52 4.28 4.28 3.79 3.79 4.11 4.11 4.3  4.3  3.65 3.65\n",
      " 3.96 3.96 3.27 3.27 5.   5.   4.75 4.75 4.55 4.55 4.58 4.58 4.75 4.75\n",
      " 4.1  4.1  4.19 4.19 4.39 4.39 4.92 4.92 4.61 4.61 4.04 4.04 4.83 4.83\n",
      " 3.71 3.71 4.48 4.48 4.41 4.41 4.05 4.05 4.7  4.7  4.37 4.37 4.73 4.73\n",
      " 4.87 4.87 5.   5.   4.25 4.25 4.04 4.04 4.17 4.17 4.11 4.11 4.33 4.33\n",
      " 4.   4.   3.52 3.52 4.74 4.74 4.83 4.83 3.23 3.23 4.45 4.45 4.33 4.33\n",
      " 4.19 4.19 4.07 4.07 3.65 3.65 4.18 4.18 4.52 4.52 4.9  4.9  4.06 4.06\n",
      " 3.16 3.16 4.89 4.89 4.42 4.42 4.2  4.2  3.84 3.84 4.21 4.21 4.93 4.93\n",
      " 4.12 4.12 3.   3.   3.78 3.78 4.55 4.55 4.78 4.78 4.22 4.22 4.34 4.34\n",
      " 4.9  4.9  4.23 4.23 4.38 4.38 4.54 4.54 4.67 4.67 4.25 4.25 3.63 3.63\n",
      " 4.26 4.26 4.47 4.47 4.46 4.46 3.82 3.82 5.   5.   5.   5.   3.63 3.63\n",
      " 3.76 3.76 4.28 4.28 4.31 4.31 4.19 4.19 4.79 4.79 4.29 4.29 4.95 4.95\n",
      " 4.69 4.69 4.53 4.53 3.68 3.68 4.42 4.42 4.08 4.08 3.09 3.09 4.   4.\n",
      " 3.85 3.85 4.21 4.21 4.41 4.41 3.78 3.78 3.95 3.95 4.18 4.18 4.39 4.39\n",
      " 4.11 4.11 5.   5.   3.72 3.72 4.47 4.47 4.3  4.3  5.   5.   4.81 4.81\n",
      " 4.65 4.65 4.17 4.17 3.15 3.15 4.12 4.12 4.44 4.44 4.64 4.64 4.59 4.59\n",
      " 4.58 4.58 4.76 4.76 4.25 4.25 4.86 4.86 4.4  4.4  4.09 4.09 4.4  4.4\n",
      " 4.55 4.55 4.52 4.52]\n",
      "Binary Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "Hidden Ratings: [3. 5. 4. 4. 5. 5. 5. 5. 4. 5. 5. 5. 5. 5. 4. 5. 5. 4. 4. 3. 4. 5. 3. 3.\n",
      " 4. 4. 3. 5. 5. 5. 3. 5. 4. 4. 5. 5. 5. 5. 5. 5. 5. 4. 5. 4. 5. 4. 5. 5.\n",
      " 5. 5. 4. 3. 4. 4. 5. 4. 4. 4. 5. 5. 4. 3. 5. 3. 5. 5. 5. 4. 5. 5. 5. 5.\n",
      " 5. 4. 1. 3. 5. 3. 3. 5. 2. 4. 5. 4. 5. 5. 5. 5. 5. 5. 4. 5. 4. 4. 5. 5.\n",
      " 4. 5. 5. 4. 4. 3. 5. 4. 2. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 4. 2. 4. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 4. 4. 5. 5. 3. 4. 3. 5. 5. 5.\n",
      " 4. 5. 3. 3. 4. 5. 5. 5. 4. 4. 4. 5. 4. 5. 4. 5. 5. 1. 5. 5. 5. 2. 3. 4.\n",
      " 4. 4. 4. 4. 5. 4. 4. 5. 4. 4. 4. 5. 3. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 4. 5. 5. 5. 4. 1. 5. 5. 3. 5. 5. 5. 5. 3. 5. 5. 5. 5. 4. 3. 3. 2. 5. 4.\n",
      " 2. 1. 3. 5. 4. 5. 5. 5. 5. 5. 4. 5. 2. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4.\n",
      " 5. 4. 5. 4. 5. 5. 5. 4. 4. 4. 1. 5. 5. 4. 5. 5. 4. 5. 3. 2. 5. 5. 5. 5.\n",
      " 4. 5. 2. 5. 5. 4. 3. 3. 4. 4. 3. 5. 5. 5. 5. 3. 5. 5. 3. 5. 3. 5. 4. 4.\n",
      " 4. 4. 4. 4. 4. 5. 5. 4. 4. 4. 5. 5. 3. 3. 5. 5. 3. 4. 4. 5. 3. 5. 3. 5.\n",
      " 4. 5. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 5. 3. 4. 4. 4. 5. 5. 4. 5. 5. 5. 4.\n",
      " 5. 5. 5. 5. 1. 4. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4. 5. 5. 1. 5. 5. 5.\n",
      " 5. 5. 5. 4. 3. 4. 4. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4. 4. 5. 3. 1. 5.\n",
      " 5. 5. 5. 5. 4. 4. 5. 4. 5. 5. 3. 2. 5. 4. 2. 5. 4. 4. 5. 5. 5. 4. 5. 5.\n",
      " 5. 5. 5. 5. 4. 4. 5. 5. 5. 5. 5. 4. 5. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 4. 4. 2. 5. 5. 5. 5. 4. 3. 3. 5. 5. 5. 3. 5. 5. 5. 5.\n",
      " 5. 3. 2. 3. 2. 2. 5. 5. 1. 5. 5. 5. 4. 1. 5. 5. 5. 5. 4. 4. 4. 4. 4. 3.\n",
      " 5. 5. 5. 5. 5. 5. 4. 5. 1. 1. 5. 3. 5. 5. 2. 5. 3. 2. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 3. 5. 5. 5. 3. 3. 4. 5. 5. 1. 5. 5. 4. 5. 5. 5. 3. 3. 5. 5.\n",
      " 5. 5. 4. 3. 5. 4. 5. 5. 5. 5. 5. 5. 2. 4. 5. 4. 5. 5. 4. 4. 5. 5. 5. 5.\n",
      " 5. 4. 5. 5. 1. 1. 5. 5. 5. 5. 4. 4. 5. 5. 4. 3. 4. 3. 4. 5. 2. 3. 5. 5.\n",
      " 5. 4. 5. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 4. 3. 4. 5. 4. 5. 5. 4. 5. 4. 2.\n",
      " 5. 5. 2. 2. 5. 5. 5. 5. 4. 2. 5. 5. 4. 5. 4. 5. 5. 5. 5. 5. 4. 5. 5. 4.\n",
      " 5. 5. 5. 5. 4. 4. 5. 4. 2. 4. 5. 5. 5. 5. 5. 3. 5. 5. 4. 5. 5. 1. 5. 5.\n",
      " 2. 4. 4. 4. 5. 5. 5. 5. 5. 2. 3. 4. 5. 5. 4. 4. 4. 5. 3. 2. 5. 5. 5. 5.\n",
      " 4. 4. 4. 2. 2. 5. 5. 5. 4. 5. 4. 5. 3. 5. 5. 5. 5. 4. 4. 4. 4. 5. 3. 4.\n",
      " 5. 4. 4. 5. 5. 4. 5. 5. 5. 3. 3. 5. 5. 5. 5. 5. 5. 3. 3. 4. 5. 5. 3. 4.\n",
      " 5. 5. 3. 4. 5. 5. 5. 4. 5. 3. 3. 5. 5. 5. 5. 4. 5. 3. 4. 4. 4. 2. 3. 4.\n",
      " 4. 5. 5. 5. 4. 5. 4. 3. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 5. 5. 4. 4. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 2. 4. 4. 4. 5. 4. 4. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 4. 5. 5. 2. 4. 4. 5. 5. 4. 4.]\n",
      "Binary Hidden Ratings: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn\n",
      "Accuracy: 0.8603491271820449\n",
      "Precision: 0.8727034120734908\n",
      "Recall: 0.9779411764705882\n",
      "F1 Score: 0.9223300970873787\n",
      "\n",
      "\n",
      "Manually\n",
      "Accuracy: 0.8603491271820449\n",
      "Precision: 0.8727034120734908\n",
      "Recall: 0.9779411764705882\n",
      "F1 Score: 0.9223300970873787\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
