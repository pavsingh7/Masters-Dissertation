{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/7wlh6jzj03185p7x7ggqb_280000gn/T/ipykernel_33175/2736403722.py:2: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/Users/pavansingh/Desktop/all_revs_1.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 17, 2016</td>\n",
       "      <td>A34SO74JEYQXZW</td>\n",
       "      <td>B0012Y0ZG2</td>\n",
       "      <td>{'Size:': ' 39'}</td>\n",
       "      <td>Jose</td>\n",
       "      <td>Sally's stop selling this great shampoo for fu...</td>\n",
       "      <td>Fuller Hair</td>\n",
       "      <td>1458172800</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 13, 2014</td>\n",
       "      <td>A2TZW7B0YG2ZJQ</td>\n",
       "      <td>B0009RF9DW</td>\n",
       "      <td>{'Size:': ' 258'}</td>\n",
       "      <td>flavio sanchez</td>\n",
       "      <td>i am ok with this adidas hair and body 3 activ...</td>\n",
       "      <td>i love it</td>\n",
       "      <td>1394668800</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 26, 2013</td>\n",
       "      <td>A4DEEDXZK8L78</td>\n",
       "      <td>B000URXP6E</td>\n",
       "      <td>{'Size:': ' 205'}</td>\n",
       "      <td>Gloria Karimi</td>\n",
       "      <td>This is a beautiful scented lotion.  Very mois...</td>\n",
       "      <td>Beautiful Scent</td>\n",
       "      <td>1382745600</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 15, 2017</td>\n",
       "      <td>A1X15KWJ11IC1P</td>\n",
       "      <td>B0012Y0ZG2</td>\n",
       "      <td>{'Size:': ' 144'}</td>\n",
       "      <td>Mert Ozer</td>\n",
       "      <td>Lovely product and works great, except the art...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1513296000</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 7, 2014</td>\n",
       "      <td>A3RGQCA2GSFLX2</td>\n",
       "      <td>B000URXP6E</td>\n",
       "      <td>{'Size:': ' 169'}</td>\n",
       "      <td>self</td>\n",
       "      <td>hard to find a lab coat the fits nice.  this o...</td>\n",
       "      <td>Love the fit of the lab coat......</td>\n",
       "      <td>1391731200</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171241</th>\n",
       "      <td>9031018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 1, 2016</td>\n",
       "      <td>A28CR7BR4LGT0W</td>\n",
       "      <td>B0006Z7NN6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kraal</td>\n",
       "      <td>Like product as we have been using braggs  ami...</td>\n",
       "      <td>Like product as we have been using braggs amin...</td>\n",
       "      <td>1475280000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171242</th>\n",
       "      <td>9031019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 9, 2015</td>\n",
       "      <td>A2MNB77YGJ3CN0</td>\n",
       "      <td>B000GW241K</td>\n",
       "      <td>{'Size:': ' 2.6 Ounce ( Pack of 4)', 'Flavor:'...</td>\n",
       "      <td>L. Mountford</td>\n",
       "      <td>I've been a fan of Jack Link's products for a ...</td>\n",
       "      <td>Tasty hit of protein, but a bit salty</td>\n",
       "      <td>1444348800</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171243</th>\n",
       "      <td>9031020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>03 20, 2016</td>\n",
       "      <td>A22RZG1NQ0WAUX</td>\n",
       "      <td>B01AK44MOK</td>\n",
       "      <td>{'Size:': ' 6 Pouches', 'Flavor:': ' Sweet Pot...</td>\n",
       "      <td>K. L. Burchett</td>\n",
       "      <td>Tasty. Almost as thick as sweet potato fluff. ...</td>\n",
       "      <td>Tasty</td>\n",
       "      <td>1458432000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171244</th>\n",
       "      <td>9031021</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 5, 2015</td>\n",
       "      <td>A14NSDI5HZX9G5</td>\n",
       "      <td>B00FFFTIP8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ret.Pet Pro</td>\n",
       "      <td>Not what I was looking to receive. I was tryin...</td>\n",
       "      <td>Great Northern Popcorn 5 Pounds Bulk GNP...</td>\n",
       "      <td>1420416000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171245</th>\n",
       "      <td>9031022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 16, 2014</td>\n",
       "      <td>A3K0OWGS5G12L4</td>\n",
       "      <td>B000FL08B0</td>\n",
       "      <td>{'Size:': ' 11.75-Ounce, 6-Count'}</td>\n",
       "      <td>C.B. Lee</td>\n",
       "      <td>What's there to say..?  Damn good!</td>\n",
       "      <td>Damn good!</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9171246 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  overall  verified   reviewTime      reviewerID  \\\n",
       "0                 0      5.0      True  03 17, 2016  A34SO74JEYQXZW   \n",
       "1                 1      5.0      True  03 13, 2014  A2TZW7B0YG2ZJQ   \n",
       "2                 2      5.0      True  10 26, 2013   A4DEEDXZK8L78   \n",
       "3                 3      5.0      True  12 15, 2017  A1X15KWJ11IC1P   \n",
       "4                 4      5.0      True   02 7, 2014  A3RGQCA2GSFLX2   \n",
       "...             ...      ...       ...          ...             ...   \n",
       "9171241     9031018      5.0     False   10 1, 2016  A28CR7BR4LGT0W   \n",
       "9171242     9031019      4.0     False   10 9, 2015  A2MNB77YGJ3CN0   \n",
       "9171243     9031020      5.0     False  03 20, 2016  A22RZG1NQ0WAUX   \n",
       "9171244     9031021      3.0      True   01 5, 2015  A14NSDI5HZX9G5   \n",
       "9171245     9031022      5.0      True  12 16, 2014  A3K0OWGS5G12L4   \n",
       "\n",
       "               asin                                              style  \\\n",
       "0        B0012Y0ZG2                                   {'Size:': ' 39'}   \n",
       "1        B0009RF9DW                                  {'Size:': ' 258'}   \n",
       "2        B000URXP6E                                  {'Size:': ' 205'}   \n",
       "3        B0012Y0ZG2                                  {'Size:': ' 144'}   \n",
       "4        B000URXP6E                                  {'Size:': ' 169'}   \n",
       "...             ...                                                ...   \n",
       "9171241  B0006Z7NN6                                                NaN   \n",
       "9171242  B000GW241K  {'Size:': ' 2.6 Ounce ( Pack of 4)', 'Flavor:'...   \n",
       "9171243  B01AK44MOK  {'Size:': ' 6 Pouches', 'Flavor:': ' Sweet Pot...   \n",
       "9171244  B00FFFTIP8                                                NaN   \n",
       "9171245  B000FL08B0                 {'Size:': ' 11.75-Ounce, 6-Count'}   \n",
       "\n",
       "           reviewerName                                         reviewText  \\\n",
       "0                  Jose  Sally's stop selling this great shampoo for fu...   \n",
       "1        flavio sanchez  i am ok with this adidas hair and body 3 activ...   \n",
       "2         Gloria Karimi  This is a beautiful scented lotion.  Very mois...   \n",
       "3             Mert Ozer  Lovely product and works great, except the art...   \n",
       "4                  self  hard to find a lab coat the fits nice.  this o...   \n",
       "...                 ...                                                ...   \n",
       "9171241           Kraal  Like product as we have been using braggs  ami...   \n",
       "9171242    L. Mountford  I've been a fan of Jack Link's products for a ...   \n",
       "9171243  K. L. Burchett  Tasty. Almost as thick as sweet potato fluff. ...   \n",
       "9171244     ret.Pet Pro  Not what I was looking to receive. I was tryin...   \n",
       "9171245        C.B. Lee                 What's there to say..?  Damn good!   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "0                                              Fuller Hair      1458172800   \n",
       "1                                                i love it      1394668800   \n",
       "2                                          Beautiful Scent      1382745600   \n",
       "3                                               Five Stars      1513296000   \n",
       "4                       Love the fit of the lab coat......      1391731200   \n",
       "...                                                    ...             ...   \n",
       "9171241  Like product as we have been using braggs amin...      1475280000   \n",
       "9171242              Tasty hit of protein, but a bit salty      1444348800   \n",
       "9171243                                              Tasty      1458432000   \n",
       "9171244        Great Northern Popcorn 5 Pounds Bulk GNP...      1420416000   \n",
       "9171245                                         Damn good!      1418688000   \n",
       "\n",
       "                         category vote image  \n",
       "0                          beauty  NaN   NaN  \n",
       "1                          beauty  NaN   NaN  \n",
       "2                          beauty  NaN   NaN  \n",
       "3                          beauty  NaN   NaN  \n",
       "4                          beauty  NaN   NaN  \n",
       "...                           ...  ...   ...  \n",
       "9171241  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171242  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171243  grocery_and_gourmet_food  8.0   NaN  \n",
       "9171244  grocery_and_gourmet_food  NaN   NaN  \n",
       "9171245  grocery_and_gourmet_food  NaN   NaN  \n",
       "\n",
       "[9171246 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('/Users/pavansingh/Desktop/all_revs_1.csv')\n",
    "data.shape\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If We Wanted to Binarise the Results\n",
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)\n",
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If predicted rating is greater than or equal to 3.5, then 1, else 0\n",
      "\n",
      "Predicted Ratings: [5.   4.03 4.4  4.4  5.   5.   4.35 4.35 4.59 4.59 5.   5.   4.83 4.83\n",
      " 4.5  5.   3.79 3.79 3.9  3.9  4.89 4.89 4.26 4.26 4.03 4.03 4.37 4.37\n",
      " 4.26 4.26 4.95 4.95 4.52 4.52 5.   5.   4.45 4.45 4.9  4.9  4.91 4.91\n",
      " 4.53 4.53 4.72 4.72 4.3  4.3  4.85 4.85 3.89 3.89 4.17 4.17 4.15 4.15\n",
      " 4.   4.   4.42 4.42 2.94 2.94 3.7  3.7  4.5  4.5  4.21 4.21 4.76 4.76\n",
      " 4.28 4.28 4.07 4.07 4.05 4.05 4.59 4.59 3.95 3.95 4.66 4.66 4.17 4.17\n",
      " 4.   4.   4.68 4.68 4.61 4.61 4.52 4.52 3.72 3.72 4.81 4.81 4.28 4.28\n",
      " 4.24 4.24 4.11 4.11 4.07 4.07 4.71 4.71 4.55 4.55 4.8  4.8  4.87 4.87\n",
      " 4.89 4.89 4.5  4.5  4.4  4.4  4.16 4.16 4.72 4.72 4.38 4.38 4.67 4.67\n",
      " 4.37 4.37 4.   3.85 5.   5.   4.37 4.37 4.18 4.18 4.42 4.42 3.72 3.72\n",
      " 4.59 4.59 4.92 4.92 4.15 4.15 4.83 4.83 4.63 4.63 4.39 4.39 4.06 4.06\n",
      " 4.62 4.62 4.41 4.41 4.52 4.52 4.56 4.56 4.83 4.83 4.12 4.12 3.8  3.8\n",
      " 3.89 3.89 4.12 4.12 4.44 4.44 4.39 4.39 4.22 4.22 4.21 4.21 4.46 4.46\n",
      " 4.6  4.6  4.57 4.57 4.81 5.   4.59 4.   4.7  4.7  4.48 4.48 4.75 4.75\n",
      " 4.95 4.95 5.   5.   4.17 4.17 4.63 4.63 3.33 3.33 4.93 4.93 4.41 4.41\n",
      " 4.07 4.07 3.27 3.27 4.53 4.53 3.42 3.42 3.78 3.78 4.58 4.58 4.6  4.6\n",
      " 4.73 4.73 3.94 3.94 3.   3.   4.68 4.68 4.32 4.32 4.21 4.21 4.44 4.44\n",
      " 4.17 4.17 4.04 4.04 3.94 3.94 4.54 4.54 3.85 3.85 3.79 3.79 4.56 4.56\n",
      " 3.73 3.73 4.16 4.16 3.99 3.99 3.71 3.71 4.38 4.38 4.57 4.57 4.38 4.38\n",
      " 4.4  4.4  4.71 4.71 4.41 4.41 3.46 3.46 4.28 4.28 4.62 4.62 4.58 4.58\n",
      " 4.7  4.7  4.27 5.   3.44 3.44 4.71 4.71 4.33 4.33 4.14 4.14 4.53 4.53\n",
      " 4.   4.   4.25 4.25 4.56 4.56 3.11 3.11 4.28 4.28 2.81 2.81 4.45 4.45\n",
      " 3.9  3.9  4.47 4.47 4.74 4.74 4.9  4.9  4.   4.   4.2  4.2  4.83 5.\n",
      " 4.68 4.68 4.1  4.1  4.35 4.35 3.74 3.74 4.18 4.18 5.   5.   4.35 4.35\n",
      " 4.77 4.77 4.7  4.7  3.85 3.85 4.52 4.52 3.75 3.75 4.13 4.13 4.6  4.6\n",
      " 4.59 4.59 4.57 5.   4.15 4.15 3.9  3.9  4.96 4.96 4.27 4.27 4.89 4.89\n",
      " 4.14 5.   4.16 4.16 4.75 4.75 3.9  3.9  4.5  4.5  5.   5.   4.67 4.67\n",
      " 3.64 3.64 4.   4.   3.55 3.55 4.55 4.55 4.84 4.84 4.43 4.43 4.59 4.59\n",
      " 4.65 4.65 1.57 1.57 4.32 4.32 4.12 4.12 4.05 4.05 5.   5.   4.19 4.19\n",
      " 3.77 3.77 4.36 4.36 4.67 4.67 4.32 4.32 5.   5.   4.1  4.1  4.11 4.11\n",
      " 4.07 4.07 4.56 4.56 4.42 4.42 4.72 4.72 4.69 4.69 4.8  4.8  4.95 4.95\n",
      " 4.52 4.52 5.   5.   4.05 4.05 4.   4.   4.94 4.94 4.52 4.52 3.26 3.26\n",
      " 3.95 3.95 4.83 4.83 4.36 4.36 4.7  4.7  4.06 4.06 3.3  3.3  3.77 3.77\n",
      " 5.   5.   4.   4.   4.44 4.44 4.   4.   4.45 4.45 4.39 4.39 4.32 4.32\n",
      " 4.17 5.   3.65 3.65 4.73 4.73 4.39 4.39 4.49 4.49 3.79 3.79 2.64 3.3\n",
      " 4.79 4.79 4.58 4.58 4.39 4.39 4.32 4.32 4.5  4.5  3.86 3.86 4.67 4.67\n",
      " 4.58 4.58 3.79 3.79 4.24 4.24 4.75 4.75 3.92 3.92 4.45 4.45 4.24 4.24\n",
      " 4.24 4.24 4.55 4.55 4.58 4.58 4.   4.   4.94 4.94 4.27 4.27 4.17 4.17\n",
      " 4.34 4.34 5.   5.   4.87 4.87 4.63 4.63 3.84 3.84 4.72 4.72 4.52 4.52\n",
      " 4.67 4.67 4.95 4.95 4.66 4.66 4.48 5.   4.94 4.94 3.14 3.14 5.   5.\n",
      " 4.97 4.97 4.52 4.52 4.28 4.28 3.79 3.79 4.11 4.11 4.3  4.3  3.65 3.65\n",
      " 3.96 3.96 3.27 3.27 5.   5.   4.75 4.75 4.55 4.55 4.58 4.58 4.75 4.75\n",
      " 4.1  4.1  4.19 4.19 4.39 4.39 4.92 4.92 4.61 4.61 4.04 4.04 4.83 4.83\n",
      " 3.71 3.71 4.48 4.48 4.41 4.41 4.05 4.05 4.7  4.7  4.37 4.37 4.73 4.73\n",
      " 4.87 4.87 5.   5.   4.25 4.25 4.04 4.04 4.17 4.17 4.11 4.11 4.33 4.33\n",
      " 4.   4.   3.52 3.52 4.74 4.74 4.83 4.83 3.23 3.23 4.45 4.45 4.33 4.33\n",
      " 4.19 4.19 4.07 4.07 3.65 3.65 4.18 4.18 4.52 4.52 4.9  4.9  4.06 4.06\n",
      " 3.16 3.16 4.89 4.89 4.42 4.42 4.2  4.2  3.84 3.84 4.21 4.21 4.93 4.93\n",
      " 4.12 4.12 3.   3.   3.78 3.78 4.55 4.55 4.78 4.78 4.22 4.22 4.34 4.34\n",
      " 4.9  4.9  4.23 4.23 4.38 4.38 4.54 4.54 4.67 4.67 4.25 4.25 3.63 3.63\n",
      " 4.26 4.26 4.47 4.47 4.46 4.46 3.82 3.82 5.   5.   5.   5.   3.63 3.63\n",
      " 3.76 3.76 4.28 4.28 4.31 4.31 4.19 4.19 4.79 4.79 4.29 4.29 4.95 4.95\n",
      " 4.69 4.69 4.53 4.53 3.68 3.68 4.42 4.42 4.08 4.08 3.09 3.09 4.   4.\n",
      " 3.85 3.85 4.21 4.21 4.41 4.41 3.78 3.78 3.95 3.95 4.18 4.18 4.39 4.39\n",
      " 4.11 4.11 5.   5.   3.72 3.72 4.47 4.47 4.3  4.3  5.   5.   4.81 4.81\n",
      " 4.65 4.65 4.17 4.17 3.15 3.15 4.12 4.12 4.44 4.44 4.64 4.64 4.59 4.59\n",
      " 4.58 4.58 4.76 4.76 4.25 4.25 4.86 4.86 4.4  4.4  4.09 4.09 4.4  4.4\n",
      " 4.55 4.55 4.52 4.52]\n",
      "Binary Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "\n",
      "Hidden Ratings: [3. 5. 4. 4. 5. 5. 5. 5. 4. 5. 5. 5. 5. 5. 4. 5. 5. 4. 4. 3. 4. 5. 3. 3.\n",
      " 4. 4. 3. 5. 5. 5. 3. 5. 4. 4. 5. 5. 5. 5. 5. 5. 5. 4. 5. 4. 5. 4. 5. 5.\n",
      " 5. 5. 4. 3. 4. 4. 5. 4. 4. 4. 5. 5. 4. 3. 5. 3. 5. 5. 5. 4. 5. 5. 5. 5.\n",
      " 5. 4. 1. 3. 5. 3. 3. 5. 2. 4. 5. 4. 5. 5. 5. 5. 5. 5. 4. 5. 4. 4. 5. 5.\n",
      " 4. 5. 5. 4. 4. 3. 5. 4. 2. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 4. 2. 4. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 4. 4. 5. 5. 3. 4. 3. 5. 5. 5.\n",
      " 4. 5. 3. 3. 4. 5. 5. 5. 4. 4. 4. 5. 4. 5. 4. 5. 5. 1. 5. 5. 5. 2. 3. 4.\n",
      " 4. 4. 4. 4. 5. 4. 4. 5. 4. 4. 4. 5. 3. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 4. 5. 5. 5. 4. 1. 5. 5. 3. 5. 5. 5. 5. 3. 5. 5. 5. 5. 4. 3. 3. 2. 5. 4.\n",
      " 2. 1. 3. 5. 4. 5. 5. 5. 5. 5. 4. 5. 2. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4.\n",
      " 5. 4. 5. 4. 5. 5. 5. 4. 4. 4. 1. 5. 5. 4. 5. 5. 4. 5. 3. 2. 5. 5. 5. 5.\n",
      " 4. 5. 2. 5. 5. 4. 3. 3. 4. 4. 3. 5. 5. 5. 5. 3. 5. 5. 3. 5. 3. 5. 4. 4.\n",
      " 4. 4. 4. 4. 4. 5. 5. 4. 4. 4. 5. 5. 3. 3. 5. 5. 3. 4. 4. 5. 3. 5. 3. 5.\n",
      " 4. 5. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 5. 3. 4. 4. 4. 5. 5. 4. 5. 5. 5. 4.\n",
      " 5. 5. 5. 5. 1. 4. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4. 5. 5. 1. 5. 5. 5.\n",
      " 5. 5. 5. 4. 3. 4. 4. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 4. 4. 5. 3. 1. 5.\n",
      " 5. 5. 5. 5. 4. 4. 5. 4. 5. 5. 3. 2. 5. 4. 2. 5. 4. 4. 5. 5. 5. 4. 5. 5.\n",
      " 5. 5. 5. 5. 4. 4. 5. 5. 5. 5. 5. 4. 5. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 4. 4. 2. 5. 5. 5. 5. 4. 3. 3. 5. 5. 5. 3. 5. 5. 5. 5.\n",
      " 5. 3. 2. 3. 2. 2. 5. 5. 1. 5. 5. 5. 4. 1. 5. 5. 5. 5. 4. 4. 4. 4. 4. 3.\n",
      " 5. 5. 5. 5. 5. 5. 4. 5. 1. 1. 5. 3. 5. 5. 2. 5. 3. 2. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 3. 5. 5. 5. 3. 3. 4. 5. 5. 1. 5. 5. 4. 5. 5. 5. 3. 3. 5. 5.\n",
      " 5. 5. 4. 3. 5. 4. 5. 5. 5. 5. 5. 5. 2. 4. 5. 4. 5. 5. 4. 4. 5. 5. 5. 5.\n",
      " 5. 4. 5. 5. 1. 1. 5. 5. 5. 5. 4. 4. 5. 5. 4. 3. 4. 3. 4. 5. 2. 3. 5. 5.\n",
      " 5. 4. 5. 5. 5. 5. 4. 5. 5. 5. 5. 5. 5. 4. 3. 4. 5. 4. 5. 5. 4. 5. 4. 2.\n",
      " 5. 5. 2. 2. 5. 5. 5. 5. 4. 2. 5. 5. 4. 5. 4. 5. 5. 5. 5. 5. 4. 5. 5. 4.\n",
      " 5. 5. 5. 5. 4. 4. 5. 4. 2. 4. 5. 5. 5. 5. 5. 3. 5. 5. 4. 5. 5. 1. 5. 5.\n",
      " 2. 4. 4. 4. 5. 5. 5. 5. 5. 2. 3. 4. 5. 5. 4. 4. 4. 5. 3. 2. 5. 5. 5. 5.\n",
      " 4. 4. 4. 2. 2. 5. 5. 5. 4. 5. 4. 5. 3. 5. 5. 5. 5. 4. 4. 4. 4. 5. 3. 4.\n",
      " 5. 4. 4. 5. 5. 4. 5. 5. 5. 3. 3. 5. 5. 5. 5. 5. 5. 3. 3. 4. 5. 5. 3. 4.\n",
      " 5. 5. 3. 4. 5. 5. 5. 4. 5. 3. 3. 5. 5. 5. 5. 4. 5. 3. 4. 4. 4. 2. 3. 4.\n",
      " 4. 5. 5. 5. 4. 5. 4. 3. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 5. 5. 4. 4. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 2. 4. 4. 4. 5. 4. 4. 5. 5. 4. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 4. 5. 5. 2. 4. 4. 5. 5. 4. 4.]\n",
      "Binary Hidden Ratings: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn\n",
      "Accuracy: 0.8603491271820449\n",
      "Precision: 0.8727034120734908\n",
      "Recall: 0.9779411764705882\n",
      "F1 Score: 0.9223300970873787\n",
      "\n",
      "\n",
      "Manually\n",
      "Accuracy: 0.8603491271820449\n",
      "Precision: 0.8727034120734908\n",
      "Recall: 0.9779411764705882\n",
      "F1 Score: 0.9223300970873787\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix factorization using stochastic gradient descent\n",
    "def matrix_factorization_sgd(R, K, steps=500, alpha=0.001, beta=0.02, overfitting=True, bias=True):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    # Initialize user and item latent feature matrices\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # apply stochastic gradient descent to update P and Q\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "        # apply regularization to prevent overfitting\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        # set threshold for error rate\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "# apply matrix factorization using stochastic gradient descent\n",
    "nP, nQ = matrix_factorization_sgd(R=x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of item based collaborative filtering. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Calculate similarity (cosine similarity)\n",
    "4. Calculate weighted average of ratings\n",
    "5. Fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings \n",
    "9. Calculate classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>book3</th>\n",
       "      <th>book4</th>\n",
       "      <th>book5</th>\n",
       "      <th>book6</th>\n",
       "      <th>book7</th>\n",
       "      <th>book8</th>\n",
       "      <th>book9</th>\n",
       "      <th>book10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user6</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user9</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user11</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book1  book2  book3  book4  book5  book6  book7  book8  book9  book10\n",
       "user1       0      0      2      5      4      3      4      4      4       4\n",
       "user2       4      0      3      5      0      0      0      0      0       4\n",
       "user3       0      3      4      4      0      2      0      0      0       0\n",
       "user4       0      0      3      5      4      0      0      0      0       0\n",
       "user5       3      4      0      4      4      0      5      5      5       5\n",
       "user6       4      5      0      0      0      0      4      2      2       0\n",
       "user7       2      2      0      0      0      0      5      3      3       3\n",
       "user8       0      5      4      0      4      3      0      0      0       0\n",
       "user9       0      5      4      0      5      2      0      2      2       0\n",
       "user10      0      0      0      0      5      0      4      4      4       4\n",
       "user11      4      2      2      0      5      0      5      5      5       0\n",
       "user12      5      5      3      0      2      3      3      3      3       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 0\n",
      "Indices of Rated Books: [2 3 4 5 6 7 8 9]\n",
      "Indices to Hide: [4 5] \n",
      "\n",
      "User: 1\n",
      "Indices of Rated Books: [0 2 3 9]\n",
      "Indices to Hide: [3 9] \n",
      "\n",
      "User: 2\n",
      "Indices of Rated Books: [1 2 3 5]\n",
      "Indices to Hide: [5 1] \n",
      "\n",
      "User: 3\n",
      "Indices of Rated Books: [2 3 4]\n",
      "Indices to Hide: [4 2] \n",
      "\n",
      "User: 4\n",
      "Indices of Rated Books: [0 1 3 4 6 7 8 9]\n",
      "Indices to Hide: [9 1] \n",
      "\n",
      "User: 5\n",
      "Indices of Rated Books: [0 1 6 7 8]\n",
      "Indices to Hide: [8 1] \n",
      "\n",
      "User: 6\n",
      "Indices of Rated Books: [0 1 6 7 8 9]\n",
      "Indices to Hide: [8 9] \n",
      "\n",
      "User: 7\n",
      "Indices of Rated Books: [1 2 4 5]\n",
      "Indices to Hide: [1 5] \n",
      "\n",
      "User: 8\n",
      "Indices of Rated Books: [1 2 4 5 7 8]\n",
      "Indices to Hide: [1 7] \n",
      "\n",
      "User: 9\n",
      "Indices of Rated Books: [4 6 7 8 9]\n",
      "Indices to Hide: [6 4] \n",
      "\n",
      "User: 10\n",
      "Indices of Rated Books: [0 1 2 4 6 7 8]\n",
      "Indices to Hide: [2 0] \n",
      "\n",
      "User: 11\n",
      "Indices of Rated Books: [0 1 2 4 5 6 7 8]\n",
      "Indices to Hide: [1 7] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of Ratings per user \n",
      " [[4 5]\n",
      " [3 9]\n",
      " [5 1]\n",
      " [4 2]\n",
      " [9 1]\n",
      " [8 1]\n",
      " [8 9]\n",
      " [1 5]\n",
      " [1 7]\n",
      " [6 4]\n",
      " [2 0]\n",
      " [1 7]]\n",
      "Indices of Ratings per User joined [4 5 3 9 5 1 4 2 9 1 8 1 8 9 1 5 1 7 6 4 2 0 1 7]\n"
     ]
    }
   ],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Matrix with Hidden Ratings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>book3</th>\n",
       "      <th>book4</th>\n",
       "      <th>book5</th>\n",
       "      <th>book6</th>\n",
       "      <th>book7</th>\n",
       "      <th>book8</th>\n",
       "      <th>book9</th>\n",
       "      <th>book10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book1  book2  book3  book4  book5  book6  book7  book8  book9  book10\n",
       "user1       0      0      2      5      0      0      4      4      4       4\n",
       "user2       4      0      3      0      0      0      0      0      0       0\n",
       "user3       0      0      4      4      0      0      0      0      0       0\n",
       "user4       0      0      0      5      0      0      0      0      0       0\n",
       "user5       3      0      0      4      4      0      5      5      5       0\n",
       "user6       4      0      0      0      0      0      4      2      0       0\n",
       "user7       2      2      0      0      0      0      5      3      0       0\n",
       "user8       0      0      4      0      4      0      0      0      0       0\n",
       "user9       0      0      4      0      5      2      0      0      2       0\n",
       "user10      0      0      0      0      0      0      0      4      4       4\n",
       "user11      0      2      0      0      5      0      5      5      5       0\n",
       "user12      5      0      3      0      2      3      3      0      3       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>book3</th>\n",
       "      <th>book4</th>\n",
       "      <th>book5</th>\n",
       "      <th>book6</th>\n",
       "      <th>book7</th>\n",
       "      <th>book8</th>\n",
       "      <th>book9</th>\n",
       "      <th>book10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user6</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user9</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user11</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user12</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book1  book2  book3  book4  book5  book6  book7  book8  book9  book10\n",
       "user1       0      0      2      5      4      3      4      4      4       4\n",
       "user2       4      0      3      5      0      0      0      0      0       4\n",
       "user3       0      3      4      4      0      2      0      0      0       0\n",
       "user4       0      0      3      5      4      0      0      0      0       0\n",
       "user5       3      4      0      4      4      0      5      5      5       5\n",
       "user6       4      5      0      0      0      0      4      2      2       0\n",
       "user7       2      2      0      0      0      0      5      3      3       3\n",
       "user8       0      5      4      0      4      3      0      0      0       0\n",
       "user9       0      5      4      0      5      2      0      2      2       0\n",
       "user10      0      0      0      0      5      0      4      4      4       4\n",
       "user11      4      2      2      0      5      0      5      5      5       0\n",
       "user12      5      5      3      0      2      3      3      3      3       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.17, 0.39, 0.16, 0.28, 0.5 , 0.62, 0.36, 0.37, 0.  ],\n",
       "       [0.17, 1.  , 0.  , 0.  , 0.38, 0.  , 0.66, 0.58, 0.36, 0.  ],\n",
       "       [0.39, 0.  , 1.  , 0.34, 0.54, 0.56, 0.19, 0.1 , 0.31, 0.17],\n",
       "       [0.16, 0.  , 0.34, 1.  , 0.19, 0.  , 0.41, 0.45, 0.45, 0.39],\n",
       "       [0.28, 0.38, 0.54, 0.19, 1.  , 0.48, 0.51, 0.5 , 0.67, 0.  ],\n",
       "       [0.5 , 0.  , 0.56, 0.  , 0.48, 1.  , 0.23, 0.  , 0.37, 0.  ],\n",
       "       [0.62, 0.66, 0.19, 0.41, 0.51, 0.23, 1.  , 0.85, 0.71, 0.26],\n",
       "       [0.36, 0.58, 0.1 , 0.45, 0.5 , 0.  , 0.85, 1.  , 0.86, 0.58],\n",
       "       [0.37, 0.36, 0.31, 0.45, 0.67, 0.37, 0.71, 0.86, 1.  , 0.58],\n",
       "       [0.  , 0.  , 0.17, 0.39, 0.  , 0.  , 0.26, 0.58, 0.58, 1.  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get cosine sim matrix and change to pd dataframe and save to csv\n",
    "pd.DataFrame(cosine_similarity(x_hidden.T).round(2), index=x.columns, columns=x.columns).to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_sim_mat_cosine.csv\")\n",
    "sim_mat_cos = cosine_similarity(x_hidden.T).round(2)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings for User 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>book3</th>\n",
       "      <th>book4</th>\n",
       "      <th>book5</th>\n",
       "      <th>book6</th>\n",
       "      <th>book7</th>\n",
       "      <th>book8</th>\n",
       "      <th>book9</th>\n",
       "      <th>book10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>3.67</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.03</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user6</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user7</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user12</th>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book1  book2  book3  book4  book5  book6  book7  book8  book9  book10\n",
       "user1    3.67      4      2      5   3.63   3.03      4      4      4       4\n",
       "user2    4.00      0      3      0   0.00   0.00      0      0      0       0\n",
       "user3    0.00      0      4      4   0.00   0.00      0      0      0       0\n",
       "user4    0.00      0      0      5   0.00   0.00      0      0      0       0\n",
       "user5    3.00      0      0      4   4.00   0.00      5      5      5       0\n",
       "user6    4.00      0      0      0   0.00   0.00      4      2      0       0\n",
       "user7    2.00      2      0      0   0.00   0.00      5      3      0       0\n",
       "user8    0.00      0      4      0   4.00   0.00      0      0      0       0\n",
       "user9    0.00      0      4      0   5.00   2.00      0      0      2       0\n",
       "user10   0.00      0      0      0   0.00   0.00      0      4      4       4\n",
       "user11   0.00      2      0      0   5.00   0.00      5      5      5       0\n",
       "user12   5.00      0      3      0   2.00   3.00      3      0      3       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# get predicted ratings for unread books for user 1 using cosine similarity\n",
    "user_ratings = predic_matrix.iloc[0, :].values.reshape(1, -1)\n",
    "unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "\n",
    "for book_id in unread_books_indices:\n",
    "    similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "    ratings = user_ratings[0, rated_books_indices]\n",
    "    predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "    predic_matrix.iloc[0, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for User 1\")\n",
    "display(predic_matrix)\n",
    "\n",
    "# save to csv\n",
    "predic_matrix.to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_predic_matrix_cosine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings for All Users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book1</th>\n",
       "      <th>book2</th>\n",
       "      <th>book3</th>\n",
       "      <th>book4</th>\n",
       "      <th>book5</th>\n",
       "      <th>book6</th>\n",
       "      <th>book7</th>\n",
       "      <th>book8</th>\n",
       "      <th>book9</th>\n",
       "      <th>book10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>3.67</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.03</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user5</th>\n",
       "      <td>3.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user6</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user7</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.99</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.95</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user8</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user9</th>\n",
       "      <td>3.05</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user10</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user11</th>\n",
       "      <td>4.72</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user12</th>\n",
       "      <td>5.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book1  book2  book3  book4  book5  book6  book7  book8  book9  book10\n",
       "user1    3.67   4.00   2.00   5.00   3.63   3.03   4.00   4.00   4.00    4.00\n",
       "user2    4.00   4.00   3.00   3.32   3.34   3.47   3.77   3.78   3.54    3.00\n",
       "user3    4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00    4.00\n",
       "user4    5.00   5.00   5.00   5.00   5.00   5.00   5.00   5.00   5.00    5.00\n",
       "user5    3.00   4.67   4.11   4.00   4.00   4.06   5.00   5.00   5.00    4.78\n",
       "user6    4.00   3.18   3.71   3.12   3.22   4.00   4.00   2.00   3.11    2.62\n",
       "user7    2.00   2.00   2.99   3.65   3.22   2.95   5.00   3.00   3.30    3.62\n",
       "user8    4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00    4.00\n",
       "user9    3.05   3.54   4.00   3.28   5.00   2.00   3.16   3.16   2.00    2.45\n",
       "user10   4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00   4.00    4.00\n",
       "user11   4.72   2.00   5.00   5.00   5.00   5.00   5.00   5.00   5.00    5.00\n",
       "user12   5.00   2.97   3.00   3.08   2.00   3.00   3.00   3.08   3.00    3.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "    for book_id in unread_books_indices:\n",
    "        similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "        ratings = user_ratings[0, rated_books_indices]\n",
    "        \n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Ratings: [4 3 5 4 2 3 4 3 5 4 2 5 3 3 5 3 5 2 4 5 2 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding Predicted Ratings: [3.63 3.03 3.32 3.   4.   4.   5.   5.   4.78 4.67 3.11 3.18 3.3  3.62\n",
      " 4.   4.   3.54 3.16 4.   4.   5.   4.72 2.97 3.08]\n"
     ]
    }
   ],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(predic_matrix.shape[0]):\n",
    "    user_predicted_ratings = predic_matrix.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn\n",
      "Mean Absolute Error (MAE): 1.0529166666666667\n",
      "Mean Squared Error (MSE): 1.6499708333333334\n",
      "Root Mean Squared Error (RMSE): 1.2845119047067386\n",
      "\n",
      "\n",
      "Manually\n",
      "Mean Absolute Error (MAE): 1.0529166666666667\n",
      "Mean Squared Error (MSE): 1.6499708333333334\n",
      "Root Mean Squared Error (RMSE): 1.2845119047067386\n"
     ]
    }
   ],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If predicted rating is greater than or equal to 3.5, then 1, else 0\n",
      "\n",
      "Predicted Ratings: [3.63 3.03 3.32 3.   4.   4.   5.   5.   4.78 4.67 3.11 3.18 3.3  3.62\n",
      " 4.   4.   3.54 3.16 4.   4.   5.   4.72 2.97 3.08]\n",
      "Binary Predictions: [1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0]\n",
      "\n",
      "\n",
      "Hidden Ratings: [4 3 5 4 2 3 4 3 5 4 2 5 3 3 5 3 5 2 4 5 2 4 5 3]\n",
      "Binary Hidden Ratings: [1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn\n",
      "Accuracy: 0.5833333333333334\n",
      "Precision: 0.6\n",
      "Recall: 0.6923076923076923\n",
      "F1 Score: 0.6428571428571429\n",
      "\n",
      "\n",
      "Manually\n",
      "Accuracy: 0.5833333333333334\n",
      "Precision: 0.6\n",
      "Recall: 0.6923076923076923\n",
      "F1 Score: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of item based collaborative filtering. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Calculate similarity (cosine similarity)\n",
    "4. Calculate weighted average of ratings\n",
    "5. Fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings \n",
    "9. Calculate classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim matrix and change to pd dataframe and save to csv\n",
    "pd.DataFrame(cosine_similarity(x_hidden.T).round(2), index=x.columns, columns=x.columns).to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_sim_mat_cosine.csv\")\n",
    "sim_mat_cos = cosine_similarity(x_hidden.T).round(2)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# get predicted ratings for unread books for user 1 using cosine similarity\n",
    "user_ratings = predic_matrix.iloc[0, :].values.reshape(1, -1)\n",
    "unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "\n",
    "for book_id in unread_books_indices:\n",
    "    similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "    ratings = user_ratings[0, rated_books_indices]\n",
    "    predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "    predic_matrix.iloc[0, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for User 1\")\n",
    "display(predic_matrix)\n",
    "\n",
    "# save to csv\n",
    "predic_matrix.to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_predic_matrix_cosine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "    for book_id in unread_books_indices:\n",
    "        similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "        ratings = user_ratings[0, rated_books_indices]\n",
    "        \n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(predic_matrix.shape[0]):\n",
    "    user_predicted_ratings = predic_matrix.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'K': [2, 3],         # Number of latent features\n",
    "    'alpha': [0.001, 0.01], # Learning rate\n",
    "    'beta': [0.01, 0.02]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Create an instance of the GridSearchCV\n",
    "np.random.seed(42)\n",
    "grid_search = GridSearchCV(estimator=matrix_factorization_sgd, param_grid=param_grid, cv=2)\n",
    "grid_search.fit(R)\n",
    "\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_K = grid_search.best_params_['K']\n",
    "best_beta = grid_search.best_params_['beta']\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "print(f\"Best K: {best_K}\")\n",
    "print(f\"Best beta: {best_beta}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model with best hyperparameters\n",
    "best_model = matrix_factorization_sgd(R=x_hidden.values, K=best_K, alpha=best_beta, beta=best_beta,\n",
    "                                      use_regularization=True, use_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of matrix factorisation collaborative filtering. Specifically, we will be conducting non-negative matrix factorisation (NMF) and alternating least squares (ALS) matrix factorisation. We will be using the sample data created. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Factorise the matrix - *either NMF or ALS or even SVD*\n",
    "4. Predict the hidden ratings - fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings\n",
    "9. Calculate classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation w/SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # we can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix factorization using stochastic gradient descent\n",
    "def matrix_factorization_sgd(R, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    # Initialize user and item latent feature matrices\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # apply stochastic gradient descent to update P and Q\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "        # apply regularization to prevent overfitting\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        # set threshold for error rate\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "# apply matrix factorization using stochastic gradient descent\n",
    "nP, nQ = matrix_factorization_sgd(R=x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS)\n",
    "\n",
    "The main difference is in the optimization method used to decompose the matrix. Instead of using NMF, you use the ALS algorithm.\n",
    "\n",
    "**Algorithm Process**:\n",
    "\n",
    "***Convert the data into a matrix:*** Same as in NMF, represent users, items, and ratings in a matrix.\n",
    "\n",
    "***Hide some ratings for testing:*** Randomly select a subset of ratings to be used as a test set.\n",
    "\n",
    "***Decompose the matrix using ALS:*** Utilize an ALS algorithm to iteratively update the user and item matrices until convergence. We may need to define hyperparameters such as the number of latent features and regularization terms.\n",
    "\n",
    "***Reconstruct the original matrix:*** Combine the user and item matrices obtained from the ALS optimization to reconstruct the original matrix.\n",
    "\n",
    "***Make predictions using the reconstructed matrix:*** Use the reconstructed matrix to predict the ratings for the items that were hidden in the test set.\n",
    "\n",
    "***Evaluate the performance of the algorithm:*** Compare the predicted ratings to the actual ratings in the test set to evaluate the accuracy and effectiveness of your collaborative filtering algorithm. Use appropriate evaluation metrics such as MSE, RMSE, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "\n",
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n",
    "\n",
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_als(R, K, steps=5000, alpha=0.0001, reg_param=0.001):\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K) * 0.01\n",
    "    Q = np.random.rand(M, K) * 0.01\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                    P_norm = np.linalg.norm(P[i, :], 2)\n",
    "                    Q_norm = np.linalg.norm(Q[j, :], 2)\n",
    "                    P[i, :] = P[i, :] + alpha * (2 * eij * Q[j, :] - reg_param * P_norm)\n",
    "                    Q[j, :] = Q[j, :] + alpha * (2 * eij * P[i, :] - reg_param * Q_norm)\n",
    "\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[j, :].T), 2)\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "# apply matrix factorization using alternating least squares\n",
    "nP, nQ = matrix_factorization_als(R = x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"\\nRATINGS PREDICTION PROBLEM\\nUsing sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\\nBINARISED or CLASSIFICATION PROBLEM\")\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "R = x_hidden.values\n",
    "matrix_factorization_sgd = MatrixFactorizationSGD()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'K': [2, 3],         # Number of latent features\n",
    "    'alpha': [0.001, 0.01], # Learning rate\n",
    "    'beta': [0.01, 0.02]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Custom scoring function\n",
    "def custom_scoring_function(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return -mean_squared_error(y_true, y_pred)  # Use negative mean squared error as the score\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=matrix_factorization_sgd, param_grid=param_grid, cv=2, scoring=custom_scoring_function)\n",
    "grid_search.fit(R)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_K = grid_search.best_params_['K']\n",
    "best_beta = grid_search.best_params_['beta']\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "print(f\"Best K: {best_K}\")\n",
    "print(f\"Best beta: {best_beta}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model with best hyperparameters\n",
    "best_model = MatrixFactorizationSGD(K=best_K, alpha=best_beta, beta=best_beta,\n",
    "                                      use_regularization=True, use_bias=True)\n",
    "# Fit the model (i.e., find the optimal P and Q)\n",
    "best_model.fit(R)\n",
    "\n",
    "# Predictions with best model \n",
    "best_R_pred = best_model.predict(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MatrixFactorizationSGD(BaseEstimator):\n",
    "    def __init__(self, K=2, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True, steps=500):\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.use_regularization = use_regularization\n",
    "        self.use_bias = use_bias\n",
    "        self.steps = steps\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        N, M = X.shape\n",
    "        self.P = np.abs(np.random.randn(N, self.K))  # Initialize with non-negative values\n",
    "        self.Q = np.abs(np.random.randn(M, self.K))\n",
    "\n",
    "        # Initialize bias terms\n",
    "        if self.use_bias:\n",
    "            self.b_u = np.zeros(N)\n",
    "            self.b_i = np.zeros(M)\n",
    "            self.b = np.mean(X[np.where(X != 0)])  # global bias\n",
    "\n",
    "        for step in range(self.steps):\n",
    "            for i in range(N):\n",
    "                for j in range(M):\n",
    "                    if X[i][j] > 0:\n",
    "                        eij = X[i][j] - np.dot(self.P[i, :], self.Q[j, :])\n",
    "\n",
    "                        # Update P and Q\n",
    "                        for k in range(self.K):\n",
    "                            if self.use_regularization:\n",
    "                                self.P[i][k] += self.alpha * (2 * eij * self.Q[j][k] - self.beta * self.P[i][k])\n",
    "                                self.Q[j][k] += self.alpha * (2 * eij * self.P[i][k] - self.beta * self.Q[j][k])\n",
    "                            else:\n",
    "                                self.P[i][k] += self.alpha * (2 * eij * self.Q[j][k])\n",
    "                                self.Q[j][k] += self.alpha * (2 * eij * self.P[i][k])\n",
    "\n",
    "                        # Update bias terms\n",
    "                        if self.use_bias:\n",
    "                            self.b_u[i] += self.alpha * (eij - self.beta * self.b_u[i])\n",
    "                            self.b_i[j] += self.alpha * (eij - self.beta * self.b_i[j])\n",
    "\n",
    "            # Check for convergence within the loop\n",
    "            if np.sqrt(np.sum((X - np.dot(self.P, self.Q.T))**2)) < 0.001:\n",
    "                break\n",
    "\n",
    "        # Add bias terms to the prediction\n",
    "        if self.use_bias:\n",
    "            self.R_pred = np.dot(self.P, self.Q.T) + self.b + self.b_u[:, np.newaxis] + self.b_i[np.newaxis:,]\n",
    "        else:\n",
    "            self.R_pred = np.dot(self.P, self.Q.T)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.R_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
