{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "1. Simple Collaborative Filtering\n",
    "- User-based CF\n",
    "- Item-based CF\n",
    "- Matrix Factorization\n",
    "\n",
    "2. Advanced Collaborative Filtering\n",
    "- Neural Collaborative Filtering\n",
    "- Deep Matrix Factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset directory\n",
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (403550, 17)\n",
      "Number of unique users 161210\n",
      "Number of unique products 227151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>sentiments_vader_revText</th>\n",
       "      <th>sentiments_textblob_revText</th>\n",
       "      <th>subjectivities_textblob_revText</th>\n",
       "      <th>sentiment_score_afinn_revText</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "      <th>sentiment_score_nrc_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A29NAG6NZOBAJ8</td>\n",
       "      <td>kingpin16</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>B001IH8ERA</td>\n",
       "      <td>tuna yum</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>['tuna', 'yum']</td>\n",
       "      <td>['tuna', 'yum']</td>\n",
       "      <td>['tuna', 'yum']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1WVA7V02PQOY6</td>\n",
       "      <td>Dad of Divas</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>B000ZGY4PG</td>\n",
       "      <td>as someone that has always liked eating oatmea...</td>\n",
       "      <td>grocery_and_gourmet_food</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>['someon', 'alway', 'like', 'eat', 'oatmeal', ...</td>\n",
       "      <td>['someone', 'always', 'liked', 'eating', 'oatm...</td>\n",
       "      <td>['someone', 'always', 'liked', 'eating', 'oatm...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.82, 'pos': 0.18, 'compou...</td>\n",
       "      <td>0.397564</td>\n",
       "      <td>0.705641</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1KQJLBDF2OEMD</td>\n",
       "      <td>Sherelle Ellis</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>B00YLLHNHW</td>\n",
       "      <td>humans are stupid they love and they make mist...</td>\n",
       "      <td>kindle_store</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>['human', 'stupid', 'love', 'make', 'mistak', ...</td>\n",
       "      <td>['human', 'stupid', 'love', 'make', 'mistake',...</td>\n",
       "      <td>['humans', 'stupid', 'love', 'make', 'mistakes...</td>\n",
       "      <td>{'neg': 0.109, 'neu': 0.703, 'pos': 0.188, 'co...</td>\n",
       "      <td>0.097186</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MUHTKSOY7WVO</td>\n",
       "      <td>Upgrade Taos Computers</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>B00GJU4DD0</td>\n",
       "      <td>this thing rocks very lightslim great fit does...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>['thing', 'rock', 'lightslim', 'great', 'fit',...</td>\n",
       "      <td>['thing', 'rock', 'lightslim', 'great', 'fit',...</td>\n",
       "      <td>['thing', 'rocks', 'lightslim', 'great', 'fit'...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.512, 'pos': 0.488, 'comp...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID            reviewerName  reviewTime        asin  \\\n",
       "0  A29NAG6NZOBAJ8               kingpin16  2014-11-24  B001IH8ERA   \n",
       "1  A1WVA7V02PQOY6            Dad of Divas  2015-02-10  B000ZGY4PG   \n",
       "2  A1KQJLBDF2OEMD          Sherelle Ellis  2015-07-28  B00YLLHNHW   \n",
       "3  A1MUHTKSOY7WVO  Upgrade Taos Computers  2015-05-20  B00GJU4DD0   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0                                           tuna yum   \n",
       "1  as someone that has always liked eating oatmea...   \n",
       "2  humans are stupid they love and they make mist...   \n",
       "3  this thing rocks very lightslim great fit does...   \n",
       "\n",
       "                   category  overall  normalized_rating  \\\n",
       "0  grocery_and_gourmet_food      5.0               1.00   \n",
       "1  grocery_and_gourmet_food      5.0               1.00   \n",
       "2              kindle_store      4.0               0.75   \n",
       "3               electronics      5.0               1.00   \n",
       "\n",
       "                               stemmed_words_revText  \\\n",
       "0                                    ['tuna', 'yum']   \n",
       "1  ['someon', 'alway', 'like', 'eat', 'oatmeal', ...   \n",
       "2  ['human', 'stupid', 'love', 'make', 'mistak', ...   \n",
       "3  ['thing', 'rock', 'lightslim', 'great', 'fit',...   \n",
       "\n",
       "                            lemmatized_words_revText  \\\n",
       "0                                    ['tuna', 'yum']   \n",
       "1  ['someone', 'always', 'liked', 'eating', 'oatm...   \n",
       "2  ['human', 'stupid', 'love', 'make', 'mistake',...   \n",
       "3  ['thing', 'rock', 'lightslim', 'great', 'fit',...   \n",
       "\n",
       "                             filtered_tokens_revText  \\\n",
       "0                                    ['tuna', 'yum']   \n",
       "1  ['someone', 'always', 'liked', 'eating', 'oatm...   \n",
       "2  ['humans', 'stupid', 'love', 'make', 'mistakes...   \n",
       "3  ['thing', 'rocks', 'lightslim', 'great', 'fit'...   \n",
       "\n",
       "                            sentiments_vader_revText  \\\n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "1  {'neg': 0.0, 'neu': 0.82, 'pos': 0.18, 'compou...   \n",
       "2  {'neg': 0.109, 'neu': 0.703, 'pos': 0.188, 'co...   \n",
       "3  {'neg': 0.0, 'neu': 0.512, 'pos': 0.488, 'comp...   \n",
       "\n",
       "   sentiments_textblob_revText  subjectivities_textblob_revText  \\\n",
       "0                     0.000000                         0.000000   \n",
       "1                     0.397564                         0.705641   \n",
       "2                     0.097186                         0.688095   \n",
       "3                     0.466667                         0.483333   \n",
       "\n",
       "   sentiment_score_afinn_revText  sentiment_score_bing_revText  \\\n",
       "0                              0                             0   \n",
       "1                              4                             4   \n",
       "2                              4                             1   \n",
       "3                              3                             1   \n",
       "\n",
       "  sentiment_score_nrc_revText  \n",
       "0                       trust  \n",
       "1                    positive  \n",
       "2                     sadness  \n",
       "3                       trust  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data from csv file\n",
    "# amazon = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti_1.csv')\n",
    "\n",
    "# load sample data from csv file\n",
    "amazon = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti_sample_1.csv')\n",
    "\n",
    "# check data \n",
    "print(\"Shape of data\", amazon.shape)\n",
    "print(\"Number of unique users\", amazon.reviewerID.nunique())\n",
    "print(\"Number of unique products\", amazon.asin.nunique())\n",
    "display(amazon.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Simple Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filtering\n",
    "\n",
    "1. change data to user-item matrix\n",
    "2. calculate similarity between users\n",
    "3. predict rating for each user-item pair\n",
    "4. recommend items with highest predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
