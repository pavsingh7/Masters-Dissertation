{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorisation\n",
    "\n",
    "- Matrix Factorization is a general technique used in collaborative filtering and other applications where a matrix is decomposed into the product of two lower-rank matrices.\n",
    "- Stochastic Gradient Descent is an optimization algorithm commonly used to minimize the error in the factorization process.\n",
    "\n",
    "- The key idea is to iteratively update the elements of the factorized matrices using the gradient of the error with respect to the elements.\n",
    "\n",
    "\n",
    "## Algorithm Summary\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix. \n",
    "\n",
    "1. **Load the data**\n",
    "- data is provided in a dataframe where each row is a review\n",
    "\n",
    "2. **Create a user-item matrix**\n",
    "- convert dataframe into user-item matrix where each row is a user and each column is an item\n",
    "\n",
    "3. **Create test and train set**\n",
    "- hide $N$ ratings for each user in the training set and use them to test the performance of the model\n",
    "- Typically, a certain percentage of ratings for each user are masked in the training set and used for testing the model's performance.\n",
    "\n",
    "4. **Apply Non-negative Matrix Factorization (NMF)**\n",
    "\n",
    "    1.  Decompose the user-item interaction matrix into two non-negative matrices: a user matrix and an item matrix.\n",
    "    2. Minimize the reconstruction error between the original matrix and the product of the decomposed matrices using optimization techniques like gradient descent.\n",
    "\n",
    "5. **Make predictions**\n",
    "- For each user-item pair in the test set, predict the rating by reconstructing the original rating matrix using the decomposed user and item matrices.\n",
    "- The predicted rating is obtained by taking the dot product of the corresponding user and item latent factor vectors.\n",
    "\n",
    "6. **Evaluate the model**\n",
    "- Calculate the predictive accuracy of the model using various evaluation metrics such as Root Mean Squared Error (RMSE), Mean Squared Error (MSE), and Mean Absolute Error (MAE).\n",
    "- Additionally, assess the Top-N recommendation performance of the model using metrics like Normalized Discounted Cumulative Gain (NDCG) and Hit Rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manaul / From Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatised_reviewText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>sentiments_afinn</th>\n",
       "      <th>sentiments_bing</th>\n",
       "      <th>sentiments_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>AQ8OO59DJFJNZ</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>wonder movi</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>A244CRJ2QSVLZ4</td>\n",
       "      <td>2008-01-29</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>resident evil is a great science fictionhorror...</td>\n",
       "      <td>resid evil great scienc fictionhorror hybrid p...</td>\n",
       "      <td>resident evil great science fictionhorror hybr...</td>\n",
       "      <td>resident evil great science fictionhorror hybr...</td>\n",
       "      <td>-12</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>A1VCLTAGM5RLND</td>\n",
       "      <td>2005-07-23</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i this movie has people living and working und...</td>\n",
       "      <td>movi peopl live work underground place call hi...</td>\n",
       "      <td>movie people living working underground place ...</td>\n",
       "      <td>movie people living working underground place ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>A119Q9NFGVOEJZ</td>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>every single video game based movie from the s...</td>\n",
       "      <td>everi singl video game base movi super mario b...</td>\n",
       "      <td>every single video game based movie super mari...</td>\n",
       "      <td>every single video game based movie super mari...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>A1RP6YCOS5VJ5I</td>\n",
       "      <td>2006-09-26</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i think that i like this movie more than the o...</td>\n",
       "      <td>think like movi origin origin still great real...</td>\n",
       "      <td>think like movie original original still great...</td>\n",
       "      <td>think like movie original original still great...</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID  reviewTime        asin  overall  \\\n",
       "76   AQ8OO59DJFJNZ  2018-01-05  0767834739      5.0   \n",
       "78  A244CRJ2QSVLZ4  2008-01-29  0767834739      5.0   \n",
       "81  A1VCLTAGM5RLND  2005-07-23  0767834739      5.0   \n",
       "82  A119Q9NFGVOEJZ  2016-02-13  0767834739      5.0   \n",
       "83  A1RP6YCOS5VJ5I  2006-09-26  0767834739      5.0   \n",
       "\n",
       "                                           reviewText  \\\n",
       "76                                    wonderful movie   \n",
       "78  resident evil is a great science fictionhorror...   \n",
       "81  i this movie has people living and working und...   \n",
       "82  every single video game based movie from the s...   \n",
       "83  i think that i like this movie more than the o...   \n",
       "\n",
       "                                stemmed_words_revText  \\\n",
       "76                                        wonder movi   \n",
       "78  resid evil great scienc fictionhorror hybrid p...   \n",
       "81  movi peopl live work underground place call hi...   \n",
       "82  everi singl video game base movi super mario b...   \n",
       "83  think like movi origin origin still great real...   \n",
       "\n",
       "                                lemmatised_reviewText  \\\n",
       "76                                    wonderful movie   \n",
       "78  resident evil great science fictionhorror hybr...   \n",
       "81  movie people living working underground place ...   \n",
       "82  every single video game based movie super mari...   \n",
       "83  think like movie original original still great...   \n",
       "\n",
       "                              filtered_tokens_revText  sentiments_afinn  \\\n",
       "76                                    wonderful movie                 4   \n",
       "78  resident evil great science fictionhorror hybr...               -12   \n",
       "81  movie people living working underground place ...                -1   \n",
       "82  every single video game based movie super mari...                18   \n",
       "83  think like movie original original still great...                29   \n",
       "\n",
       "    sentiments_bing  sentiments_vader  \n",
       "76                1            0.5719  \n",
       "78               -5           -0.9455  \n",
       "81                0           -0.1806  \n",
       "82                6            0.9846  \n",
       "83               10            0.9951  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  83139\n",
      "Number of Columns:  11\n",
      "Number of Unique Users:  3668\n",
      "Number of Unique Products:  3249\n",
      "Fewest reviews by a reviewer: 13\n",
      "Most reviews by a reviewer: 193\n",
      "Fewest reviews per product: 13\n",
      "Most reviews per product: 189\n",
      "\n",
      "\n",
      "\n",
      "User-Item Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0767834739</th>\n",
       "      <th>7799146915</th>\n",
       "      <th>B00000DMAT</th>\n",
       "      <th>B00000DMAX</th>\n",
       "      <th>B00000DMB3</th>\n",
       "      <th>B00000F1GM</th>\n",
       "      <th>B00000I1BJ</th>\n",
       "      <th>B00000I1BY</th>\n",
       "      <th>B00000ID61</th>\n",
       "      <th>B00000INR2</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H353FLA</th>\n",
       "      <th>B01H353HUY</th>\n",
       "      <th>B01H3VFR6U</th>\n",
       "      <th>B01H5GB8ZW</th>\n",
       "      <th>B01H6OXQFS</th>\n",
       "      <th>B01H9SH2LU</th>\n",
       "      <th>B01HGBAFNC</th>\n",
       "      <th>B01HHVVLGQ</th>\n",
       "      <th>B01HHVWWMI</th>\n",
       "      <th>B01HIZF7XE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100RH4M1W1DF0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1027EV8A9PV1O</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A103KKI1Y4TFNQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1047P9FLHTDZJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            0767834739  7799146915  B00000DMAT  B00000DMAX  B00000DMB3  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B00000F1GM  B00000I1BJ  B00000I1BY  B00000ID61  B00000INR2  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            ...  B01H353FLA  B01H353HUY  B01H3VFR6U  B01H5GB8ZW  \\\n",
       "reviewerID      ...                                                   \n",
       "A100RH4M1W1DF0  ...         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O  ...         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01H6OXQFS  B01H9SH2LU  B01HGBAFNC  B01HHVVLGQ  B01HHVWWMI  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         5.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HIZF7XE  \n",
       "reviewerID                  \n",
       "A100RH4M1W1DF0         0.0  \n",
       "A100WO06OQR8BQ         0.0  \n",
       "A1027EV8A9PV1O         0.0  \n",
       "A103KKI1Y4TFNQ         0.0  \n",
       "A1047P9FLHTDZJ         0.0  \n",
       "\n",
       "[5 rows x 3249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3668, 3249)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "# amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "amz_data = pd.read_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set4_data_modelling.csv\", index_col=0)\n",
    "display(amz_data.head())\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 4\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of Ratings per user \n",
      " [[2807 2258 2647 1953]\n",
      " [2111 1398 1498 1710]\n",
      " [ 200 1102 1089 1429]\n",
      " ...\n",
      " [2353 1482  185 1469]\n",
      " [ 639 2206 3123  311]\n",
      " [ 193  533  406  220]]\n",
      "Indices of Ratings per User joined [2807 2258 2647 ...  533  406  220]\n",
      "\n",
      "\n",
      "Updated Matrix with Hidden Ratings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0767834739</th>\n",
       "      <th>7799146915</th>\n",
       "      <th>B00000DMAT</th>\n",
       "      <th>B00000DMAX</th>\n",
       "      <th>B00000DMB3</th>\n",
       "      <th>B00000F1GM</th>\n",
       "      <th>B00000I1BJ</th>\n",
       "      <th>B00000I1BY</th>\n",
       "      <th>B00000ID61</th>\n",
       "      <th>B00000INR2</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H353FLA</th>\n",
       "      <th>B01H353HUY</th>\n",
       "      <th>B01H3VFR6U</th>\n",
       "      <th>B01H5GB8ZW</th>\n",
       "      <th>B01H6OXQFS</th>\n",
       "      <th>B01H9SH2LU</th>\n",
       "      <th>B01HGBAFNC</th>\n",
       "      <th>B01HHVVLGQ</th>\n",
       "      <th>B01HHVWWMI</th>\n",
       "      <th>B01HIZF7XE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100RH4M1W1DF0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1027EV8A9PV1O</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A103KKI1Y4TFNQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1047P9FLHTDZJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZVIQ5SU7XPD5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZW0HVDKOXGN9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZX2RDN9YXZAE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZY157FF14CSL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZYU8M791SIFC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3668 rows × 3249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            0767834739  7799146915  B00000DMAT  B00000DMAX  B00000DMB3  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B00000F1GM  B00000I1BJ  B00000I1BY  B00000ID61  B00000INR2  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            ...  B01H353FLA  B01H353HUY  B01H3VFR6U  B01H5GB8ZW  \\\n",
       "reviewerID      ...                                                   \n",
       "A100RH4M1W1DF0  ...         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O  ...         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ  ...         0.0         0.0         0.0         0.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5   ...         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9   ...         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE   ...         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL   ...         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC   ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01H6OXQFS  B01H9SH2LU  B01HGBAFNC  B01HHVVLGQ  B01HHVWWMI  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         5.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HIZF7XE  \n",
       "reviewerID                  \n",
       "A100RH4M1W1DF0         0.0  \n",
       "A100WO06OQR8BQ         0.0  \n",
       "A1027EV8A9PV1O         0.0  \n",
       "A103KKI1Y4TFNQ         0.0  \n",
       "A1047P9FLHTDZJ         0.0  \n",
       "...                    ...  \n",
       "AZVIQ5SU7XPD5          0.0  \n",
       "AZW0HVDKOXGN9          0.0  \n",
       "AZX2RDN9YXZAE          0.0  \n",
       "AZY157FF14CSL          0.0  \n",
       "AZYU8M791SIFC          0.0  \n",
       "\n",
       "[3668 rows x 3249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0767834739</th>\n",
       "      <th>7799146915</th>\n",
       "      <th>B00000DMAT</th>\n",
       "      <th>B00000DMAX</th>\n",
       "      <th>B00000DMB3</th>\n",
       "      <th>B00000F1GM</th>\n",
       "      <th>B00000I1BJ</th>\n",
       "      <th>B00000I1BY</th>\n",
       "      <th>B00000ID61</th>\n",
       "      <th>B00000INR2</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H353FLA</th>\n",
       "      <th>B01H353HUY</th>\n",
       "      <th>B01H3VFR6U</th>\n",
       "      <th>B01H5GB8ZW</th>\n",
       "      <th>B01H6OXQFS</th>\n",
       "      <th>B01H9SH2LU</th>\n",
       "      <th>B01HGBAFNC</th>\n",
       "      <th>B01HHVVLGQ</th>\n",
       "      <th>B01HHVWWMI</th>\n",
       "      <th>B01HIZF7XE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100RH4M1W1DF0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1027EV8A9PV1O</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A103KKI1Y4TFNQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1047P9FLHTDZJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZVIQ5SU7XPD5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZW0HVDKOXGN9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZX2RDN9YXZAE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZY157FF14CSL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZYU8M791SIFC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3668 rows × 3249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            0767834739  7799146915  B00000DMAT  B00000DMAX  B00000DMB3  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B00000F1GM  B00000I1BJ  B00000I1BY  B00000ID61  B00000INR2  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            ...  B01H353FLA  B01H353HUY  B01H3VFR6U  B01H5GB8ZW  \\\n",
       "reviewerID      ...                                                   \n",
       "A100RH4M1W1DF0  ...         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O  ...         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ  ...         0.0         0.0         0.0         0.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5   ...         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9   ...         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE   ...         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL   ...         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC   ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01H6OXQFS  B01H9SH2LU  B01HGBAFNC  B01HHVVLGQ  B01HHVWWMI  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         5.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5          0.0         0.0         0.0         0.0         0.0   \n",
       "AZW0HVDKOXGN9          0.0         0.0         0.0         0.0         0.0   \n",
       "AZX2RDN9YXZAE          0.0         0.0         0.0         0.0         0.0   \n",
       "AZY157FF14CSL          0.0         0.0         0.0         0.0         0.0   \n",
       "AZYU8M791SIFC          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HIZF7XE  \n",
       "reviewerID                  \n",
       "A100RH4M1W1DF0         0.0  \n",
       "A100WO06OQR8BQ         0.0  \n",
       "A1027EV8A9PV1O         0.0  \n",
       "A103KKI1Y4TFNQ         0.0  \n",
       "A1047P9FLHTDZJ         0.0  \n",
       "...                    ...  \n",
       "AZVIQ5SU7XPD5          0.0  \n",
       "AZW0HVDKOXGN9          0.0  \n",
       "AZX2RDN9YXZAE          0.0  \n",
       "AZY157FF14CSL          0.0  \n",
       "AZYU8M791SIFC          0.0  \n",
       "\n",
       "[3668 rows x 3249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n",
    "\n",
    "# see updated matrix with hidden ratings\n",
    "print(\"\\n\\nUpdated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition, Optimisation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of matrix factorization using stochastic gradient descent (SGD) for non-negative matrix factorization (NMF). Let’s break down the key components:\n",
    "\n",
    "1. Initialization:\n",
    "- We initialize matrices P and Q with non-negative random values, which is appropriate for NMF.\n",
    "- The bias terms b_u and b_i are initialized to zeros, and the global bias b is calculated as the mean of non-zero elements in the input matrix R.\n",
    "\n",
    "\n",
    "\n",
    "2. Update Rules:\n",
    "- We use the SGD approach to update P and Q iteratively based on the error eij (difference between the actual rating and the predicted rating).\n",
    "- If use_regularization is enabled, We apply L2 regularization to the updates by adding a penalty term proportional to the current value of P and Q.\n",
    "- The bias terms b_u and b_i are also updated based on the error.\n",
    "- Main Loop: The code runs for a fixed number of iterations, with each iteration looping over all $(i,j)$, entries in the input matrix $R$. If R[i][j] is a non-zero rating, it computes the prediction error $e_{ij}$ (difference between observed and predicted ratings). Then, it updates P[i] and Q[j] by SGD with added regularization terms.\n",
    "\n",
    "3. Convergence Check:\n",
    "- We monitor the convergence by calculating the Frobenius norm of the difference between the original matrix R and the reconstructed matrix PQ^T.\n",
    "- If the difference falls below a threshold (0.001 in our case), the algorithm stops iterating.\n",
    "\n",
    "4. Bias Terms:\n",
    "- We correctly add the bias terms to the final prediction if use_bias is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Original Matrix:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Reconstructed Matrix:\n",
      "[[ 8.11170986 10.40847241 10.91051086 ... 10.0319263  10.42355291\n",
      "  10.2637877 ]\n",
      " [ 7.86299632  9.63079303  9.99850803 ...  9.38918653  9.50124324\n",
      "   9.67077695]\n",
      " [ 8.09068375 10.40319009 10.90813577 ... 10.02503282 10.41706243\n",
      "  10.25923443]\n",
      " ...\n",
      " [ 5.30186922  8.25856039  8.98029402 ...  7.5987452   8.71749544\n",
      "   7.5860218 ]\n",
      " [ 6.85017054  9.7408542  10.40672677 ...  9.18409616  9.98411501\n",
      "   9.31453052]\n",
      " [ 7.63063289  9.42200823  9.80515319 ...  9.15356501  9.34663211\n",
      "   9.39986478]]\n",
      "\n",
      "Reconstructed Matrix as a DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0767834739</th>\n",
       "      <th>7799146915</th>\n",
       "      <th>B00000DMAT</th>\n",
       "      <th>B00000DMAX</th>\n",
       "      <th>B00000DMB3</th>\n",
       "      <th>B00000F1GM</th>\n",
       "      <th>B00000I1BJ</th>\n",
       "      <th>B00000I1BY</th>\n",
       "      <th>B00000ID61</th>\n",
       "      <th>B00000INR2</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H353FLA</th>\n",
       "      <th>B01H353HUY</th>\n",
       "      <th>B01H3VFR6U</th>\n",
       "      <th>B01H5GB8ZW</th>\n",
       "      <th>B01H6OXQFS</th>\n",
       "      <th>B01H9SH2LU</th>\n",
       "      <th>B01HGBAFNC</th>\n",
       "      <th>B01HHVVLGQ</th>\n",
       "      <th>B01HHVWWMI</th>\n",
       "      <th>B01HIZF7XE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100RH4M1W1DF0</th>\n",
       "      <td>8.111710</td>\n",
       "      <td>10.408472</td>\n",
       "      <td>10.910511</td>\n",
       "      <td>10.048930</td>\n",
       "      <td>10.798227</td>\n",
       "      <td>10.493628</td>\n",
       "      <td>10.508752</td>\n",
       "      <td>9.997847</td>\n",
       "      <td>10.148841</td>\n",
       "      <td>10.406584</td>\n",
       "      <td>...</td>\n",
       "      <td>9.613887</td>\n",
       "      <td>9.788183</td>\n",
       "      <td>10.115304</td>\n",
       "      <td>10.604661</td>\n",
       "      <td>10.019414</td>\n",
       "      <td>9.791733</td>\n",
       "      <td>9.771988</td>\n",
       "      <td>10.031926</td>\n",
       "      <td>10.423553</td>\n",
       "      <td>10.263788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>7.862996</td>\n",
       "      <td>9.630793</td>\n",
       "      <td>9.998508</td>\n",
       "      <td>9.220483</td>\n",
       "      <td>9.987230</td>\n",
       "      <td>9.726718</td>\n",
       "      <td>9.733856</td>\n",
       "      <td>9.052886</td>\n",
       "      <td>9.402366</td>\n",
       "      <td>9.397979</td>\n",
       "      <td>...</td>\n",
       "      <td>8.998871</td>\n",
       "      <td>9.176625</td>\n",
       "      <td>9.140778</td>\n",
       "      <td>9.995920</td>\n",
       "      <td>9.457581</td>\n",
       "      <td>8.757086</td>\n",
       "      <td>8.804417</td>\n",
       "      <td>9.389187</td>\n",
       "      <td>9.501243</td>\n",
       "      <td>9.670777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1027EV8A9PV1O</th>\n",
       "      <td>8.090684</td>\n",
       "      <td>10.403190</td>\n",
       "      <td>10.908136</td>\n",
       "      <td>10.041008</td>\n",
       "      <td>10.796725</td>\n",
       "      <td>10.491079</td>\n",
       "      <td>10.506611</td>\n",
       "      <td>9.987088</td>\n",
       "      <td>10.142911</td>\n",
       "      <td>10.400852</td>\n",
       "      <td>...</td>\n",
       "      <td>9.602777</td>\n",
       "      <td>9.778602</td>\n",
       "      <td>10.103728</td>\n",
       "      <td>10.605033</td>\n",
       "      <td>10.012206</td>\n",
       "      <td>9.782307</td>\n",
       "      <td>9.759400</td>\n",
       "      <td>10.025033</td>\n",
       "      <td>10.417062</td>\n",
       "      <td>10.259234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A103KKI1Y4TFNQ</th>\n",
       "      <td>7.192071</td>\n",
       "      <td>9.708995</td>\n",
       "      <td>10.279979</td>\n",
       "      <td>9.420201</td>\n",
       "      <td>10.079278</td>\n",
       "      <td>9.753159</td>\n",
       "      <td>9.769571</td>\n",
       "      <td>9.492981</td>\n",
       "      <td>9.433007</td>\n",
       "      <td>9.890751</td>\n",
       "      <td>...</td>\n",
       "      <td>8.858497</td>\n",
       "      <td>9.011851</td>\n",
       "      <td>9.643021</td>\n",
       "      <td>9.707174</td>\n",
       "      <td>9.176330</td>\n",
       "      <td>9.340167</td>\n",
       "      <td>9.306429</td>\n",
       "      <td>9.247536</td>\n",
       "      <td>9.850172</td>\n",
       "      <td>9.413032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1047P9FLHTDZJ</th>\n",
       "      <td>7.915208</td>\n",
       "      <td>10.250739</td>\n",
       "      <td>10.762679</td>\n",
       "      <td>9.895135</td>\n",
       "      <td>10.642789</td>\n",
       "      <td>10.334944</td>\n",
       "      <td>10.350645</td>\n",
       "      <td>9.852923</td>\n",
       "      <td>9.988805</td>\n",
       "      <td>10.266159</td>\n",
       "      <td>...</td>\n",
       "      <td>9.444283</td>\n",
       "      <td>9.618240</td>\n",
       "      <td>9.972635</td>\n",
       "      <td>10.433985</td>\n",
       "      <td>9.845625</td>\n",
       "      <td>9.653452</td>\n",
       "      <td>9.628851</td>\n",
       "      <td>9.864177</td>\n",
       "      <td>10.276709</td>\n",
       "      <td>10.092193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZVIQ5SU7XPD5</th>\n",
       "      <td>7.593515</td>\n",
       "      <td>9.963377</td>\n",
       "      <td>10.490180</td>\n",
       "      <td>9.634454</td>\n",
       "      <td>10.341876</td>\n",
       "      <td>10.029676</td>\n",
       "      <td>10.044935</td>\n",
       "      <td>9.635327</td>\n",
       "      <td>9.697830</td>\n",
       "      <td>10.035040</td>\n",
       "      <td>...</td>\n",
       "      <td>9.151921</td>\n",
       "      <td>9.316461</td>\n",
       "      <td>9.766515</td>\n",
       "      <td>10.075472</td>\n",
       "      <td>9.518911</td>\n",
       "      <td>9.449204</td>\n",
       "      <td>9.426814</td>\n",
       "      <td>9.554506</td>\n",
       "      <td>10.029793</td>\n",
       "      <td>9.757770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZW0HVDKOXGN9</th>\n",
       "      <td>6.197117</td>\n",
       "      <td>8.371460</td>\n",
       "      <td>8.880402</td>\n",
       "      <td>8.144746</td>\n",
       "      <td>8.656363</td>\n",
       "      <td>8.352730</td>\n",
       "      <td>8.360072</td>\n",
       "      <td>8.286306</td>\n",
       "      <td>8.109236</td>\n",
       "      <td>8.571175</td>\n",
       "      <td>...</td>\n",
       "      <td>7.648873</td>\n",
       "      <td>7.767143</td>\n",
       "      <td>8.456006</td>\n",
       "      <td>8.234668</td>\n",
       "      <td>7.875684</td>\n",
       "      <td>8.105976</td>\n",
       "      <td>8.142328</td>\n",
       "      <td>7.942372</td>\n",
       "      <td>8.545087</td>\n",
       "      <td>8.052676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZX2RDN9YXZAE</th>\n",
       "      <td>5.301869</td>\n",
       "      <td>8.258560</td>\n",
       "      <td>8.980294</td>\n",
       "      <td>8.160691</td>\n",
       "      <td>8.556620</td>\n",
       "      <td>8.184346</td>\n",
       "      <td>8.201294</td>\n",
       "      <td>8.556232</td>\n",
       "      <td>7.946534</td>\n",
       "      <td>8.894651</td>\n",
       "      <td>...</td>\n",
       "      <td>7.308165</td>\n",
       "      <td>7.400191</td>\n",
       "      <td>8.791628</td>\n",
       "      <td>7.733555</td>\n",
       "      <td>7.385289</td>\n",
       "      <td>8.525853</td>\n",
       "      <td>8.478086</td>\n",
       "      <td>7.598745</td>\n",
       "      <td>8.717495</td>\n",
       "      <td>7.586022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZY157FF14CSL</th>\n",
       "      <td>6.850171</td>\n",
       "      <td>9.740854</td>\n",
       "      <td>10.406727</td>\n",
       "      <td>9.487849</td>\n",
       "      <td>10.134734</td>\n",
       "      <td>9.777469</td>\n",
       "      <td>9.799527</td>\n",
       "      <td>9.642831</td>\n",
       "      <td>9.442823</td>\n",
       "      <td>10.085633</td>\n",
       "      <td>...</td>\n",
       "      <td>8.775401</td>\n",
       "      <td>8.926345</td>\n",
       "      <td>9.813726</td>\n",
       "      <td>9.619876</td>\n",
       "      <td>9.055765</td>\n",
       "      <td>9.553360</td>\n",
       "      <td>9.472204</td>\n",
       "      <td>9.184096</td>\n",
       "      <td>9.984115</td>\n",
       "      <td>9.314531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZYU8M791SIFC</th>\n",
       "      <td>7.630633</td>\n",
       "      <td>9.422008</td>\n",
       "      <td>9.805153</td>\n",
       "      <td>9.049896</td>\n",
       "      <td>9.755786</td>\n",
       "      <td>9.491013</td>\n",
       "      <td>9.497032</td>\n",
       "      <td>8.942077</td>\n",
       "      <td>9.189751</td>\n",
       "      <td>9.262880</td>\n",
       "      <td>...</td>\n",
       "      <td>8.791374</td>\n",
       "      <td>8.954849</td>\n",
       "      <td>9.045973</td>\n",
       "      <td>9.687124</td>\n",
       "      <td>9.200234</td>\n",
       "      <td>8.661843</td>\n",
       "      <td>8.716268</td>\n",
       "      <td>9.153565</td>\n",
       "      <td>9.346632</td>\n",
       "      <td>9.399865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3668 rows × 3249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            0767834739  7799146915  B00000DMAT  B00000DMAX  B00000DMB3  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0    8.111710   10.408472   10.910511   10.048930   10.798227   \n",
       "A100WO06OQR8BQ    7.862996    9.630793    9.998508    9.220483    9.987230   \n",
       "A1027EV8A9PV1O    8.090684   10.403190   10.908136   10.041008   10.796725   \n",
       "A103KKI1Y4TFNQ    7.192071    9.708995   10.279979    9.420201   10.079278   \n",
       "A1047P9FLHTDZJ    7.915208   10.250739   10.762679    9.895135   10.642789   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5     7.593515    9.963377   10.490180    9.634454   10.341876   \n",
       "AZW0HVDKOXGN9     6.197117    8.371460    8.880402    8.144746    8.656363   \n",
       "AZX2RDN9YXZAE     5.301869    8.258560    8.980294    8.160691    8.556620   \n",
       "AZY157FF14CSL     6.850171    9.740854   10.406727    9.487849   10.134734   \n",
       "AZYU8M791SIFC     7.630633    9.422008    9.805153    9.049896    9.755786   \n",
       "\n",
       "asin            B00000F1GM  B00000I1BJ  B00000I1BY  B00000ID61  B00000INR2  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0   10.493628   10.508752    9.997847   10.148841   10.406584   \n",
       "A100WO06OQR8BQ    9.726718    9.733856    9.052886    9.402366    9.397979   \n",
       "A1027EV8A9PV1O   10.491079   10.506611    9.987088   10.142911   10.400852   \n",
       "A103KKI1Y4TFNQ    9.753159    9.769571    9.492981    9.433007    9.890751   \n",
       "A1047P9FLHTDZJ   10.334944   10.350645    9.852923    9.988805   10.266159   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5    10.029676   10.044935    9.635327    9.697830   10.035040   \n",
       "AZW0HVDKOXGN9     8.352730    8.360072    8.286306    8.109236    8.571175   \n",
       "AZX2RDN9YXZAE     8.184346    8.201294    8.556232    7.946534    8.894651   \n",
       "AZY157FF14CSL     9.777469    9.799527    9.642831    9.442823   10.085633   \n",
       "AZYU8M791SIFC     9.491013    9.497032    8.942077    9.189751    9.262880   \n",
       "\n",
       "asin            ...  B01H353FLA  B01H353HUY  B01H3VFR6U  B01H5GB8ZW  \\\n",
       "reviewerID      ...                                                   \n",
       "A100RH4M1W1DF0  ...    9.613887    9.788183   10.115304   10.604661   \n",
       "A100WO06OQR8BQ  ...    8.998871    9.176625    9.140778    9.995920   \n",
       "A1027EV8A9PV1O  ...    9.602777    9.778602   10.103728   10.605033   \n",
       "A103KKI1Y4TFNQ  ...    8.858497    9.011851    9.643021    9.707174   \n",
       "A1047P9FLHTDZJ  ...    9.444283    9.618240    9.972635   10.433985   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5   ...    9.151921    9.316461    9.766515   10.075472   \n",
       "AZW0HVDKOXGN9   ...    7.648873    7.767143    8.456006    8.234668   \n",
       "AZX2RDN9YXZAE   ...    7.308165    7.400191    8.791628    7.733555   \n",
       "AZY157FF14CSL   ...    8.775401    8.926345    9.813726    9.619876   \n",
       "AZYU8M791SIFC   ...    8.791374    8.954849    9.045973    9.687124   \n",
       "\n",
       "asin            B01H6OXQFS  B01H9SH2LU  B01HGBAFNC  B01HHVVLGQ  B01HHVWWMI  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0   10.019414    9.791733    9.771988   10.031926   10.423553   \n",
       "A100WO06OQR8BQ    9.457581    8.757086    8.804417    9.389187    9.501243   \n",
       "A1027EV8A9PV1O   10.012206    9.782307    9.759400   10.025033   10.417062   \n",
       "A103KKI1Y4TFNQ    9.176330    9.340167    9.306429    9.247536    9.850172   \n",
       "A1047P9FLHTDZJ    9.845625    9.653452    9.628851    9.864177   10.276709   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZVIQ5SU7XPD5     9.518911    9.449204    9.426814    9.554506   10.029793   \n",
       "AZW0HVDKOXGN9     7.875684    8.105976    8.142328    7.942372    8.545087   \n",
       "AZX2RDN9YXZAE     7.385289    8.525853    8.478086    7.598745    8.717495   \n",
       "AZY157FF14CSL     9.055765    9.553360    9.472204    9.184096    9.984115   \n",
       "AZYU8M791SIFC     9.200234    8.661843    8.716268    9.153565    9.346632   \n",
       "\n",
       "asin            B01HIZF7XE  \n",
       "reviewerID                  \n",
       "A100RH4M1W1DF0   10.263788  \n",
       "A100WO06OQR8BQ    9.670777  \n",
       "A1027EV8A9PV1O   10.259234  \n",
       "A103KKI1Y4TFNQ    9.413032  \n",
       "A1047P9FLHTDZJ   10.092193  \n",
       "...                    ...  \n",
       "AZVIQ5SU7XPD5     9.757770  \n",
       "AZW0HVDKOXGN9     8.052676  \n",
       "AZX2RDN9YXZAE     7.586022  \n",
       "AZY157FF14CSL     9.314531  \n",
       "AZYU8M791SIFC     9.399865  \n",
       "\n",
       "[3668 rows x 3249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def matrix_factorization_sgd(R, K, steps=50, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = bias term\n",
    "\n",
    "    N, M = R.shape\n",
    "    P = np.abs(np.random.randn(N, K))  # Initialize with non-negative values\n",
    "    Q = np.abs(np.random.randn(M, K))\n",
    "    counter = 0\n",
    "\n",
    "    # Initialize bias terms\n",
    "    if use_bias:\n",
    "        b_u = np.zeros(N)\n",
    "        b_i = np.zeros(M)\n",
    "        b = np.mean(R[np.where(R != 0)])  # global bias\n",
    "\n",
    "    for step in range(steps):\n",
    "        print(\"Step:\", step)\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[j, :])\n",
    "\n",
    "                    # Update P and Q\n",
    "                    for k in range(K):\n",
    "                        if use_regularization:\n",
    "                            P[i][k] += alpha * (2 * eij * Q[j][k] - beta * P[i][k])\n",
    "                            Q[j][k] += alpha * (2 * eij * P[i][k] - beta * Q[j][k])\n",
    "                        else:\n",
    "                            P[i][k] += alpha * (2 * eij * Q[j][k])\n",
    "                            Q[j][k] += alpha * (2 * eij * P[i][k])\n",
    "\n",
    "                    # Update bias terms\n",
    "                    if use_bias:\n",
    "                        b_u[i] += alpha * (eij - beta * b_u[i])\n",
    "                        b_i[j] += alpha * (eij - beta * b_i[j])\n",
    "\n",
    "        # Check for convergence within the loop\n",
    "        if np.sqrt(np.sum((R - np.dot(P, Q.T))**2)) < 0.001:\n",
    "            break\n",
    "\n",
    "    # Add bias terms to the prediction\n",
    "    if use_bias:\n",
    "        R_pred = np.dot(P, Q.T) + b + b_u[:, np.newaxis] + b_i[np.newaxis:,]  \n",
    "    else:\n",
    "        R_pred = np.dot(P, Q.T)\n",
    "\n",
    "    return P, Q, R_pred\n",
    "\n",
    "\n",
    "# Use the function to reconstruct the original matrix\n",
    "np.random.seed(42)\n",
    "R = x_hidden.values\n",
    "nP, nQ, nR_pred = matrix_factorization_sgd(R, K=2, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True)\n",
    "print(\"Original Matrix:\")\n",
    "print(R)\n",
    "print(\"\\nReconstructed Matrix:\")\n",
    "print(nR_pred)\n",
    "\n",
    "#  convert the reconstructed matrix to a dataframe\n",
    "nR_pred = pd.DataFrame(nR_pred, columns=x_hidden.columns, index=x_hidden.index)\n",
    "print(\"\\nReconstructed Matrix as a DataFrame\")\n",
    "display(nR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "hidden_ratings_arrays = []\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 18\n",
      "K=2, alpha=0.001, beta=0.1\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Checking RMSE: 5.136051412482668\n",
      "New best RMSE: 5.136051412482668\n",
      "\n",
      "\n",
      "Iteration 2 of 18\n",
      "K=2, alpha=0.001, beta=0.5\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Checking RMSE: 4.9947778118396355\n",
      "New best RMSE: 4.9947778118396355\n",
      "\n",
      "\n",
      "Iteration 3 of 18\n",
      "K=2, alpha=0.001, beta=1\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Checking RMSE: 4.804254603260058\n",
      "New best RMSE: 4.804254603260058\n",
      "\n",
      "\n",
      "Iteration 4 of 18\n",
      "K=2, alpha=0.0001, beta=0.1\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Checking RMSE: 3.692075999183521\n",
      "New best RMSE: 3.692075999183521\n",
      "\n",
      "\n",
      "Iteration 5 of 18\n",
      "K=2, alpha=0.0001, beta=0.5\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Checking RMSE: 3.5499014313162847\n",
      "New best RMSE: 3.5499014313162847\n",
      "\n",
      "\n",
      "Iteration 6 of 18\n",
      "K=2, alpha=0.0001, beta=1\n",
      "Step: 0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(param_combinations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, alpha=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, beta=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m nP, nQ, nR_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization_sgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_regularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Compute RMSE\u001b[39;00m\n\u001b[1;32m     36\u001b[0m nR_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(nR_pred, columns\u001b[38;5;241m=\u001b[39mx_hidden\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mx_hidden\u001b[38;5;241m.\u001b[39mindex)\n",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36mmatrix_factorization_sgd\u001b[0;34m(R, K, steps, alpha, beta, use_regularization, use_bias)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mR\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m     24\u001b[0m             eij \u001b[38;5;241m=\u001b[39m R[i][j] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(P[i, :], Q[j, :])\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;66;03m# Update P and Q\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import itertools\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'K': [2,3,5],         # Number of latent features\n",
    "    'alpha': [0.001, 0.0001], # Learning rate\n",
    "    'beta': [0.1, 0.5, 1]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "# Initialize variables to keep track of the best parameters and the best RMSE\n",
    "best_params = None\n",
    "best_rmse = float('inf')  # initialize with a large value\n",
    "counter = 0\n",
    "\n",
    "# Loop over each parameter combination\n",
    "for params in param_combinations:\n",
    "    \n",
    "    # Unpack the parameters\n",
    "    K, alpha, beta = params\n",
    "    \n",
    "    # counter\n",
    "    counter += 1\n",
    "\n",
    "    # Run matrix factorization with the current hyperparameters\n",
    "    np.random.seed(42)\n",
    "    print(f\"Iteration {counter} of {len(param_combinations)}\")\n",
    "    print(f'K={K}, alpha={alpha}, beta={beta}')\n",
    "    nP, nQ, nR_pred = matrix_factorization_sgd(\n",
    "        R, K=K, alpha=alpha, beta=beta, use_regularization=True, use_bias=True)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    nR_pred = pd.DataFrame(nR_pred, columns=x_hidden.columns, index=x_hidden.index)\n",
    "    predicted_ratings_arrays = []\n",
    "    for user in range(nR_pred.shape[0]):\n",
    "        user_predicted_ratings = nR_pred.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "        predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "    predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(hidden_ratings_array, predicted_ratings_array))\n",
    "\n",
    "    # Check if this is the best RMSE so far\n",
    "    print(f\"Checking RMSE: {rmse}\")\n",
    "    if rmse < best_rmse:\n",
    "        print(f'New best RMSE: {rmse}')\n",
    "        best_rmse = rmse\n",
    "        best_params = params\n",
    "    else :\n",
    "        print(\"RMSE not improved\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the best parameters and the best RMSE\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best RMSE: {best_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Predictive Accuracy)\n",
    "\n",
    "Now evaluate how good the predictions are vs the hidden ratings\n",
    "- ***step 1***: identify the hidden ratings indices\n",
    "- ***step 2***: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "- ***step 3***: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Ratings: [3. 5. 5. ... 4. 1. 5.]\n",
      "Corresponding Predicted Ratings: [5.7297655  5.69016655 6.06080439 ... 4.81111752 5.00394805 5.15794999]\n",
      "Using sklearn\n",
      "Mean Absolute Error (MAE): 1.8010954363377594\n",
      "Mean Squared Error (MSE): 5.308916394493818\n",
      "Root Mean Squared Error (RMSE): 2.3041085899961002\n",
      "\n",
      "\n",
      "Manually\n",
      "Mean Absolute Error (MAE): 1.8010954363377594\n",
      "Mean Squared Error (MSE): 5.308916394493818\n",
      "Root Mean Squared Error (RMSE): 2.3041085899961002\n"
     ]
    }
   ],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR_pred.shape[0]):\n",
    "    user_predicted_ratings = nR_pred.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 2 decimal places\n",
    "mae = round(mae, 3)\n",
    "mse = round(mse, 3)\n",
    "rmse = round(rmse, 3)\n",
    "\n",
    "# Save the results to a csv file\n",
    "results = pd.DataFrame({'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "# results.to_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\results_NMF.csv', index=False)\n",
    "results.to_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/Results/MF_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `use_regularization` parameter controls whether regularization (beta) is applied.\n",
    "- The `use_bias` parameter controls whether bias terms are included.\n",
    "- We use the `NMF` class from `Scikit-learn`, which handles the optimization process for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavansingh/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "/Users/pavansingh/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Reconstructed Matrix:\n",
      "[[ 9.47914175  4.52876106  4.70464802 ...  4.52876106  4.52876106\n",
      "   4.88160201]\n",
      " [ 9.47914175  4.52876106  4.70464802 ...  4.52876106  4.52876106\n",
      "   4.88160201]\n",
      " [ 9.47914175  4.52876106  4.70464802 ...  4.52876106  4.52876106\n",
      "   4.88160201]\n",
      " ...\n",
      " [11.96670806  7.01632738  7.19221434 ...  7.01632738  7.01632738\n",
      "   7.36916833]\n",
      " [ 9.47914175  4.52876106  4.70464802 ...  4.52876106  4.52876106\n",
      "   4.88160201]\n",
      " [ 9.47914175  4.52876106  4.70464802 ...  4.52876106  4.52876106\n",
      "   4.88160201]]\n"
     ]
    }
   ],
   "source": [
    "# import NMF from scikit-learn\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "def matrix_factorization_nmf(R, K, steps=500, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True):\n",
    "    \"\"\"\n",
    "    Perform non-negative matrix factorization using scikit-learn's NMF.\n",
    "\n",
    "    Args:\n",
    "        R (numpy.ndarray): The input rating matrix.\n",
    "        K (int): Number of latent features.\n",
    "        steps (int): Maximum number of iterations.\n",
    "        alpha (float): Learning rate.\n",
    "        beta (float): Regularization parameter.\n",
    "        use_regularization (bool): Whether to use regularization.\n",
    "        use_bias (bool): Whether to use bias terms.\n",
    "    Returns:\n",
    "        numpy.ndarray, numpy.ndarray, numpy.ndarray: Factorized matrices P, Q, and the reconstructed matrix R_pred.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize NMF model\n",
    "    nmf_model = NMF(n_components=K, init='random', solver='cd', beta_loss='frobenius', max_iter=steps,\n",
    "                    alpha=alpha if use_regularization else 0.0, l1_ratio=beta if use_regularization else 0)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    nmf_model.fit(R)\n",
    "\n",
    "    # Get the transformed matrices\n",
    "    P = nmf_model.transform(R)\n",
    "    Q = nmf_model.components_\n",
    "\n",
    "    if use_bias:\n",
    "        b_u = np.zeros(P.shape[0])\n",
    "        b_i = np.zeros(Q.shape[1])\n",
    "        b = np.mean(R[np.where(R != 0)])\n",
    "\n",
    "        for _ in range(steps):\n",
    "            for i in range(P.shape[0]):\n",
    "                for j in range(Q.shape[1]):\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "\n",
    "                        P[i, :] += alpha * (2 * eij * Q[:, j] - beta * P[i, :])\n",
    "                        Q[:, j] += alpha * (2 * eij * P[i, :] - beta * Q[:, j])\n",
    "\n",
    "                        b_u[i] += alpha * (eij - beta * b_u[i])\n",
    "                        b_i[j] += alpha * (eij - beta * b_i[j])\n",
    "\n",
    "        R_pred = np.dot(P, Q) + b + b_u[:, np.newaxis] + b_i[np.newaxis:,]\n",
    "    else:\n",
    "        R_pred = np.dot(P, Q)\n",
    "\n",
    "    return P, Q, R_pred\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "nP, nQ, nR_pred = matrix_factorization_nmf(R, K=2, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True)\n",
    "print(\"Original Matrix:\")\n",
    "print(R)\n",
    "print(\"\\nReconstructed Matrix:\")\n",
    "print(nR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <function matrix_factorization_nmf at 0x7faa32abc550> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmatrix_factorization_nmf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# get params\u001b[39;00m\n\u001b[1;32m     15\u001b[0m best_K \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:777\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    775\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 777\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:459\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator should be an estimator implementing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;241m%\u001b[39m estimator\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <function matrix_factorization_nmf at 0x7faa32abc550> was passed"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'K': [2, 3, 4],         # Number of latent features\n",
    "    'alpha': [0.001, 0.01], # Learning rate\n",
    "    'beta': [0.01, 0.02]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Create an instance of the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=matrix_factorization_nmf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(R)\n",
    "\n",
    "# get params\n",
    "best_K = grid_search.best_params_['K']\n",
    "best_beta = grid_search.best_params_['beta']\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "print(f\"Best K: {best_K}\")\n",
    "print(f\"Best beta: {best_beta}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Re-train the model with best hyperparameters\n",
    "best_model = matrix_factorization_nmf(R=x_hidden.values, K=best_K, alpha=best_beta, beta=best_beta,\n",
    "                                      use_regularization=True, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Packages without Bias and Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nNMF does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m NMF(n_components\u001b[38;5;241m=\u001b[39mn_components, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2207\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_copy\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# User-feature matrix\u001b[39;00m\n\u001b[1;32m     14\u001b[0m Q \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcomponents_            \u001b[38;5;66;03m# Feature-item matrix\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Multiply P and Q to get the estimated ratings\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1588\u001b[0m, in \u001b[0;36mNMF.fit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1564\u001b[0m     \u001b[38;5;124;03m\"\"\"Learn a NMF model for the data X and returns the transformed data.\u001b[39;00m\n\u001b[1;32m   1565\u001b[0m \n\u001b[1;32m   1566\u001b[0m \u001b[38;5;124;03m    This is more efficient than calling fit followed by transform.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;124;03m        Transformed data.\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(assume_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1593\u001b[0m         W, H, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, W\u001b[38;5;241m=\u001b[39mW, H\u001b[38;5;241m=\u001b[39mH)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nNMF does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create a copy of the original ratings matrix (you should use a copy so as not to modify the original matrix)\n",
    "R_copy = R.copy()\n",
    "\n",
    "# Replace original zeros in R_copy with NaNs\n",
    "R_copy[R_copy == 0] = np.nan\n",
    "\n",
    "# Specify the number of components (you can experiment with different values)\n",
    "n_components = 10\n",
    "model = NMF(n_components=n_components, init='random', random_state=2207, max_iter=1000, alpha=0.01, l1_ratio=1.5, verbose=False)\n",
    "P = model.fit_transform(R_copy)  # User-feature matrix\n",
    "Q = model.components_            # Feature-item matrix\n",
    "\n",
    "# Multiply P and Q to get the estimated ratings\n",
    "R_estimated = np.dot(P, Q)\n",
    "\n",
    "# Create a mask for the missing values\n",
    "mask = np.isnan(R_copy)\n",
    "\n",
    "# Replace the original missing values with the predicted ratings\n",
    "R_predicted = R.copy()  # Create a copy to ensure that the original matrix is not modified\n",
    "R_predicted[mask] = R_estimated[mask]\n",
    "\n",
    "# Print the original and predicted ratings\n",
    "print(\"Original Ratings:\")\n",
    "print(R)\n",
    "\n",
    "print(\"\\nPredicted Ratings:\")\n",
    "print(R_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavansingh/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ratings:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Predicted Ratings:\n",
      "[[1.13756107e-05 1.97293066e-04 0.00000000e+00 ... 1.75846414e-01\n",
      "  1.80200509e-01 3.25668829e-03]\n",
      " [5.13774224e-03 1.35576910e-04 1.39125748e-04 ... 1.80595700e-02\n",
      "  1.84806670e-02 8.05029405e-03]\n",
      " [3.44309594e-03 3.36838948e-03 1.52714421e-02 ... 1.62260490e-03\n",
      "  0.00000000e+00 5.91030722e-03]\n",
      " ...\n",
      " [3.90118221e-07 2.51222987e-04 6.20551495e-04 ... 1.46281673e-04\n",
      "  1.16376849e-05 1.55002994e-03]\n",
      " [0.00000000e+00 2.96481398e-04 0.00000000e+00 ... 7.20876672e-02\n",
      "  7.38726141e-02 1.73037274e-03]\n",
      " [6.46961783e-02 2.17507721e-02 1.33368959e-01 ... 7.24586383e-04\n",
      "  2.20241253e-04 1.88555567e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Specify the number of components (you can experiment with different values)\n",
    "n_components = 10\n",
    "model = NMF(n_components=n_components, init='random', random_state=2207, max_iter=1000, alpha=0.01, l1_ratio=1.5, verbose=False)\n",
    "P = model.fit_transform(R)  # User-feature matrix\n",
    "Q = model.components_       # Feature-item matrix\n",
    "\n",
    "\n",
    "# Multiply A and B to get the estimated ratings\n",
    "R_estimated = np.dot(P, Q)\n",
    "\n",
    "# Replace original zeros in R with predicted ratings\n",
    "R_predicted = np.where(R == 0, R_estimated, R)\n",
    "\n",
    "# Print the original and predicted ratings\n",
    "print(\"Original Ratings:\")\n",
    "print(R)\n",
    "\n",
    "print(\"\\nPredicted Ratings:\")\n",
    "print(R_predicted)\n",
    "R_predicted = pd.DataFrame(R_predicted, columns=x_hidden.columns, index=x_hidden.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn\n",
      "Mean Absolute Error (MAE): 4.241243101668249\n",
      "Mean Squared Error (MSE): 18.985869875308374\n",
      "Root Mean Squared Error (RMSE): 4.35727780561538\n",
      "\n",
      "\n",
      "Manually\n",
      "Mean Absolute Error (MAE): 4.241243101668249\n",
      "Mean Squared Error (MSE): 18.985869875308374\n",
      "Root Mean Squared Error (RMSE): 4.35727780561538\n"
     ]
    }
   ],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(R_predicted.shape[0]):\n",
    "    user_predicted_ratings = R_predicted.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Suprise Test and Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatised_reviewText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>sentiments_afinn</th>\n",
       "      <th>sentiments_bing</th>\n",
       "      <th>sentiments_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>AQ8OO59DJFJNZ</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>wonder movi</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>wonderful movie</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>A244CRJ2QSVLZ4</td>\n",
       "      <td>2008-01-29</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>resident evil is a great science fictionhorror...</td>\n",
       "      <td>resid evil great scienc fictionhorror hybrid p...</td>\n",
       "      <td>resident evil great science fictionhorror hybr...</td>\n",
       "      <td>resident evil great science fictionhorror hybr...</td>\n",
       "      <td>-12</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>A1VCLTAGM5RLND</td>\n",
       "      <td>2005-07-23</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i this movie has people living and working und...</td>\n",
       "      <td>movi peopl live work underground place call hi...</td>\n",
       "      <td>movie people living working underground place ...</td>\n",
       "      <td>movie people living working underground place ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>A119Q9NFGVOEJZ</td>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>every single video game based movie from the s...</td>\n",
       "      <td>everi singl video game base movi super mario b...</td>\n",
       "      <td>every single video game based movie super mari...</td>\n",
       "      <td>every single video game based movie super mari...</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>A1RP6YCOS5VJ5I</td>\n",
       "      <td>2006-09-26</td>\n",
       "      <td>0767834739</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i think that i like this movie more than the o...</td>\n",
       "      <td>think like movi origin origin still great real...</td>\n",
       "      <td>think like movie original original still great...</td>\n",
       "      <td>think like movie original original still great...</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID  reviewTime        asin  overall  \\\n",
       "76   AQ8OO59DJFJNZ  2018-01-05  0767834739      5.0   \n",
       "78  A244CRJ2QSVLZ4  2008-01-29  0767834739      5.0   \n",
       "81  A1VCLTAGM5RLND  2005-07-23  0767834739      5.0   \n",
       "82  A119Q9NFGVOEJZ  2016-02-13  0767834739      5.0   \n",
       "83  A1RP6YCOS5VJ5I  2006-09-26  0767834739      5.0   \n",
       "\n",
       "                                           reviewText  \\\n",
       "76                                    wonderful movie   \n",
       "78  resident evil is a great science fictionhorror...   \n",
       "81  i this movie has people living and working und...   \n",
       "82  every single video game based movie from the s...   \n",
       "83  i think that i like this movie more than the o...   \n",
       "\n",
       "                                stemmed_words_revText  \\\n",
       "76                                        wonder movi   \n",
       "78  resid evil great scienc fictionhorror hybrid p...   \n",
       "81  movi peopl live work underground place call hi...   \n",
       "82  everi singl video game base movi super mario b...   \n",
       "83  think like movi origin origin still great real...   \n",
       "\n",
       "                                lemmatised_reviewText  \\\n",
       "76                                    wonderful movie   \n",
       "78  resident evil great science fictionhorror hybr...   \n",
       "81  movie people living working underground place ...   \n",
       "82  every single video game based movie super mari...   \n",
       "83  think like movie original original still great...   \n",
       "\n",
       "                              filtered_tokens_revText  sentiments_afinn  \\\n",
       "76                                    wonderful movie                 4   \n",
       "78  resident evil great science fictionhorror hybr...               -12   \n",
       "81  movie people living working underground place ...                -1   \n",
       "82  every single video game based movie super mari...                18   \n",
       "83  think like movie original original still great...                29   \n",
       "\n",
       "    sentiments_bing  sentiments_vader  \n",
       "76                1            0.5719  \n",
       "78               -5           -0.9455  \n",
       "81                0           -0.1806  \n",
       "82                6            0.9846  \n",
       "83               10            0.9951  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  83139\n",
      "Number of Columns:  11\n",
      "Number of Unique Users:  3668\n",
      "Number of Unique Products:  3249\n",
      "Fewest reviews by a reviewer: 13\n",
      "Most reviews by a reviewer: 193\n",
      "Fewest reviews per product: 13\n",
      "Most reviews per product: 189\n",
      "\n",
      "\n",
      "\n",
      "User-Item Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0767834739</th>\n",
       "      <th>7799146915</th>\n",
       "      <th>B00000DMAT</th>\n",
       "      <th>B00000DMAX</th>\n",
       "      <th>B00000DMB3</th>\n",
       "      <th>B00000F1GM</th>\n",
       "      <th>B00000I1BJ</th>\n",
       "      <th>B00000I1BY</th>\n",
       "      <th>B00000ID61</th>\n",
       "      <th>B00000INR2</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H353FLA</th>\n",
       "      <th>B01H353HUY</th>\n",
       "      <th>B01H3VFR6U</th>\n",
       "      <th>B01H5GB8ZW</th>\n",
       "      <th>B01H6OXQFS</th>\n",
       "      <th>B01H9SH2LU</th>\n",
       "      <th>B01HGBAFNC</th>\n",
       "      <th>B01HHVVLGQ</th>\n",
       "      <th>B01HHVWWMI</th>\n",
       "      <th>B01HIZF7XE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100RH4M1W1DF0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1027EV8A9PV1O</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A103KKI1Y4TFNQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1047P9FLHTDZJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            0767834739  7799146915  B00000DMAT  B00000DMAX  B00000DMB3  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B00000F1GM  B00000I1BJ  B00000I1BY  B00000ID61  B00000INR2  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            ...  B01H353FLA  B01H353HUY  B01H3VFR6U  B01H5GB8ZW  \\\n",
       "reviewerID      ...                                                   \n",
       "A100RH4M1W1DF0  ...         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1027EV8A9PV1O  ...         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ  ...         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01H6OXQFS  B01H9SH2LU  B01HGBAFNC  B01HHVVLGQ  B01HHVWWMI  \\\n",
       "reviewerID                                                                   \n",
       "A100RH4M1W1DF0         0.0         0.0         0.0         0.0         0.0   \n",
       "A100WO06OQR8BQ         0.0         0.0         5.0         0.0         0.0   \n",
       "A1027EV8A9PV1O         0.0         0.0         0.0         0.0         0.0   \n",
       "A103KKI1Y4TFNQ         0.0         0.0         0.0         0.0         0.0   \n",
       "A1047P9FLHTDZJ         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HIZF7XE  \n",
       "reviewerID                  \n",
       "A100RH4M1W1DF0         0.0  \n",
       "A100WO06OQR8BQ         0.0  \n",
       "A1027EV8A9PV1O         0.0  \n",
       "A103KKI1Y4TFNQ         0.0  \n",
       "A1047P9FLHTDZJ         0.0  \n",
       "\n",
       "[5 rows x 3249 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3668, 3249)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "# amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "amz_data = pd.read_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set4_data_modelling.csv\", index_col=0)\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hidden ratings matrix\n",
    "x_hidden = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/suprise_hidden_ratings_matrix.csv')\n",
    "\n",
    "# load testset indices\n",
    "testset_indices = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/suprise_testset_indices.csv')\n",
    "\n",
    "# convert to numpy\n",
    "testset_indices = testset_indices.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get predicted ratings for the testset\n",
    "predicted_ratings = []\n",
    "for i in range(len(testset_indices)):\n",
    "    user_id = testset_indices[i][0]\n",
    "    item_id = testset_indices[i][1]\n",
    "    predicted_ratings.append(predic_matrix.iloc[user_id, item_id])\n",
    "\n",
    "print(\"Predicted Ratings:\")\n",
    "print(predicted_ratings)\n",
    "\n",
    "# get actual ratings for the testset\n",
    "print(\"\\nActual Ratings:\")\n",
    "actual_ratings = testset_df[2].to_list()\n",
    "print(actual_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE, MSE and RMSE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "mse = mean_squared_error(actual_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.round(2)}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse.round(2)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.round(2)}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "\n",
    "# calculate MAE, MSE and RMSE using actual and predicted ratings\n",
    "mae = np.mean(np.abs(np.array(actual_ratings) - np.array(predicted_ratings))) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((np.array(actual_ratings) - np.array(predicted_ratings)) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.round(2)}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse.round(2)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "results = pd.DataFrame({'MAE': [mae.round(3)], 'MSE': [mse.round(3)], 'RMSE': [rmse.round(3)]})\n",
    "results.to_csv(\"Data/Results/NMF_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
