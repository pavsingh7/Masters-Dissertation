{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorisation\n",
    "\n",
    "## Algorithm Summary\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix. \n",
    "\n",
    "1. **Load the data**\n",
    "- data is provided in a dataframe where each row is a review\n",
    "\n",
    "2. **Create a user-item matrix**\n",
    "- convert dataframe into user-item matrix where each row is a user and each column is an item\n",
    "\n",
    "3. **Create test and train set**\n",
    "- hide $N$ ratings for each user in the training set and use them to test the performance of the model\n",
    "- Typically, a certain percentage of ratings for each user are masked in the training set and used for testing the model's performance.\n",
    "\n",
    "4. **Apply Non-negative Matrix Factorization (NMF)**\n",
    "\n",
    "    1.  Decompose the user-item interaction matrix into two non-negative matrices: a user matrix and an item matrix.\n",
    "    2. Minimize the reconstruction error between the original matrix and the product of the decomposed matrices using optimization techniques like gradient descent.\n",
    "\n",
    "5. **Make predictions**\n",
    "- For each user-item pair in the test set, predict the rating by reconstructing the original rating matrix using the decomposed user and item matrices.\n",
    "- The predicted rating is obtained by taking the dot product of the corresponding user and item latent factor vectors.\n",
    "\n",
    "6. **Evaluate the model**\n",
    "- Calculate the predictive accuracy of the model using various evaluation metrics such as Root Mean Squared Error (RMSE), Mean Squared Error (MSE), and Mean Absolute Error (MAE).\n",
    "- Additionally, assess the Top-N recommendation performance of the model using metrics like Normalized Discounted Cumulative Gain (NDCG) and Hit Rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manaul / From Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "display(amz_data.head())\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 3\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n",
    "\n",
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition, Optimisation and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of matrix factorization using stochastic gradient descent (SGD) for non-negative matrix factorization (NMF) is quite promising. Letâ€™s break down the key components:\n",
    "\n",
    "1. Initialization:\n",
    "- We initialize matrices P and Q with non-negative random values, which is appropriate for NMF.\n",
    "- The bias terms b_u and b_i are initialized to zeros, and the global bias b is calculated as the mean of non-zero elements in the input matrix R.\n",
    "\n",
    "2. Update Rules:\n",
    "- We use the SGD approach to update P and Q iteratively based on the error eij (difference between the actual rating and the predicted rating).\n",
    "- If use_regularization is enabled, We apply L2 regularization to the updates by adding a penalty term proportional to the current value of P and Q.\n",
    "- The bias terms b_u and b_i are also updated based on the error.\n",
    "\n",
    "3. Convergence Check:\n",
    "- We monitor the convergence by calculating the Frobenius norm of the difference between the original matrix R and the reconstructed matrix PQ^T.\n",
    "- If the difference falls below a threshold (0.001 in our case), the algorithm stops iterating.\n",
    "\n",
    "4. Bias Terms:\n",
    "- We correctly add the bias terms to the final prediction if use_bias is enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_sgd(R, K, steps=500, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    N, M = R.shape\n",
    "    P = np.abs(np.random.randn(N, K))  # Initialize with non-negative values\n",
    "    Q = np.abs(np.random.randn(M, K))\n",
    "\n",
    "    # Initialize bias terms\n",
    "    if use_bias:\n",
    "        b_u = np.zeros(N)\n",
    "        b_i = np.zeros(M)\n",
    "        b = np.mean(R[np.where(R != 0)])  # global bias\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[j, :])\n",
    "\n",
    "                    # Update P and Q\n",
    "                    for k in range(K):\n",
    "                        if use_regularization:\n",
    "                            P[i][k] += alpha * (2 * eij * Q[j][k] - beta * P[i][k])\n",
    "                            Q[j][k] += alpha * (2 * eij * P[i][k] - beta * Q[j][k])\n",
    "                        else:\n",
    "                            P[i][k] += alpha * (2 * eij * Q[j][k])\n",
    "                            Q[j][k] += alpha * (2 * eij * P[i][k])\n",
    "\n",
    "                    # Update bias terms\n",
    "                    if use_bias:\n",
    "                        b_u[i] += alpha * (eij - beta * b_u[i])\n",
    "                        b_i[j] += alpha * (eij - beta * b_i[j])\n",
    "\n",
    "        # Check for convergence within the loop\n",
    "        if np.sqrt(np.sum((R - np.dot(P, Q.T))**2)) < 0.001:\n",
    "            break\n",
    "\n",
    "    # Add bias terms to the prediction\n",
    "    if use_bias:\n",
    "        R_pred = np.dot(P, Q.T) + b + b_u[:, np.newaxis] + b_i[np.newaxis:,]  \n",
    "    else:\n",
    "        R_pred = np.dot(P, Q.T)\n",
    "\n",
    "    return P, Q, R_pred\n",
    "\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "R = np.random.randint(0, 6, size=(10, 5))\n",
    "nP, nQ, nR_pred = matrix_factorization_sgd(R, K=2, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True)\n",
    "print(\"Original Matrix:\")\n",
    "print(R)\n",
    "print(\"\\nReconstructed Matrix:\")\n",
    "print(nR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'K': [2, 3, 4],         # Number of latent features\n",
    "    'alpha': [0.001, 0.01], # Learning rate\n",
    "    'beta': [0.01, 0.02]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Create an instance of the GridSearchCV\n",
    "np.random.seed(42)\n",
    "grid_search = GridSearchCV(estimator=matrix_factorization_sgd, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(R)\n",
    "\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_K = grid_search.best_params_['K']\n",
    "best_beta = grid_search.best_params_['beta']\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "print(f\"Best K: {best_K}\")\n",
    "print(f\"Best beta: {best_beta}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Re-train the model with best hyperparameters\n",
    "best_model = matrix_factorization_sgd(R=x_hidden.values, K=best_K, alpha=best_beta, beta=best_beta,\n",
    "                                      use_regularization=True, use_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Predictive Accuracy)\n",
    "\n",
    "Now evaluate how good the predictions are vs the hidden ratings\n",
    "- ***step 1***: identify the hidden ratings indices\n",
    "- ***step 2***: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "- ***step 3***: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 2 decimal places\n",
    "mae = round(mae, 2)\n",
    "mse = round(mse, 2)\n",
    "rmse = round(rmse, 2)\n",
    "\n",
    "# Save the results to a csv file\n",
    "results = pd.DataFrame({'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "results.to_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\results_NMF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `use_regularization` parameter controls whether regularization (beta) is applied.\n",
    "- The `use_bias` parameter controls whether bias terms are included.\n",
    "- We use the `NMF` class from `Scikit-learn`, which handles the optimization process for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_nmf(R, K, steps=500, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True):\n",
    "    \"\"\"\n",
    "    Perform non-negative matrix factorization using scikit-learn's NMF.\n",
    "\n",
    "    Args:\n",
    "        R (numpy.ndarray): The input rating matrix.\n",
    "        K (int): Number of latent features.\n",
    "        steps (int): Maximum number of iterations.\n",
    "        alpha (float): Learning rate.\n",
    "        beta (float): Regularization parameter.\n",
    "        use_regularization (bool): Whether to use regularization.\n",
    "        use_bias (bool): Whether to use bias terms.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray, numpy.ndarray, numpy.ndarray: Factorized matrices P, Q, and the reconstructed matrix R_pred.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize NMF model\n",
    "    nmf_model = NMF(n_components=K, init='random', solver='cd', beta_loss='frobenius', max_iter=steps,\n",
    "                    alpha=alpha if use_regularization else 0.0, l1_ratio=beta if use_regularization else 0)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    nmf_model.fit(R)\n",
    "\n",
    "    # Get the transformed matrices\n",
    "    P = nmf_model.transform(R)\n",
    "    Q = nmf_model.components_\n",
    "\n",
    "    if use_bias:\n",
    "        b_u = np.zeros(P.shape[0])\n",
    "        b_i = np.zeros(Q.shape[1])\n",
    "        b = np.mean(R[np.where(R != 0)])\n",
    "\n",
    "        for _ in range(steps):\n",
    "            for i in range(P.shape[0]):\n",
    "                for j in range(Q.shape[1]):\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "\n",
    "                        P[i, :] += alpha * (2 * eij * Q[:, j] - beta * P[i, :])\n",
    "                        Q[:, j] += alpha * (2 * eij * P[i, :] - beta * Q[:, j])\n",
    "\n",
    "                        b_u[i] += alpha * (eij - beta * b_u[i])\n",
    "                        b_i[j] += alpha * (eij - beta * b_i[j])\n",
    "\n",
    "        R_pred = np.dot(P, Q) + b + b_u[:, np.newaxis] + b_i[np.newaxis:,]\n",
    "    else:\n",
    "        R_pred = np.dot(P, Q)\n",
    "\n",
    "    return P, Q, R_pred\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "nP, nQ, nR_pred = matrix_factorization_nmf(R, K=2, alpha=0.001, beta=0.02, use_regularization=True, use_bias=True)\n",
    "print(\"Original Matrix:\")\n",
    "print(R)\n",
    "print(\"\\nReconstructed Matrix:\")\n",
    "print(nR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'K': [2, 3, 4],         # Number of latent features\n",
    "    'alpha': [0.001, 0.01], # Learning rate\n",
    "    'beta': [0.01, 0.02]    # Regularization parameter\n",
    "}\n",
    "\n",
    "# Create an instance of the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=matrix_factorization_nmf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(R)\n",
    "\n",
    "# get params\n",
    "best_K = grid_search.best_params_['K']\n",
    "best_beta = grid_search.best_params_['beta']\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "print(f\"Best K: {best_K}\")\n",
    "print(f\"Best beta: {best_beta}\")\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "# Re-train the model with best hyperparameters\n",
    "best_model = matrix_factorization_nmf(R=x_hidden.values, K=best_K, alpha=best_beta, beta=best_beta,\n",
    "                                      use_regularization=True, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of matrix factorisation collaborative filtering. Specifically, we will be conducting non-negative matrix factorisation (NMF) and alternating least squares (ALS) matrix factorisation. We will be using the sample data created. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Factorise the matrix - *either NMF or ALS or even SVD*\n",
    "4. Predict the hidden ratings - fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings\n",
    "9. Calculate classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation w/SGD\n",
    "\n",
    "- Matrix Factorization is a general technique used in collaborative filtering and other applications where a matrix is decomposed into the product of two lower-rank matrices.\n",
    "- Stochastic Gradient Descent is an optimization algorithm commonly used to minimize the error in the factorization process.\n",
    "\n",
    "- The key idea is to iteratively update the elements of the factorized matrices using the gradient of the error with respect to the elements.\n",
    "\n",
    "**Algorithm Process**:\n",
    "\n",
    "1. ***Convert the data into a matrix:*** Represent users, items, and ratings in a matrix where rows correspond to users, columns correspond to items, and values represent ratings.\n",
    "\n",
    "2. ***Hide some ratings for testing:*** Randomly select a subset of ratings to be used as a test set to evaluate the performance of our collaborative filtering algorithm.\n",
    "\n",
    "3. ***Decompose the matrix using SGD:*** Decompose the original matrix into two matrices - one representing users and latent features (user matrix) and the other representing items and latent features (item matrix).\n",
    "\n",
    "4. ***Reconstruct the original matrix:*** Take the dot product of the user and item matrices obtained from step 3 to reconstruct the original matrix.\n",
    "\n",
    "5. ***Make predictions using the reconstructed matrix:*** Use the reconstructed matrix to predict the ratings for the items that were hidden in the test set. These predictions will be our estimated ratings.\n",
    "\n",
    "6. ***Evaluate the performance of the algorithm:*** Compare the predicted ratings to the actual ratings in the test set to evaluate the accuracy and effectiveness of your collaborative filtering algorithm. Common evaluation metrics include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), or other relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # we can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix factorization using stochastic gradient descent\n",
    "def matrix_factorization_sgd(R, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    # Initialize user and item latent feature matrices\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # apply stochastic gradient descent to update P and Q\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "        # apply regularization to prevent overfitting\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        # set threshold for error rate\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "# apply matrix factorization using stochastic gradient descent\n",
    "nP, nQ = matrix_factorization_sgd(R=x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS)\n",
    "\n",
    "The main difference is in the optimization method used to decompose the matrix. Instead of using NMF, you use the ALS algorithm.\n",
    "\n",
    "**Algorithm Process**:\n",
    "\n",
    "***Convert the data into a matrix:*** Same as in NMF, represent users, items, and ratings in a matrix.\n",
    "\n",
    "***Hide some ratings for testing:*** Randomly select a subset of ratings to be used as a test set.\n",
    "\n",
    "***Decompose the matrix using ALS:*** Utilize an ALS algorithm to iteratively update the user and item matrices until convergence. We may need to define hyperparameters such as the number of latent features and regularization terms.\n",
    "\n",
    "***Reconstruct the original matrix:*** Combine the user and item matrices obtained from the ALS optimization to reconstruct the original matrix.\n",
    "\n",
    "***Make predictions using the reconstructed matrix:*** Use the reconstructed matrix to predict the ratings for the items that were hidden in the test set.\n",
    "\n",
    "***Evaluate the performance of the algorithm:*** Compare the predicted ratings to the actual ratings in the test set to evaluate the accuracy and effectiveness of your collaborative filtering algorithm. Use appropriate evaluation metrics such as MSE, RMSE, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "\n",
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n",
    "\n",
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_als(R, K, steps=5000, alpha=0.0001, reg_param=0.001):\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K) * 0.01\n",
    "    Q = np.random.rand(M, K) * 0.01\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                    P_norm = np.linalg.norm(P[i, :], 2)\n",
    "                    Q_norm = np.linalg.norm(Q[j, :], 2)\n",
    "                    P[i, :] = P[i, :] + alpha * (2 * eij * Q[j, :] - reg_param * P_norm)\n",
    "                    Q[j, :] = Q[j, :] + alpha * (2 * eij * P[i, :] - reg_param * Q_norm)\n",
    "\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[j, :].T), 2)\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "# apply matrix factorization using alternating least squares\n",
    "nP, nQ = matrix_factorization_als(R = x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"\\nRATINGS PREDICTION PROBLEM\\nUsing sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\\nBINARISED or CLASSIFICATION PROBLEM\")\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
