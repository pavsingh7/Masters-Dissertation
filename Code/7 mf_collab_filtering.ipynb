{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorisation\n",
    "\n",
    "## Algorithm Summary\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommender systems. Matrix factorization algorithms work by decomposing the user-item interaction matrix. \n",
    "\n",
    "1. **Load the data**\n",
    "- data is provided in a dataframe where each row is a review\n",
    "\n",
    "2. **Create a user-item matrix**\n",
    "- convert dataframe into user-item matrix where each row is a user and each column is an item\n",
    "\n",
    "3. **Create test and train set**\n",
    "- hide $N$ ratings for each user in the training set and use them to test the performance of the model\n",
    "- Typically, a certain percentage of ratings for each user are masked in the training set and used for testing the model's performance.\n",
    "\n",
    "4. **Apply Non-negative Matrix Factorization (NMF)**\n",
    "\n",
    "    1.  Decompose the user-item interaction matrix into two non-negative matrices: a user matrix and an item matrix.\n",
    "    2. Minimize the reconstruction error between the original matrix and the product of the decomposed matrices using optimization techniques like gradient descent.\n",
    "\n",
    "5. **Make predictions**\n",
    "- For each user-item pair in the test set, predict the rating by reconstructing the original rating matrix using the decomposed user and item matrices.\n",
    "- The predicted rating is obtained by taking the dot product of the corresponding user and item latent factor vectors.\n",
    "\n",
    "6. **Evaluate the model**\n",
    "- Calculate the predictive accuracy of the model using various evaluation metrics such as Root Mean Squared Error (RMSE), Mean Squared Error (MSE), and Mean Absolute Error (MAE).\n",
    "- Additionally, assess the Top-N recommendation performance of the model using metrics like Normalized Discounted Cumulative Gain (NDCG) and Hit Rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manaul / From Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "display(amz_data.head())\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 3\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n",
    "\n",
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition, Optimisation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix factorization using stochastic gradient descent\n",
    "def matrix_factorization_sgd(R, K, steps=500, alpha=0.001, beta=0.02):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    # Initialize user and item latent feature matrices\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # apply stochastic gradient descent to update P and Q\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "        # apply regularization to prevent overfitting\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        # set threshold for error rate\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "# apply matrix factorization using stochastic gradient descent\n",
    "nP, nQ = matrix_factorization_sgd(R=x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Predictive Accuracy)\n",
    "\n",
    "Now evaluate how good the predictions are vs the hidden ratings\n",
    "- ***step 1***: identify the hidden ratings indices\n",
    "- ***step 2***: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "- ***step 3***: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 2 decimal places\n",
    "mae = round(mae, 2)\n",
    "mse = round(mse, 2)\n",
    "rmse = round(rmse, 2)\n",
    "\n",
    "# Save the results to a csv file\n",
    "results = pd.DataFrame({'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "results.to_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\results_IBCF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of matrix factorisation collaborative filtering. Specifically, we will be conducting non-negative matrix factorisation (NMF) and alternating least squares (ALS) matrix factorisation. We will be using the sample data created. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Factorise the matrix - *either NMF or ALS or even SVD*\n",
    "4. Predict the hidden ratings - fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings\n",
    "9. Calculate classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation w/SGD\n",
    "\n",
    "- Matrix Factorization is a general technique used in collaborative filtering and other applications where a matrix is decomposed into the product of two lower-rank matrices.\n",
    "- Stochastic Gradient Descent is an optimization algorithm commonly used to minimize the error in the factorization process.\n",
    "\n",
    "- The key idea is to iteratively update the elements of the factorized matrices using the gradient of the error with respect to the elements.\n",
    "\n",
    "**Algorithm Process**:\n",
    "\n",
    "1. ***Convert the data into a matrix:*** Represent users, items, and ratings in a matrix where rows correspond to users, columns correspond to items, and values represent ratings.\n",
    "\n",
    "2. ***Hide some ratings for testing:*** Randomly select a subset of ratings to be used as a test set to evaluate the performance of your collaborative filtering algorithm.\n",
    "\n",
    "3. ***Decompose the matrix using SGD:*** Decompose the original matrix into two matrices - one representing users and latent features (user matrix) and the other representing items and latent features (item matrix).\n",
    "\n",
    "4. ***Reconstruct the original matrix:*** Take the dot product of the user and item matrices obtained from step 3 to reconstruct the original matrix.\n",
    "\n",
    "5. ***Make predictions using the reconstructed matrix:*** Use the reconstructed matrix to predict the ratings for the items that were hidden in the test set. These predictions will be your estimated ratings.\n",
    "\n",
    "6. ***Evaluate the performance of the algorithm:*** Compare the predicted ratings to the actual ratings in the test set to evaluate the accuracy and effectiveness of your collaborative filtering algorithm. Common evaluation metrics include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), or other relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix factorization using stochastic gradient descent\n",
    "def matrix_factorization_sgd(R, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    # R = user-item ratings matrix\n",
    "    # K = number of latent features\n",
    "    # steps = number of iterations\n",
    "    # alpha = learning rate\n",
    "    # beta = regularization parameter\n",
    "\n",
    "    # Initialize user and item latent feature matrices\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K)\n",
    "    Q = np.random.rand(M, K)\n",
    "    Q = Q.T\n",
    "    \n",
    "    # apply stochastic gradient descent to update P and Q\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "        # apply regularization to prevent overfitting\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        # set threshold for error rate\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "# apply matrix factorization using stochastic gradient descent\n",
    "nP, nQ = matrix_factorization_sgd(R=x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS)\n",
    "\n",
    "The main difference is in the optimization method used to decompose the matrix. Instead of using NMF, you use the ALS algorithm.\n",
    "\n",
    "**Algorithm Process**:\n",
    "\n",
    "***Convert the data into a matrix:*** Same as in NMF, represent users, items, and ratings in a matrix.\n",
    "\n",
    "***Hide some ratings for testing:*** Randomly select a subset of ratings to be used as a test set.\n",
    "\n",
    "***Decompose the matrix using ALS:*** Utilize an ALS algorithm to iteratively update the user and item matrices until convergence. You may need to define hyperparameters such as the number of latent features and regularization terms.\n",
    "\n",
    "***Reconstruct the original matrix:*** Combine the user and item matrices obtained from the ALS optimization to reconstruct the original matrix.\n",
    "\n",
    "***Make predictions using the reconstructed matrix:*** Use the reconstructed matrix to predict the ratings for the items that were hidden in the test set.\n",
    "\n",
    "***Evaluate the performance of the algorithm:*** Compare the predicted ratings to the actual ratings in the test set to evaluate the accuracy and effectiveness of your collaborative filtering algorithm. Use appropriate evaluation metrics such as MSE, RMSE, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "\n",
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n",
    "\n",
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_als(R, K, steps=5000, alpha=0.0001, reg_param=0.001):\n",
    "    N, M = R.shape\n",
    "    P = np.random.rand(N, K) * 0.01\n",
    "    Q = np.random.rand(M, K) * 0.01\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                    P_norm = np.linalg.norm(P[i, :], 2)\n",
    "                    Q_norm = np.linalg.norm(Q[j, :], 2)\n",
    "                    P[i, :] = P[i, :] + alpha * (2 * eij * Q[j, :] - reg_param * P_norm)\n",
    "                    Q[j, :] = Q[j, :] + alpha * (2 * eij * P[i, :] - reg_param * Q_norm)\n",
    "\n",
    "        e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[j, :].T), 2)\n",
    "        if e < 0.001:\n",
    "            break\n",
    "\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "# apply matrix factorization using alternating least squares\n",
    "nP, nQ = matrix_factorization_als(R = x_hidden.values, K=2)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# view reconstructed matrix\n",
    "print(\"Reconstructed Matrix\")\n",
    "nR = pd.DataFrame(nR, index=x_hidden.index, columns=x_hidden.columns)\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(nR.shape[0]):\n",
    "    user_predicted_ratings = nR.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"\\nRATINGS PREDICTION PROBLEM\\nUsing sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\\nBINARISED or CLASSIFICATION PROBLEM\")\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
