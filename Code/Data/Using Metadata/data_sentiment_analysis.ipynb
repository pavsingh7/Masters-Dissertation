{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "# <a id='toc5_'></a>[Sentiment Analysis](#toc0_)\n",
    "\n",
    "We perform sentiment analysis on the reviewText column. We conduct one types of sentiment analysis: \n",
    "\n",
    "1. Sentiment Analysis using Lexicon-based Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from csv file\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_rev_cleaned.csv')\n",
    "\n",
    "# read in sample file\n",
    "#amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_rev_sample.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category_x</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>stemmed_words_desc</th>\n",
       "      <th>lemmatized_words_desc</th>\n",
       "      <th>filtered_tokens_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>John Bennett</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>0001526863</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>steve green</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>movies and tv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['product', 'work', 'advertis', 'pleas', 'resu...</td>\n",
       "      <td>['product', 'worked', 'advertised', 'pleased',...</td>\n",
       "      <td>['product', 'worked', 'advertised', 'pleased',...</td>\n",
       "      <td>['steve', 'green', 'hide', 'em', 'heart', '13'...</td>\n",
       "      <td>['steve', 'green', 'hide', 'em', 'heart', '13'...</td>\n",
       "      <td>['steve', 'green', 'hide', 'em', 'heart', '13'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>samson</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>christmas eve and other stories</td>\n",
       "      <td>trans siberian orchestra</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>cds and vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nice', 'hear', 'cd', 'beauti']</td>\n",
       "      <td>['nice', 'hear', 'cd', 'beautiful']</td>\n",
       "      <td>['nice', 'hear', 'cd', 'beautiful']</td>\n",
       "      <td>['concept', 'album', 'way', 'tale', 'christma'...</td>\n",
       "      <td>['concept', 'album', 'way', 'tale', 'christmas...</td>\n",
       "      <td>['concept', 'album', 'way', 'tales', 'christma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>2001-04-24</td>\n",
       "      <td>0005465079</td>\n",
       "      <td>forgiven</td>\n",
       "      <td>don francisco</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>cds and vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['one', 'song', 'one', 'best', 'ccm', 'tell', ...</td>\n",
       "      <td>['one', 'song', 'one', 'best', 'ccm', 'tell', ...</td>\n",
       "      <td>['one', 'song', 'one', 'best', 'ccm', 'tells',...</td>\n",
       "      <td>['1', 'jesu', 'lord', 'way', 'feel', '2', 'jeh...</td>\n",
       "      <td>['1', 'jesus', 'lord', 'way', 'feel', '2', 'je...</td>\n",
       "      <td>['1', 'jesus', 'lord', 'way', 'feel', '2', 'je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>sj</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>0307142493</td>\n",
       "      <td>santa claus is comin to town vhs</td>\n",
       "      <td>fred astaire</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>movies and tv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['love', 'older', 'movi', 'realli', 'classic',...</td>\n",
       "      <td>['love', 'older', 'movie', 'really', 'classic'...</td>\n",
       "      <td>['love', 'older', 'movies', 'really', 'classic...</td>\n",
       "      <td>['vh', 'movi', 'santa', 'clau', 'comin', 'town...</td>\n",
       "      <td>['vhs', 'movie', 'santa', 'claus', 'comin', 't...</td>\n",
       "      <td>['vhs', 'movie', 'santa', 'claus', 'comin', 't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  reviewTime        asin  \\\n",
       "0    A3WJELEV137U     John Bennett  2015-06-05  0001526863   \n",
       "1  A3OJM6TXMK3J53           samson  2015-12-05  0005164885   \n",
       "2  A14YR7QK3ASFFW  Amazon Customer  2001-04-24  0005465079   \n",
       "3  A1VE933MFXTG18               sj  2016-02-21  0307142493   \n",
       "\n",
       "                                               title  \\\n",
       "0  steve green hide em in your heart 13 bible mem...   \n",
       "1                    christmas eve and other stories   \n",
       "2                                           forgiven   \n",
       "3                   santa claus is comin to town vhs   \n",
       "\n",
       "                      brand  \\\n",
       "0               steve green   \n",
       "1  trans siberian orchestra   \n",
       "2             don francisco   \n",
       "3              fred astaire   \n",
       "\n",
       "                                         description  \\\n",
       "0  steve green hide em in your heart 13 bible mem...   \n",
       "1  this is a concept album all the way with tales...   \n",
       "2  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText     category_x  overall  \\\n",
       "0  product worked as advertised and am pleased wi...  movies and tv      5.0   \n",
       "1                     nice to hear this cd beautiful  cds and vinyl      5.0   \n",
       "2  that one song has to be one of the best in ccm...  cds and vinyl      5.0   \n",
       "3  i just love these older movies they really are...  movies and tv      5.0   \n",
       "\n",
       "   normalized_rating                              stemmed_words_revText  \\\n",
       "0                1.0  ['product', 'work', 'advertis', 'pleas', 'resu...   \n",
       "1                1.0                   ['nice', 'hear', 'cd', 'beauti']   \n",
       "2                1.0  ['one', 'song', 'one', 'best', 'ccm', 'tell', ...   \n",
       "3                1.0  ['love', 'older', 'movi', 'realli', 'classic',...   \n",
       "\n",
       "                            lemmatized_words_revText  \\\n",
       "0  ['product', 'worked', 'advertised', 'pleased',...   \n",
       "1                ['nice', 'hear', 'cd', 'beautiful']   \n",
       "2  ['one', 'song', 'one', 'best', 'ccm', 'tell', ...   \n",
       "3  ['love', 'older', 'movie', 'really', 'classic'...   \n",
       "\n",
       "                             filtered_tokens_revText  \\\n",
       "0  ['product', 'worked', 'advertised', 'pleased',...   \n",
       "1                ['nice', 'hear', 'cd', 'beautiful']   \n",
       "2  ['one', 'song', 'one', 'best', 'ccm', 'tells',...   \n",
       "3  ['love', 'older', 'movies', 'really', 'classic...   \n",
       "\n",
       "                                  stemmed_words_desc  \\\n",
       "0  ['steve', 'green', 'hide', 'em', 'heart', '13'...   \n",
       "1  ['concept', 'album', 'way', 'tale', 'christma'...   \n",
       "2  ['1', 'jesu', 'lord', 'way', 'feel', '2', 'jeh...   \n",
       "3  ['vh', 'movi', 'santa', 'clau', 'comin', 'town...   \n",
       "\n",
       "                               lemmatized_words_desc  \\\n",
       "0  ['steve', 'green', 'hide', 'em', 'heart', '13'...   \n",
       "1  ['concept', 'album', 'way', 'tale', 'christmas...   \n",
       "2  ['1', 'jesus', 'lord', 'way', 'feel', '2', 'je...   \n",
       "3  ['vhs', 'movie', 'santa', 'claus', 'comin', 't...   \n",
       "\n",
       "                                filtered_tokens_desc  \n",
       "0  ['steve', 'green', 'hide', 'em', 'heart', '13'...  \n",
       "1  ['concept', 'album', 'way', 'tales', 'christma...  \n",
       "2  ['1', 'jesus', 'lord', 'way', 'feel', '2', 'je...  \n",
       "3  ['vhs', 'movie', 'santa', 'claus', 'comin', 't...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data\n",
    "amz_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data => (496219, 17)\n",
      "Number of unique products => 251615\n",
      "Number of unique users => 339625\n"
     ]
    }
   ],
   "source": [
    "# data summary\n",
    "print(\"Shape of data =>\", amz_data.shape)\n",
    "print(\"Number of unique products =>\", amz_data['asin'].nunique())\n",
    "print(\"Number of unique users =>\", amz_data['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category_x</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>stemmed_words_desc</th>\n",
       "      <th>lemmatized_words_desc</th>\n",
       "      <th>filtered_tokens_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>John Bennett</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>0001526863</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>steve green</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>movies and tv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[product, work, advertis, pleas, result]</td>\n",
       "      <td>[product, worked, advertised, pleased, result]</td>\n",
       "      <td>[product, worked, advertised, pleased, results]</td>\n",
       "      <td>[steve, green, hide, em, heart, 13, bibl, memo...</td>\n",
       "      <td>[steve, green, hide, em, heart, 13, bible, mem...</td>\n",
       "      <td>[steve, green, hide, em, heart, 13, bible, mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>samson</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>christmas eve and other stories</td>\n",
       "      <td>trans siberian orchestra</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>cds and vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[nice, hear, cd, beauti]</td>\n",
       "      <td>[nice, hear, cd, beautiful]</td>\n",
       "      <td>[nice, hear, cd, beautiful]</td>\n",
       "      <td>[concept, album, way, tale, christma, kind, in...</td>\n",
       "      <td>[concept, album, way, tale, christmas, kindnes...</td>\n",
       "      <td>[concept, album, way, tales, christmas, kindne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>2001-04-24</td>\n",
       "      <td>0005465079</td>\n",
       "      <td>forgiven</td>\n",
       "      <td>don francisco</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>cds and vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[one, song, one, best, ccm, tell, stori, resur...</td>\n",
       "      <td>[one, song, one, best, ccm, tell, story, resur...</td>\n",
       "      <td>[one, song, one, best, ccm, tells, story, resu...</td>\n",
       "      <td>[1, jesu, lord, way, feel, 2, jehoshaphat, 3, ...</td>\n",
       "      <td>[1, jesus, lord, way, feel, 2, jehoshaphat, 3,...</td>\n",
       "      <td>[1, jesus, lord, way, feel, 2, jehoshaphat, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>sj</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>0307142493</td>\n",
       "      <td>santa claus is comin to town vhs</td>\n",
       "      <td>fred astaire</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>movies and tv</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[love, older, movi, realli, classic, share, yo...</td>\n",
       "      <td>[love, older, movie, really, classic, sharing,...</td>\n",
       "      <td>[love, older, movies, really, classics, sharin...</td>\n",
       "      <td>[vh, movi, santa, clau, comin, town, origin, c...</td>\n",
       "      <td>[vhs, movie, santa, claus, comin, town, origin...</td>\n",
       "      <td>[vhs, movie, santa, claus, comin, town, origin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     reviewerName  reviewTime        asin  \\\n",
       "0    A3WJELEV137U     John Bennett  2015-06-05  0001526863   \n",
       "1  A3OJM6TXMK3J53           samson  2015-12-05  0005164885   \n",
       "2  A14YR7QK3ASFFW  Amazon Customer  2001-04-24  0005465079   \n",
       "3  A1VE933MFXTG18               sj  2016-02-21  0307142493   \n",
       "\n",
       "                                               title  \\\n",
       "0  steve green hide em in your heart 13 bible mem...   \n",
       "1                    christmas eve and other stories   \n",
       "2                                           forgiven   \n",
       "3                   santa claus is comin to town vhs   \n",
       "\n",
       "                      brand  \\\n",
       "0               steve green   \n",
       "1  trans siberian orchestra   \n",
       "2             don francisco   \n",
       "3              fred astaire   \n",
       "\n",
       "                                         description  \\\n",
       "0  steve green hide em in your heart 13 bible mem...   \n",
       "1  this is a concept album all the way with tales...   \n",
       "2  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText     category_x  overall  \\\n",
       "0  product worked as advertised and am pleased wi...  movies and tv      5.0   \n",
       "1                     nice to hear this cd beautiful  cds and vinyl      5.0   \n",
       "2  that one song has to be one of the best in ccm...  cds and vinyl      5.0   \n",
       "3  i just love these older movies they really are...  movies and tv      5.0   \n",
       "\n",
       "   normalized_rating                              stemmed_words_revText  \\\n",
       "0                1.0           [product, work, advertis, pleas, result]   \n",
       "1                1.0                           [nice, hear, cd, beauti]   \n",
       "2                1.0  [one, song, one, best, ccm, tell, stori, resur...   \n",
       "3                1.0  [love, older, movi, realli, classic, share, yo...   \n",
       "\n",
       "                            lemmatized_words_revText  \\\n",
       "0     [product, worked, advertised, pleased, result]   \n",
       "1                        [nice, hear, cd, beautiful]   \n",
       "2  [one, song, one, best, ccm, tell, story, resur...   \n",
       "3  [love, older, movie, really, classic, sharing,...   \n",
       "\n",
       "                             filtered_tokens_revText  \\\n",
       "0    [product, worked, advertised, pleased, results]   \n",
       "1                        [nice, hear, cd, beautiful]   \n",
       "2  [one, song, one, best, ccm, tells, story, resu...   \n",
       "3  [love, older, movies, really, classics, sharin...   \n",
       "\n",
       "                                  stemmed_words_desc  \\\n",
       "0  [steve, green, hide, em, heart, 13, bibl, memo...   \n",
       "1  [concept, album, way, tale, christma, kind, in...   \n",
       "2  [1, jesu, lord, way, feel, 2, jehoshaphat, 3, ...   \n",
       "3  [vh, movi, santa, clau, comin, town, origin, c...   \n",
       "\n",
       "                               lemmatized_words_desc  \\\n",
       "0  [steve, green, hide, em, heart, 13, bible, mem...   \n",
       "1  [concept, album, way, tale, christmas, kindnes...   \n",
       "2  [1, jesus, lord, way, feel, 2, jehoshaphat, 3,...   \n",
       "3  [vhs, movie, santa, claus, comin, town, origin...   \n",
       "\n",
       "                                filtered_tokens_desc  \n",
       "0  [steve, green, hide, em, heart, 13, bible, mem...  \n",
       "1  [concept, album, way, tales, christmas, kindne...  \n",
       "2  [1, jesus, lord, way, feel, 2, jehoshaphat, 3,...  \n",
       "3  [vhs, movie, santa, claus, comin, town, origin...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "# Change to list of words for: filtered_tokens_revText\n",
    "amz_data['filtered_tokens_revText'] = amz_data['filtered_tokens_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: stemmed_words_revText\n",
    "amz_data['stemmed_words_revText'] = amz_data['stemmed_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: lemmatized_words_revText\n",
    "amz_data['lemmatized_words_revText'] = amz_data['lemmatized_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: stemmed_words_desc\n",
    "amz_data['stemmed_words_desc'] = amz_data['stemmed_words_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: lemmatized_words_desc\n",
    "amz_data['lemmatized_words_desc'] = amz_data['lemmatized_words_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: filtered_tokens_desc\n",
    "amz_data['filtered_tokens_desc'] = amz_data['filtered_tokens_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# view data\n",
    "amz_data.head(4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc5_1_'></a>[Sentiment Analysis using Lexicon-based Methods](#toc0_)\n",
    "\n",
    "First we use lexicon-based methods to perform sentiment analysis. Lexicon-based methods use a lexicon, or a collection of words and phrases associated with emotions, to assign sentiment scores to a body of text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[VADER](#toc0_)\n",
    "\n",
    "We use the VADER (Valence Aware Dictionary and Sentiment Reasoner) lexicon to perform sentiment analysis on the reviewText column. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "VADER utilizes a sentiment lexicon containing words with sentiment scores. However, VADER goes beyond simply assigning positive or negative labels to words. It considers the intensity of sentiment and incorporates linguistic rules to handle negations, intensifiers, and other linguistic features. This makes VADER particularly suitable for analyzing sentiment in social media text, where linguistic nuances and context play a significant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/pavansingh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# instance of the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through tokenized reviews and analyze the sentiment for each one\n",
    "sentiments_vader_revText = []\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):  # Check if the review is a string\n",
    "        sentiment = sia.polarity_scores(review)\n",
    "    else:\n",
    "        sentiment = sia.polarity_scores('')  # Replace NaN with an empty string\n",
    "    sentiments_vader_revText.append(sentiment)\n",
    "\n",
    "# store the sentiment scores in the dataframe\n",
    "amz_data['sentiments_vader_revText'] = sentiments_vader_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404},\n",
       "       {'neg': 0.0, 'neu': 0.374, 'pos': 0.626, 'compound': 0.7717},\n",
       "       {'neg': 0.058, 'neu': 0.803, 'pos': 0.139, 'compound': 0.7645},\n",
       "       {'neg': 0.034, 'neu': 0.663, 'pos': 0.303, 'compound': 0.9954}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some results\n",
    "amz_data.sentiments_vader_revText.head(4).values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy array containing sentiment analysis results. Each element in the array represents the sentiment scores for a single review. These sentiment scores are generated by VADER (Valence Aware Dictionary and sEntiment Reasoner), which is a popular rule-based model used for sentiment analysis. The scores are typically between -1 and 1, where values closer to 1 indicate more positive sentiment, values closer to -1 indicate more negative sentiment, and values around 0 indicate neutral sentiment. The compound score represents an overall sentiment intensity, combining the individual sentiment scores. The compound score in VADER sentiment analysis typically varies between -1 and 1. A compound score of 1 indicates extremely positive sentiment, while a score of -1 indicates extremely negative sentiment. Scores close to 0 represent more neutral or balanced sentiment.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiments_vader_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.374, 'pos': 0.626, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.058, 'neu': 0.803, 'pos': 0.139, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.663, 'pos': 0.303, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "                            sentiments_vader_revText  \n",
       "0  {'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'comp...  \n",
       "1  {'neg': 0.0, 'neu': 0.374, 'pos': 0.626, 'comp...  \n",
       "2  {'neg': 0.058, 'neu': 0.803, 'pos': 0.139, 'co...  \n",
       "3  {'neg': 0.034, 'neu': 0.663, 'pos': 0.303, 'co...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see dataframe\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall', 'sentiments_vader_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_2_'></a>[TextBlob](#toc0_)\n",
    "\n",
    "We also use the TextBlob library to perform sentiment analysis on the reviewText column. TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob is built on top of NLTK and Pattern and provides an easy-to-use interface to the NLTK library. We use the sentiment analysis functionality of TextBlob to calculate the polarity and subjectivity scores for each review in the reviewText column. \n",
    "\n",
    "TextBlob's sentiment analysis algorithm is based on a pre-trained model that has been trained on a large dataset. The model uses a combination of linguistic rules, pattern matching, and machine learning techniques like Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiments_textblob_revText = []\n",
    "subjectivities_textblob_revText = []\n",
    "\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):\n",
    "        blob = TextBlob(review)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "    else:\n",
    "        blob = TextBlob('')\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    sentiments_textblob_revText.append(sentiment)\n",
    "    subjectivities_textblob_revText.append(subjectivity)\n",
    "\n",
    "amz_data['sentiments_textblob_revText'] = sentiments_textblob_revText\n",
    "amz_data['subjectivities_textblob_revText'] = subjectivities_textblob_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.725      0.36194444 0.31653376]\n",
      "[1.         1.         0.43527778 0.57597023]\n"
     ]
    }
   ],
   "source": [
    "# see some results - sentiment\n",
    "print(amz_data.sentiments_textblob_revText.head(4).values)\n",
    "\n",
    "# see some results - subjectivity\n",
    "print(amz_data.subjectivities_textblob_revText.head(4).values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob's sentiment analysis is based on a machine learning algorithm trained on a large dataset of labeled data. The algorithm learns patterns and linguistic features from the data to classify text into different sentiment categories, such as positive, negative, or neutral.\n",
    "\n",
    "**Polarity**: It indicates the sentiment of the text on a scale from -1 to 1. A polarity score close to -1 indicates negative sentiment, a score close to 1 indicates positive sentiment, and a score around 0 indicates neutral sentiment.\n",
    "\n",
    "**Subjectivity**: It measures the subjectivity of the text on a scale from 0 to 1. A subjectivity score of 0 means the text is objective and factual, while a score of 1 means the text is highly subjective and opinionated.\n",
    "\n",
    "**TextBlob uses a trained model to analyze the sentiment of the input text based on the learned patterns and features. It takes into account not only individual words but also the context and grammar of the text.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc5_1_3_'></a>[Bing, AFINN, and NRC](#toc0_)\n",
    "\n",
    "The BING lexicon, for example, classifies words as either positive or negative. bing assigns a numerical sentiment score to words, where a positive score indicates positive sentiment and a negative score indicates negative sentiment. NRC extends this approach by providing a more comprehensive list of words and associating them with multiple sentiment dimensions, such as anger, joy, fear, etc.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of AFINN: (2477, 2)\n",
      "Unique Sentiments: [-2 -3  2  1 -1  3  4 -4 -5  5  0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  value\n",
       "0    abandon     -2\n",
       "1  abandoned     -2\n",
       "2   abandons     -2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read lexicons in\n",
    "afinn = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/Afinn.csv')\n",
    "\n",
    "# AFINN\n",
    "print(\"Shape of AFINN:\", afinn.shape)\n",
    "print(\"Unique Sentiments:\", afinn.value.unique())\n",
    "display(afinn.head(3))\n",
    "afinn_dict = dict(zip(afinn['word'], afinn['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each description using AFINN\n",
    "sentiment_scores_afinn = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    sentiment_score = sum(afinn_dict.get(word, 0) for word in review_tokens)\n",
    "    sentiment_scores_afinn.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_afinn_desc'] = sentiment_scores_afinn\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using AFINN\n",
    "sentiment_scores_afinn = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(afinn_dict.get(word, 0) for word in review_tokens)\n",
    "    sentiment_scores_afinn.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_afinn_revText'] = sentiment_scores_afinn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_afinn_desc</th>\n",
       "      <th>sentiment_score_afinn_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_afinn_desc  sentiment_score_afinn_revText  \n",
       "0                          -1                              3  \n",
       "1                           4                              6  \n",
       "2                           2                              4  \n",
       "3                           1                             24  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_afinn_desc', 'sentiment_score_afinn_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bing: (6786, 2)\n",
      "Unique Sentiments: ['negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faces</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abolish</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word sentiment\n",
       "0     faces  negative\n",
       "1  abnormal  negative\n",
       "2   abolish  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in \n",
    "bing = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/Bing.csv')\n",
    "\n",
    "# BING\n",
    "print(\"Shape of Bing:\", bing.shape)\n",
    "print(\"Unique Sentiments:\", bing.sentiment.unique())\n",
    "display(bing.head(3))\n",
    "bing_dict = dict(zip(bing['word'], bing['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each description using bing\n",
    "sentiment_scores_bing_desc = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    sentiment_score = sum(-1 if bing_dict.get(word, '') == 'negative' else 1 if bing_dict.get(word, '') == 'positive' else 0 for word in review_tokens)\n",
    "    sentiment_scores_bing_desc.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_bing_desc'] = sentiment_scores_bing_desc\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using bing\n",
    "sentiment_scores_bing_revText = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(-1 if bing_dict.get(word, '') == 'negative' else 1 if bing_dict.get(word, '') == 'positive' else 0 for word in review_tokens)\n",
    "    sentiment_scores_bing_revText.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_bing_revText'] = sentiment_scores_bing_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \n",
       "0                          0                             2  \n",
       "1                          5                             2  \n",
       "2                          2                             3  \n",
       "3                          3                             5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_bing_desc', 'sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of NRC: (13901, 2)\n",
      "Unique Sentiments: ['trust' 'fear' 'negative' 'sadness' 'anger' 'surprise' 'positive'\n",
      " 'disgust' 'joy' 'anticipation']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abacus</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word sentiment\n",
       "0   abacus     trust\n",
       "1  abandon      fear\n",
       "2  abandon  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in \n",
    "nrc = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/NRC.csv')\n",
    "\n",
    "# NRC\n",
    "print(\"Shape of NRC:\", nrc.shape)\n",
    "print(\"Unique Sentiments:\", nrc.sentiment.unique())\n",
    "display(nrc.head(3))\n",
    "nrc_dict = dict(zip(nrc['word'], nrc['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_scores_nrc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23%40gmail.com/My%20Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# find counts of each sentiment in the review (TESTING for ONE REVIEW)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23%40gmail.com/My%20Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m review \u001b[39m=\u001b[39m amz_data[\u001b[39m'\u001b[39m\u001b[39mfiltered_tokens_desc\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23%40gmail.com/My%20Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m review_sentiment_scores \u001b[39m=\u001b[39m sentiment_scores_nrc\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23%40gmail.com/My%20Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m review:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23%40gmail.com/My%20Drive/Portfolio/Masters-Dissertation/Code/data_sentiment_analysis.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     word_sentiments \u001b[39m=\u001b[39m nrc_dict\u001b[39m.\u001b[39mget(word, [])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_scores_nrc' is not defined"
     ]
    }
   ],
   "source": [
    "# find counts of each sentiment in the review (TESTING for ONE REVIEW)\n",
    "review = amz_data['filtered_tokens_desc'][1]\n",
    "review_sentiment_scores = sentiment_scores_nrc.copy()\n",
    "for word in review:\n",
    "    word_sentiments = nrc_dict.get(word, [])\n",
    "    for sentiment in unique_sentiments:\n",
    "        if sentiment in word_sentiments:\n",
    "            review_sentiment_scores[sentiment] += 1\n",
    "print(review_sentiment_scores)\n",
    "\n",
    "# get the overall sentiment\n",
    "overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "print(\"Overall Sentiment:\", overall_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sentiments = ['trust', 'fear', 'negative', 'sadness', 'anger', 'surprise', 'positive', 'disgust', 'joy', 'anticipation']\n",
    "\n",
    "# Get the sentiment score for each description using NRC\n",
    "sentiment_scores_nrc_desc = []\n",
    "\n",
    "# Calculate sentiment score and overall sentiment for each review using NRC lexicon\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    review_sentiment_scores = {sentiment: 0 for sentiment in unique_sentiments}\n",
    "    for word in review_tokens:\n",
    "        word_sentiments = nrc_dict.get(word, [])\n",
    "        for sentiment in unique_sentiments:\n",
    "            if sentiment in word_sentiments:\n",
    "                review_sentiment_scores[sentiment] += 1\n",
    "\n",
    "    overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "    sentiment_scores_nrc_desc.append(overall_sentiment)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_nrc_desc'] = sentiment_scores_nrc_desc\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using NRC\n",
    "sentiment_scores_nrc_revText = []\n",
    "\n",
    "# Calculate sentiment score and overall sentiment for each review using NRC lexicon\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    review_sentiment_scores = {sentiment: 0 for sentiment in unique_sentiments}\n",
    "    for word in review_tokens:\n",
    "        word_sentiments = nrc_dict.get(word, [])\n",
    "        for sentiment in unique_sentiments:\n",
    "            if sentiment in word_sentiments:\n",
    "                review_sentiment_scores[sentiment] += 1\n",
    "\n",
    "    overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "    sentiment_scores_nrc_revText.append(overall_sentiment)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_nrc_revText'] = sentiment_scores_nrc_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \n",
       "0                          0                             2  \n",
       "1                          5                             2  \n",
       "2                          2                             3  \n",
       "3                          3                             5  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_bing_desc', 'sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Data Frame with BING, AFINN and NRC Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_afinn_desc</th>\n",
       "      <th>sentiment_score_afinn_revText</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "      <th>sentiment_score_nrc_desc</th>\n",
       "      <th>sentiment_score_nrc_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Bennett</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>trust</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samson</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>trust</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>trust</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewerName                                        description  \\\n",
       "0     John Bennett  steve green hide em in your heart 13 bible mem...   \n",
       "1           samson  this is a concept album all the way with tales...   \n",
       "2  Amazon Customer  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3               sj  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_afinn_desc  sentiment_score_afinn_revText  \\\n",
       "0                          -1                              3   \n",
       "1                           4                              6   \n",
       "2                           2                              4   \n",
       "3                           1                             24   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \\\n",
       "0                          0                             2   \n",
       "1                          5                             2   \n",
       "2                          2                             3   \n",
       "3                          3                             5   \n",
       "\n",
       "  sentiment_score_nrc_desc sentiment_score_nrc_revText  \n",
       "0                    trust                    positive  \n",
       "1                 positive                    positive  \n",
       "2                    trust                     sadness  \n",
       "3                    trust                    positive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data \n",
    "amz_data[['reviewerName', 'description', 'reviewText','overall', 'sentiment_score_afinn_desc', 'sentiment_score_afinn_revText',\n",
    "       'sentiment_score_bing_desc', 'sentiment_score_bing_revText', 'sentiment_score_nrc_desc', 'sentiment_score_nrc_revText']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti.csv\", index=False)\n",
    "\n",
    "# create a smaller dataframe by randomly sampling 10% of the data\n",
    "amz_rev_sample = amz_data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# save data as csv\n",
    "amz_rev_sample.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
