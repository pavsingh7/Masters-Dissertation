{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Based Collaborative Filtering\n",
    "## Algorithm Summary\n",
    "\n",
    "Item-based collaborative filtering is a model-based algorithm for making recommendations. It is based on the similarity between items calculated using people's ratings of those items. It is also known as item-item collaborative filtering.\n",
    "\n",
    "1. **Load the data**\n",
    "- data is provided in a dataframe where each row is a review\n",
    "\n",
    "2. **Create a user-item matrix**\n",
    "- convert dataframe into user-item matrix where each row is a user and each column is an item\n",
    "\n",
    "3. **Create test, train and validation set**\n",
    "- hide $N$ ratings for each user in the training set and use them to test the performance of the model. Use the other hidden ratings as validation set.\n",
    "\n",
    "4. **Calculate user similarity**\n",
    "- using training set, calculate the similarity between users using cosine similarity\n",
    "\n",
    "5. **Make predictions**\n",
    "- for each user, for each item in the test set, calculate the weighted sum of the ratings of the items that are similar to the item in question\n",
    "\n",
    "6. **Evaluate the model**\n",
    "- calculate the predictive accuracy of the model using RMSE, MSE and MAE\n",
    "- calculate the Top-N metrics of the model using NDCG and Hit Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Manaul / From Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data - WINDOWS\n",
    "# amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "# display(amz_data.head())\n",
    "\n",
    "# load data - MAC OS\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set3_data_modelling.csv')\n",
    "display(amz_data.head(3))\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"Shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 3\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide another 2 ratings for validation\n",
    "N = 2\n",
    "indices_tracker_val = []\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  \n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker_val.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n",
    "\n",
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim matrix and change to pd dataframe and save to csv\n",
    "sim_mat_cos = cosine_similarity(x_hidden).round(5)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set k \n",
    "k = [5,10,20,40]\n",
    "\n",
    "# get predicted ratings for all users for each K, calculate RMSE and store in a list\n",
    "for k in k:\n",
    "    print(\"K = \", k)\n",
    "    # get top k similar users\n",
    "    top_k_users = np.argsort(-sim_mat_cos, axis=1)[:, 1:k+1]\n",
    "    print(\"Top K Similar Users\")\n",
    "    print(top_k_users)\n",
    "    \n",
    "    # get predicted ratings for all users\n",
    "    predicted_ratings = np.zeros(x_hidden.shape)\n",
    "    for i in range(x_hidden.shape[0]):\n",
    "        for j in range(x_hidden.shape[1]):\n",
    "            if x_hidden.iloc[i, j] == 0:\n",
    "                predicted_ratings[i, j] = np.mean(x_hidden.iloc[top_k_users[i], j])\n",
    "            else:\n",
    "                predicted_ratings[i, j] = x_hidden.iloc[i, j]\n",
    "    print(\"Predicted Ratings\")\n",
    "    print(predicted_ratings)\n",
    "    \n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(np.sum((predicted_ratings - x)**2) / (x.shape[0] * x.shape[1]))\n",
    "    print(\"RMSE: \", rmse)\n",
    "    \n",
    "    # store RMSE in a list\n",
    "    rmse_list.append(rmse)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# see best k \n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# set k to 40\n",
    "k = 40\n",
    "\n",
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unrated_products_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_users_indices = np.where(user_ratings > 0)[1]\n",
    "    for product_id in unrated_products_indices:\n",
    "        similarity_i_j = sim_mat_cos[user_id, rated_users_indices]  # Get similarity between this user and other users who rated this product\n",
    "        ratings = user_ratings[0, rated_users_indices]\n",
    "        \n",
    "        # sort by similarity and select top k\n",
    "        sorted_indices = np.argsort(similarity_i_j)[::-1][:k]\n",
    "        similarity_i_j = similarity_i_j[sorted_indices]\n",
    "        ratings = ratings[sorted_indices]\n",
    "\n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, product_id] = predicted_rating\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Predictive Accuracy)\n",
    "\n",
    "Now evaluate how good the predictions are vs the hidden ratings\n",
    "- ***step 1***: identify the hidden ratings indices\n",
    "- ***step 2***: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "- ***step 3***: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(predic_matrix.shape[0]):\n",
    "    user_predicted_ratings = predic_matrix.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 2 decimal places\n",
    "mae = round(mae, 2)\n",
    "mse = round(mse, 2)\n",
    "rmse = round(rmse, 2)\n",
    "\n",
    "# save results to csv\n",
    "results = pd.DataFrame({'MAE': [mae.round(3)], 'MSE': [mse.round(3)], 'RMSE': [rmse.round(3)]})\n",
    "results.to_csv(\"Data/Results/UBCF_results_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Top-N Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn matrix into a dataframe with user and product, rating columns\n",
    "preds_series = predic_matrix.stack().reset_index().rename(columns={0: 'rating'}).sort_values(by=['asin', 'reviewerID'])\n",
    "preds_series = preds_series['rating'].reset_index(drop=True)\n",
    "preds_series\n",
    "\n",
    "\n",
    "# getting a dataframe with interactions and ratings\n",
    "data = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "data_mat = data.copy()\n",
    "data_mat = data_mat.reset_index()\n",
    "data_mat = data_mat.melt(id_vars=data_mat.columns[0], var_name='product', value_name='rating')\n",
    "data_mat.columns = ['user', 'product', 'rating']\n",
    "data_mat['user'] = data_mat['user'].astype('category')\n",
    "data_mat['product'] = data_mat['product'].astype('category')\n",
    "\n",
    "# data_mat['user'] = data_mat['user'].cat.codes\n",
    "# data_mat['product'] = data_mat['product'].cat.codes\n",
    "display(data_mat.head(3))\n",
    "\n",
    "# create a completed dataframe\n",
    "completed = data_mat.copy()\n",
    "nan_rows = completed[completed['rating'].isnull()]\n",
    "\n",
    "# for nan_rows, replace the rating with the predicted rating\n",
    "completed.loc[nan_rows.index, 'rating'] = preds_series[nan_rows.index]\n",
    "\n",
    "# see original data with user item interactions\n",
    "print(\"User Item Interactions with Ratings\")\n",
    "display(data_mat.head(3))\n",
    "\n",
    "# see data with predictions\n",
    "print(\"\\nUser Item Interactions with Predicted Ratings\")\n",
    "display(completed.head(3))\n",
    "\n",
    "# details on completed dataframe\n",
    "print('\\n\\nNumber of Rows: ', completed.shape[0])\n",
    "print('Number of Columns: ', completed.shape[1])\n",
    "print('Number of Unique Users: ', len(completed['user'].unique()))\n",
    "print('Number of Unique Products: ', len(completed['product'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute for One User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 3\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data for user (i.e., remove the hidden ratings and keep only the observed ratings)\n",
    "train_data = x_hidden.copy()\n",
    "train_data = train_data.stack().reset_index().rename(columns={0: 'rating'}).sort_values(by=['reviewerID', 'asin'])\n",
    "\n",
    "# remove all zeros and nan values\n",
    "train_data = train_data[(train_data != 0)]\n",
    "\n",
    "# remove all nan values\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "\n",
    "# apply cat codes to the user and product columns\n",
    "train_data['reviewerID'] = train_data['reviewerID'].astype('category')\n",
    "train_data['asin'] = train_data['asin'].astype('category')\n",
    "\n",
    "# train_data['reviewerID'] = train_data['reviewerID'].cat.codes\n",
    "# train_data['asin'] = train_data['asin'].cat.codes\n",
    "train_data.rename(columns={'reviewerID': 'user', 'asin':'product' }, inplace=True)\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set N - number of recommendations\n",
    "N = 10000\n",
    "\n",
    "# get interactions for user 1 used for training\n",
    "train_x_user_1 = train_data[train_data['user'] == 'A100RH4M1W1DF0']\n",
    "train_x_user_1\n",
    "\n",
    "# Get interactions for User 1 (including ratings)\n",
    "user_1 = completed[completed['user'] == 'A100RH4M1W1DF0']\n",
    "print(\"Number of Interactions for User 1: \", user_1.shape[0])\n",
    "\n",
    "# Identify liked items for User 1 (above a threshold, e.g., rating > 3)\n",
    "liked_items = user_1[user_1['rating'] > 3.5]\n",
    "print(\"Number of Liked Items for User 1: \", liked_items.shape[0])\n",
    "\n",
    "# get items that were hidden for user 1 (get product names)\n",
    "product_ids_hidden = x.iloc[0, indices_tracker[0]].index\n",
    "product_ids_hidden = product_ids_hidden.tolist()\n",
    "print(\"Number of Hidden Items for User 1: \", len(product_ids_hidden))\n",
    "\n",
    "# get ratings for hidden items and predicted ratings - for user 1 (put in a dataframe)\n",
    "hidden_ratings = x.iloc[0, indices_tracker[0]].values\n",
    "predicted_ratings = predic_matrix.iloc[0, indices_tracker[0]].values\n",
    "hidden_ratings_df = pd.DataFrame({'product': product_ids_hidden, 'hidden_rating': hidden_ratings, 'predicted_rating': predicted_ratings})\n",
    "hidden_ratings_df\n",
    "\n",
    "# set  threshold for recommendations\n",
    "threshold = 3.\n",
    "# create a label column for hidden ratings (1 = liked, 0 = not liked)\n",
    "hidden_ratings_df['label'] = hidden_ratings_df['hidden_rating'].apply(lambda x: 1 if x > threshold else 0)\n",
    "hidden_ratings_df\n",
    "\n",
    "# add label for used interactions (add 1 to all interactions that exist in training data)\n",
    "user_1['used_ind'] = 0\n",
    "for i in range(user_1.shape[0]):\n",
    "    if user_1.iloc[i, 1] in list(train_x_user_1['product']):\n",
    "        user_1.iloc[i, 3] = 1\n",
    "\n",
    "# count how many interactions are in train_x\n",
    "print(\"Number of Interactions in Train Set for User 1: \", train_x_user_1.shape[0])\n",
    "\n",
    "# count how many 1 in completed_user_1\n",
    "print(\"Number of Interactions in Completed User 1: \", user_1[user_1['used_ind'] == 1].shape[0])\n",
    "\n",
    "# add label liked for completed_user_1\n",
    "user_1['liked'] = user_1['rating'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "\n",
    "# add a label column to user_1_top_n: test_ind (if the product is in hidden_ratings_df, then 1, else 0)\n",
    "user_1['test_ind'] = 0\n",
    "for i in range(user_1.shape[0]):\n",
    "    if user_1.iloc[i, 1] in list(hidden_ratings_df['product']):\n",
    "        user_1.iloc[i, 5] = 1\n",
    "\n",
    "# for all records where test_ind = 1, replace the hidden_rating with predicted_rating\n",
    "for i in range(user_1.shape[0]):\n",
    "    if user_1.iloc[i, 5] == 1:\n",
    "        user_1.iloc[i, 2] = hidden_ratings_df[hidden_ratings_df['product'] == user_1.iloc[i, 1]]['predicted_rating'].values[0] \n",
    "\n",
    "# get top N recommendations for user 1 - exclude items where used_ind = 1\n",
    "user_1_top_n = user_1[user_1['used_ind'] == 0]\n",
    "user_1_top_n = user_1_top_n.sort_values(by='rating', ascending=False)\n",
    "user_1_top_n = user_1_top_n.head(N)\n",
    "\n",
    "# count how many 1 in user_1_top_n\n",
    "print(\"Number of Items in Top N for User 1 that Were Used and Liked: \", user_1_top_n[user_1_top_n['test_ind'] == 1].shape[0])\n",
    "\n",
    "# see top N recommendations for user 1\n",
    "print(\"\\n\\nTop N Recommendations for User 1\")\n",
    "display(user_1_top_n)\n",
    "\n",
    "# Calculate precision@K (top N recommendations)\n",
    "precision_at_N = user_1_top_n['test_ind'].sum() / N\n",
    "\n",
    "# Calculate recall@K\n",
    "recall_at_N = user_1_top_n['test_ind'].sum() / liked_items.shape[0]\n",
    "\n",
    "# calculate F1 score\n",
    "f1_at_N = 2 * (precision_at_N * recall_at_N) / (precision_at_N + recall_at_N)\n",
    "\n",
    "print(f\"Precision@{N}: {precision_at_N:.4f}\")\n",
    "print(f\"Recall@{N}: {recall_at_N:.4f}\")\n",
    "print(f\"F1@{N}: {f1_at_N:.4f}\")\n",
    "\n",
    "# save results to csv\n",
    "results = pd.DataFrame({'Precision@N': [precision_at_N], 'Recall@N': [recall_at_N], 'F1@N': [f1_at_N]})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe with columns: user, products\n",
    "hid = pd.DataFrame(hidden_ratings_ind)\n",
    "hid['user'] = x.index\n",
    "hid = hid[['user', 0, 1, 2]]\n",
    "\n",
    "# convert 0,1,2 to list\n",
    "hid['products'] = hid.iloc[:, 1:].values.tolist()\n",
    "hid = hid[['user', 'products']]\n",
    "hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topN_user(user_id, threshold, N):\n",
    "    print(f\"Evaluating User {user_id}\")\n",
    "    \n",
    "    train_x_user = train_data[train_data['user'] == user_id]\n",
    "    user_data = completed[completed['user'] == user_id]\n",
    "    \n",
    "    liked_items = user_data[user_data['rating'] > threshold]\n",
    "    product_ids_hidden = x.iloc[0, indices_tracker[0]].index.tolist()\n",
    "    \n",
    "\n",
    "    all_ints = x.loc[user_id, :]\n",
    "    product_names = all_ints.index[hid[hid['user'] == user_id]['products'].values[0]]\n",
    "\n",
    "    hidden_ratings = x.loc[user_id, product_names].values\n",
    "    predicted_ratings = predic_matrix.loc[user_id, product_names].values\n",
    "    \n",
    "    hidden_ratings_df = pd.DataFrame({\n",
    "        'product': product_ids_hidden,\n",
    "        'hidden_rating': hidden_ratings,\n",
    "        'predicted_rating': predicted_ratings\n",
    "    })\n",
    "\n",
    "    hidden_ratings_df['label'] = hidden_ratings_df['hidden_rating'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    user_data['used_ind'] = 0\n",
    "    user_data['liked'] = user_data['rating'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    user_data['test_ind'] = user_data['product'].apply(lambda x: 1 if x in hidden_ratings_df['product'].tolist() else 0)\n",
    "\n",
    "    for i in range(user_data.shape[0]):\n",
    "        if user_data.iloc[i, 5] == 1:\n",
    "            user_data.iloc[i, 2] = hidden_ratings_df[hidden_ratings_df['product'] == user_data.iloc[i, 1]]['predicted_rating'].values[0]\n",
    "\n",
    "    user_top_n = user_data[user_data['used_ind'] == 0].sort_values(by='rating', ascending=False).head(N)\n",
    "    display(user_top_n)\n",
    "\n",
    "    precision_at_N = user_top_n['test_ind'].sum() / N\n",
    "    recall_at_N = user_top_n['test_ind'].sum() / liked_items.shape[0]\n",
    "\n",
    "    if precision_at_N + recall_at_N == 0:\n",
    "        f1_at_N = 0\n",
    "    else:\n",
    "        f1_at_N = 2 * (precision_at_N * recall_at_N) / (precision_at_N + recall_at_N)\n",
    "\n",
    "    results = pd.DataFrame({'Precision@N': [precision_at_N], 'Recall@N': [recall_at_N], 'F1@N': [f1_at_N]})\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can call evaluate_user_recommendation with different user_id, threshold, and N\n",
    "results = evaluate_topN_user(user_id='A214JN9AJNSHCJ', threshold=3.5, N=1000)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute for All Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of users\n",
    "user_count = len(completed['user'].unique())\n",
    "counter = 0\n",
    "\n",
    "# loop through users to get results for each user and save to a dataframe\n",
    "results = pd.DataFrame()\n",
    "for user in completed['user'].unique():\n",
    "    counter += 1\n",
    "    print(f\"User {counter} of {user_count}\")\n",
    "    user_results = evaluate_topN_user(user_id=user, threshold=3, N=10000)\n",
    "    print(user_results)\n",
    "    results = pd.concat([results, user_results])\n",
    "    \n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average results for all users\n",
    "average_results = results.mean()\n",
    "average_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate recall, using precision and f1 only. \n",
    "# Recall = 2 * (precision * f1) / (precision + f1)\n",
    "average_results['Recall@N'] = 2 * (average_results['Precision@N'] * average_results['F1@N']) / (average_results['Precision@N'] + average_results['F1@N'])\n",
    "average_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_N = average_results['Precision@N']\n",
    "recall_at_N = average_results['Recall@N']\n",
    "f1_at_N = average_results['F1@N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results = pd.DataFrame({'Precision@N': [precision_at_N], 'Recall@N': [recall_at_N], 'F1@N': [f1_at_N]})\n",
    "average_results.to_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/Results/UBCF_results_1_top10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Using Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Packages for IBCF\n",
    "import surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and Change data to User-`Item-`Rating format\n",
    "# amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data_modelling.csv', index_col=0)\n",
    "display(amz_data.head())\n",
    "\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Assume you have a user-item matrix 'user_item_matrix'\n",
    "# Convert the user-item matrix back to a DataFrame of ratings\n",
    "ratings = x.stack().reset_index()\n",
    "ratings.columns = ['user', 'item', 'rating']\n",
    "\n",
    "# Remove rows where rating is 0\n",
    "ratings = ratings[ratings['rating'] != 0]\n",
    "\n",
    "# Define a Reader object\n",
    "# The Reader object helps in parsing the file or dataframe containing ratings\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create the dataset to be used for building the filter\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "# Split the dataset into train and test\n",
    "# Test set is made of 25% of the ratings\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=2207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the algorithm - User Based Collaborative Filtering\n",
    "# Use cosine similarity\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True  # this will compute similarity between users\n",
    "}\n",
    "\n",
    "# set k\n",
    "k = 40\n",
    "\n",
    "# Create an instance of KNNBasic\n",
    "algo = KNNBasic(sim_options=sim_options, k=k, verbose=True,random_state=2207)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE, MSE and MAE\n",
    "print(\"\\nUser-based Model Test Set Results:\")\n",
    "mae_pack = accuracy.mae(predictions).round(2)\n",
    "mse_pack = accuracy.mse(predictions).round(2)\n",
    "rmse_pack = accuracy.rmse(predictions).round(2)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae_pack}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_pack}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_pack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "results = pd.DataFrame({'MAE': [mae_pack.round(3)], 'MSE': [mse_pack.round(3)], 'RMSE': [rmse_pack.round(3)]})\n",
    "results.to_csv(\"Data/Results/UBCF_results_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## (3) Manual Process with Same Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data - WINDOWS\n",
    "# amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "# display(amz_data.head())\n",
    "\n",
    "# load data - MAC OS\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data_modelling.csv')\n",
    "display(amz_data.head(3))\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"Shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using created testset from packages chapter\n",
    "ratings = x.stack().reset_index()\n",
    "ratings.columns = ['user', 'item', 'rating']\n",
    "ratings = ratings[ratings['rating'] != 0]\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=2207)\n",
    "testset_df = pd.DataFrame(testset)\n",
    "testset_df = testset_df\n",
    "\n",
    "\n",
    "# convert each row of the testset to a tuple\n",
    "testset_tuples = [tuple(x) for x in testset_df[[0, 1]].to_numpy()]\n",
    "\n",
    "# find indices of the testset in the original matrix\n",
    "testset_indices = []\n",
    "for i in range(len(testset_tuples)):\n",
    "    user = testset_tuples[i][0]\n",
    "    item = testset_tuples[i][1]\n",
    "    user_index = x.index.get_loc(user)\n",
    "    item_index = x.columns.get_loc(item)\n",
    "    testset_indices.append((user_index, item_index))\n",
    "\n",
    "# shorten the testset_indices to 100\n",
    "testset_indices = testset_indices\n",
    "print(\"Testset Indices: \")\n",
    "testset_indices[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a copy of the original matrix to store hidden ratings\n",
    "# x_hidden = x.copy()\n",
    "# indices_tracker = []\n",
    "\n",
    "# # loop through the testset indices to hide the rating (make 0) - update x_hidden\n",
    "# for user_id in range(x_hidden.shape[0]):\n",
    "#     for item_id in range(x_hidden.shape[1]):\n",
    "#         if (user_id, item_id) in testset_indices:\n",
    "#             x_hidden.iloc[user_id, item_id] = 0\n",
    "\n",
    "# # save x_hidden to csv\n",
    "# x_hidden.to_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/suprise_hidden_ratings_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hidden ratings matrix\n",
    "x_hidden = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/suprise_hidden_ratings_matrix.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim matrix and change to pd dataframe\n",
    "sim_mat_cos = cosine_similarity(x_hidden)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# set k to 40\n",
    "k = 40\n",
    "\n",
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unrated_products_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_users_indices = np.where(user_ratings > 0)[1]\n",
    "    for product_id in unrated_products_indices:\n",
    "        similarity_i_j = sim_mat_cos[user_id, rated_users_indices]  # Get similarity between this user and other users who rated this product\n",
    "        ratings = user_ratings[0, rated_users_indices]\n",
    "        \n",
    "        # sort by similarity and select top k\n",
    "        sorted_indices = np.argsort(similarity_i_j)[::-1][:k]\n",
    "        similarity_i_j = similarity_i_j[sorted_indices]\n",
    "        ratings = ratings[sorted_indices]\n",
    "\n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, product_id] = predicted_rating\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get predicted ratings for the testset\n",
    "predicted_ratings = []\n",
    "for i in range(len(testset_indices)):\n",
    "    user_id = testset_indices[i][0]\n",
    "    item_id = testset_indices[i][1]\n",
    "    predicted_ratings.append(predic_matrix.iloc[user_id, item_id])\n",
    "\n",
    "print(\"Predicted Ratings:\")\n",
    "print(predicted_ratings)\n",
    "\n",
    "\n",
    "# get actual ratings for the testset\n",
    "print(\"\\nActual Ratings:\")\n",
    "actual_ratings = testset_df[2].to_list()\n",
    "print(actual_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE, MSE and RMSE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
    "mse = mean_squared_error(actual_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.round(2)}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse.round(2)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.round(2)}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "\n",
    "# calculate MAE, MSE and RMSE using actual and predicted ratings\n",
    "mae = np.mean(np.abs(np.array(actual_ratings) - np.array(predicted_ratings))) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((np.array(actual_ratings) - np.array(predicted_ratings)) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.round(2)}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse.round(2)}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "results = pd.DataFrame({'MAE': [mae.round(3)], 'MSE': [mse.round(3)], 'RMSE': [rmse.round(3)]})\n",
    "results.to_csv(\"Data/Results/UBCF_results_3.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
