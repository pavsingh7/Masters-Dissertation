{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Based Collaborative Filtering\n",
    "## Algorithm Summary\n",
    "\n",
    "Item-based collaborative filtering is a model-based algorithm for making recommendations. It is based on the similarity between items calculated using people's ratings of those items. It is also known as item-item collaborative filtering.\n",
    "\n",
    "1. **Load the data**\n",
    "- data is provided in a dataframe where each row is a review\n",
    "\n",
    "2. **Create a user-item matrix**\n",
    "- convert dataframe into user-item matrix where each row is a user and each column is an item\n",
    "\n",
    "3. **Create test and train set**\n",
    "- hide $N$ ratings for each user in the training set and use them to test the performance of the model\n",
    "\n",
    "4. **Calculate user similarity**\n",
    "- using training set, calculate the similarity between users using cosine similarity\n",
    "\n",
    "5. **Make predictions**\n",
    "- for each user, for each item in the test set, calculate the weighted sum of the ratings of the items that are similar to the item in question\n",
    "\n",
    "6. **Evaluate the model**\n",
    "- calculate the predictive accuracy of the model using RMSE, MSE and MAE\n",
    "- calculate the Top-N metrics of the model using NDCG and Hit Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manaul / From Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data - WINDOWS\n",
    "amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "display(amz_data.head())\n",
    "\n",
    "# load data - MAC OS\n",
    "# amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data_modelling.csv')\n",
    "# display(amz_data.head(3))\n",
    "\n",
    "# print details\n",
    "print('Number of Rows: ', amz_data.shape[0])\n",
    "print('Number of Columns: ', amz_data.shape[1])\n",
    "print('Number of Unique Users: ', len(amz_data['reviewerID'].unique()))\n",
    "print('Number of Unique Products: ', len(amz_data['asin'].unique()))\n",
    "print('Fewest reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().min())\n",
    "print('Most reviews by a reviewer:', amz_data.groupby('reviewerID')['asin'].count().max())\n",
    "print(\"Fewest reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().min())\n",
    "print(\"Most reviews per product:\", amz_data.groupby('asin')['reviewerID'].count().max())\n",
    "\n",
    "\n",
    "# Creating User Item Matrix =====================================================\n",
    "# create user-item matrix\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# number of products to hide for each user\n",
    "N = 3\n",
    "\n",
    "# identifies rated items and randomly selects N products to hide ratings for each user\n",
    "np.random.seed(2207)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_products = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    # print(\"User:\", user_id)\n",
    "    # print(\"Indices of Rated Products:\", rated_products)\n",
    "    hidden_indices = np.random.choice(rated_products, N, replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    # print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n",
    "\n",
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim matrix and change to pd dataframe and save to csv\n",
    "sim_mat_cos = cosine_similarity(x_hidden).round(5)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unrated_products_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_users_indices = np.where(user_ratings > 0)[1]\n",
    "    for product_id in unrated_products_indices:\n",
    "        similarity_i_j = sim_mat_cos[user_id, rated_users_indices]  # Get similarity between this user and other users who rated this product\n",
    "        ratings = user_ratings[0, rated_users_indices]\n",
    "        \n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, product_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (Predictive Accuracy)\n",
    "\n",
    "Now evaluate how good the predictions are vs the hidden ratings\n",
    "- ***step 1***: identify the hidden ratings indices\n",
    "- ***step 2***: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "- ***step 3***: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "\n",
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(predic_matrix.shape[0]):\n",
    "    user_predicted_ratings = predic_matrix.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n",
    "\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to 2 decimal places\n",
    "mae = round(mae, 2)\n",
    "mse = round(mse, 2)\n",
    "rmse = round(rmse, 2)\n",
    "\n",
    "# Save the results to a csv file\n",
    "results = pd.DataFrame({'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "results.to_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\results_UBCF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Packages for IBCF\n",
    "import surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and Change data to User-`Item-`Rating format\n",
    "amz_data = pd.read_csv(r'C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\Data\\set2_data_modelling.csv')\n",
    "display(amz_data.head())\n",
    "\n",
    "\n",
    "x = amz_data.pivot_table(index='reviewerID', columns='asin', values='overall')\n",
    "x = x.fillna(0)\n",
    "print(\"\\n\\n\\nUser-Item Matrix\")\n",
    "display(x.head())\n",
    "print('Shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Assume you have a user-item matrix 'user_item_matrix'\n",
    "# Convert the user-item matrix back to a DataFrame of ratings\n",
    "ratings = user_item_matrix.stack().reset_index()\n",
    "ratings.columns = ['user', 'item', 'rating']\n",
    "\n",
    "# Remove rows where rating is 0\n",
    "ratings = ratings[ratings['rating'] != 0]\n",
    "\n",
    "# Define a Reader object\n",
    "# The Reader object helps in parsing the file or dataframe containing ratings\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Create the dataset to be used for building the filter\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "# Split the dataset into train and test\n",
    "# Test set is made of 25% of the ratings\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# Configure the algorithm - User Based Collaborative Filtering\n",
    "# Use cosine similarity\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True  # this will compute similarity between users\n",
    "}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE, MSE and MAE\n",
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Sandbox\n",
    "\n",
    "Here we will test out the workings of item based collaborative filtering. The steps are as follows:\n",
    "\n",
    "1. Have User Item matrix\n",
    "2. Hide some ratings to simulate a test set\n",
    "3. Calculate similarity (cosine similarity)\n",
    "4. Calculate weighted average of ratings\n",
    "5. Fill in missing values with predicted ratings\n",
    "6. Take the predicted ratings and compare them to the hidden ratings\n",
    "7. Calculate MAE, RMSE, MSE\n",
    "8. Binarise the ratings \n",
    "9. Calculate classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data.csv\", index_col=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original matrix to store hidden ratings\n",
    "x_hidden = x.copy()\n",
    "indices_tracker = []\n",
    "\n",
    "# identifies rated books and randomly selects 2 books to hide ratings for each user\n",
    "np.random.seed(10)  # You can use any integer value as the seed\n",
    "for user_id in range(x_hidden.shape[0]):\n",
    "    rated_books = np.where(x_hidden.iloc[user_id, :] > 0)[0]\n",
    "    print(\"User:\", user_id)\n",
    "    print(\"Indices of Rated Books:\", rated_books)\n",
    "    hidden_indices = np.random.choice(rated_books, min(2, len(rated_books)), replace=False)\n",
    "    indices_tracker.append(hidden_indices)\n",
    "    print(\"Indices to Hide:\", hidden_indices, \"\\n\")\n",
    "    x_hidden.iloc[user_id, hidden_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tracker - all hidden ratings \n",
    "indices_tracker = pd.DataFrame(indices_tracker).to_numpy()\n",
    "print(\"Indices of Ratings per user \\n\", indices_tracker)\n",
    "\n",
    "# flattened\n",
    "indices_tracker_flat = indices_tracker.flatten()\n",
    "print(\"Indices of Ratings per User joined\", indices_tracker_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see updated matrix with hidden ratings\n",
    "print(\"Updated Matrix with Hidden Ratings\")\n",
    "display(x_hidden)\n",
    "\n",
    "# see original matrix\n",
    "print(\"Original Matrix\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim matrix and change to pd dataframe and save to csv\n",
    "pd.DataFrame(cosine_similarity(x_hidden.T).round(2), index=x.columns, columns=x.columns).to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_sim_mat_cosine.csv\")\n",
    "sim_mat_cos = cosine_similarity(x_hidden.T).round(2)\n",
    "print(\"Cosine Similarity Matrix\") \n",
    "sim_mat_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a predictions matrix\n",
    "predic_matrix = x_hidden.copy()\n",
    "\n",
    "# get predicted ratings for unread books for user 1 using cosine similarity\n",
    "user_ratings = predic_matrix.iloc[0, :].values.reshape(1, -1)\n",
    "unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "\n",
    "for book_id in unread_books_indices:\n",
    "    similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "    ratings = user_ratings[0, rated_books_indices]\n",
    "    predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "    predic_matrix.iloc[0, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for User 1\")\n",
    "display(predic_matrix)\n",
    "\n",
    "# save to csv\n",
    "predic_matrix.to_csv(r\"C:\\Users\\e1002902\\Documents\\GitHub Repository\\Masters-Dissertation\\Code\\temp_data_predic_matrix_cosine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get predicted ratings for all users\n",
    "for user_id in range(predic_matrix.shape[0]):\n",
    "    user_ratings = predic_matrix.iloc[user_id, :].values.reshape(1, -1)\n",
    "    unread_books_indices = np.where(user_ratings == 0)[1]\n",
    "    rated_books_indices = np.where(user_ratings > 0)[1]\n",
    "    for book_id in unread_books_indices:\n",
    "        similarity_i_j = sim_mat_cos[book_id, rated_books_indices]\n",
    "        ratings = user_ratings[0, rated_books_indices]\n",
    "        \n",
    "        if np.any(similarity_i_j):\n",
    "            predicted_rating = np.sum(ratings * similarity_i_j) / np.sum(np.abs(similarity_i_j))\n",
    "        else:\n",
    "            # make predicted rating mean of user's ratings\n",
    "            predicted_rating = np.mean(ratings)\n",
    "        \n",
    "        predic_matrix.iloc[user_id, book_id] = predicted_rating.round(2)\n",
    "\n",
    "# see updated matrix with predicted ratings\n",
    "print(\"Predicted Ratings for All Users\")\n",
    "display(predic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate how good the predictions are vs the hidden ratings\n",
    "# step 1: identify the hidden ratings indices\n",
    "# step 2: extract hidden ratings indices and corresponding predicted ratings indices\n",
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values)\n",
    "# step 4:  binarise to get classification metrics\n",
    "\n",
    "# step 1: identify the hidden ratings indices = indices_tracker and get the hidden ratings ==========================================================================\n",
    "hidden_ratings_ind = indices_tracker.copy()\n",
    "\n",
    "# Loop through users to append hidden ratings\n",
    "hidden_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append hidden ratings arrays\n",
    "for user in range(x.shape[0]):\n",
    "    user_hidden_ratings = x.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    hidden_ratings_arrays.append(user_hidden_ratings)\n",
    "\n",
    "\n",
    "hidden_ratings_array = pd.DataFrame(hidden_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: extract corresponding predicted ratings indices ==========================================================================\n",
    "\n",
    "# Create an empty list to store predicted ratings arrays\n",
    "predicted_ratings_arrays = []\n",
    "\n",
    "# Loop through users to append predicted ratings arrays\n",
    "for user in range(predic_matrix.shape[0]):\n",
    "    user_predicted_ratings = predic_matrix.iloc[user, hidden_ratings_ind[user, :]].reset_index(drop=True).values\n",
    "    predicted_ratings_arrays.append(user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_array = pd.DataFrame(predicted_ratings_arrays).to_numpy().flatten()\n",
    "print(\"Corresponding Predicted Ratings:\", predicted_ratings_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: calculate MAE, MSE and RMSE (take the hidden ratings as the true values and the predicted ratings as the predicted values) ==========================================================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# calculate MAE, MSE and RMSE\n",
    "print(\"Using sklearn\")\n",
    "mae = mean_absolute_error(hidden_ratings_array, predicted_ratings_array)\n",
    "mse = mean_squared_error(hidden_ratings_array, predicted_ratings_array)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "# Manually\n",
    "print(\"\\n\\nManually\")\n",
    "mae = np.mean(np.abs(hidden_ratings_array - predicted_ratings_array)) # Calculate Mean Absolute Error (MAE)\n",
    "mse = np.mean((hidden_ratings_array - predicted_ratings_array) ** 2) # Calculate Mean Squared Error (MSE)\n",
    "rmse = np.sqrt(mse) # Calculate Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: calculate Classification Metrics (take the hidden ratings and the predicted ratings and binarise them) ==========================================================================\n",
    "\n",
    "# Binarise the hidden ratings and predicted ratings\n",
    "threshold = 3.5\n",
    "binary_prediction_ratings = (predicted_ratings_array >= threshold).astype(int) \n",
    "print(f\"If predicted rating is greater than or equal to {threshold}, then 1, else 0\\n\")\n",
    "print(\"Predicted Ratings:\", predicted_ratings_array)\n",
    "print(\"Binary Predictions:\", binary_prediction_ratings)\n",
    "binary_hidden_ratings = (hidden_ratings_array >= threshold).astype(int)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hidden Ratings:\", hidden_ratings_array)\n",
    "print(\"Binary Hidden Ratings:\", binary_hidden_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate accuracy using sklearn\n",
    "print(\"Using sklearn\")\n",
    "accuracy = accuracy_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "precision = precision_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "recall = recall_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "f1 = f1_score(binary_hidden_ratings, binary_prediction_ratings)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# calculate accuracy manually\n",
    "print(\"\\n\\nManually\")\n",
    "true_positives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 1))\n",
    "true_negatives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 0))\n",
    "false_positives = np.sum((binary_hidden_ratings == 0) & (binary_prediction_ratings == 1))\n",
    "false_negatives = np.sum((binary_hidden_ratings == 1) & (binary_prediction_ratings == 0))\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
