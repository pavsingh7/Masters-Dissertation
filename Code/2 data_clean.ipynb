{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Data Cleaning and Processing](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Cleaning and Processing](#toc1_)    \n",
    "- [Data Cleaning Processes](#toc2_)    \n",
    "  - [Removing Unnecessary Columns](#toc2_1_)    \n",
    "  - [NaN/Missing Values in the Data](#toc2_2_)    \n",
    "  - [Duplicates in the Data](#toc2_3_)    \n",
    "  - [Outliers in the Data](#toc2_4_)    \n",
    "  - [Standardizing and Checking Data Types](#toc2_5_)    \n",
    "  - [Normalizing Data](#toc2_6_)    \n",
    "  - [Check Data Imbalance](#toc2_7_)    \n",
    "- [Dealing with Categorical Data](#toc3_)    \n",
    "- [Dealing with Text Data](#toc4_)    \n",
    "  - [Text Normalization](#toc4_1_)    \n",
    "    - [Description](#toc4_1_1_)    \n",
    "    - [Title](#toc4_1_2_)    \n",
    "    - [Brand](#toc4_1_3_)    \n",
    "    - [Category](#toc4_1_4_)    \n",
    "    - [ReviewText](#toc4_1_5_)    \n",
    "  - [Text Cleaning](#toc4_2_)    \n",
    "    - [Tokenization](#toc4_2_1_)    \n",
    "    - [ Stopword Removal](#toc4_2_2_)    \n",
    "    - [Stemming and Lemmatization](#toc4_2_3_)    \n",
    "- [Sentiment Analysis](#toc5_)    \n",
    "  - [Sentiment Analysis using Lexicon-based Methods](#toc5_1_)    \n",
    "    - [VADER](#toc5_1_1_)    \n",
    "    - [TextBlob](#toc5_1_2_)    \n",
    "    - [Bing, AFINN, and NRC](#toc5_1_3_)    \n",
    "    - [Comparison of Lexicon-based Methods](#toc5_1_4_)    \n",
    "- [Creating New Dataset and Saving](#toc6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset (removing all variables, functions, and other objects from memory)\n",
    "%reset -f\n",
    "\n",
    "# import all the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workbook we will clean and process the data for the project. We will also create a new dataset that will be used for the analysis. This dataset will be saved as a csv file and will be used in the analysis workbook. Specifically, we will do the following:\n",
    "\n",
    "1. Load the data from the csv file created in the data loadings workbook\n",
    "2. Clean the data by:\n",
    "    - removing or looking at columns that are not needed\n",
    "    - looking at missing values\n",
    "    - looking at duplicates\n",
    "    - looking at outliers\n",
    "    - standardizing and checking data types\n",
    "    - deal with text data\n",
    "    - deal with categorical data (categories)\n",
    "    - check for data consistency across columns\n",
    "    - look at normalizing data (price, votes, etc. )\n",
    "    - Looking at rows with missing values\n",
    "    - check data balance\n",
    "    - feature engineering (sentiment analysis, etc.)\n",
    "\n",
    "3. Create a new dataset\n",
    "4. Save the new dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Data Cleaning Processes](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/7wlh6jzj03185p7x7ggqb_280000gn/T/ipykernel_41709/4228232554.py:5: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set1_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# load data - MAC OS\n",
    "# amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/all_revs_with_records_1.csv', low_memory=False)\n",
    "\n",
    "# # load data - Set 1\n",
    "amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set1_data.csv')\n",
    "\n",
    "# # load data - Set 2\n",
    "# amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set2_data.csv')\n",
    "\n",
    "# # load data - Set 3\n",
    "# amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set3_data.csv')\n",
    "\n",
    "# load data - Set 4\n",
    "# amz_rev = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/set4_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 11, 2017</td>\n",
       "      <td>A33PVCHCQ2BTN0</td>\n",
       "      <td>B0010ZBORW</td>\n",
       "      <td>{'Color:': ' Nail Brush'}</td>\n",
       "      <td>VW</td>\n",
       "      <td>I really like this nail brush from Urban Spa. ...</td>\n",
       "      <td>Handy nail brush, gets garden dirt out from un...</td>\n",
       "      <td>1505088000</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 2, 2017</td>\n",
       "      <td>A2503LT8PZIHAD</td>\n",
       "      <td>B0010ZBORW</td>\n",
       "      <td>{'Color:': ' Foot File'}</td>\n",
       "      <td>Trouble</td>\n",
       "      <td>This is about the same quality foot file as th...</td>\n",
       "      <td>Basic foot file</td>\n",
       "      <td>1504310400</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>02 21, 2018</td>\n",
       "      <td>A1MAI0TUIM3R2X</td>\n",
       "      <td>B001LNODUS</td>\n",
       "      <td>{'Color:': ' Body Lotion'}</td>\n",
       "      <td>Princess Bookworm</td>\n",
       "      <td>Nice lavender lotion that absorbs easily in my...</td>\n",
       "      <td>Fragrant Lavender Lotion</td>\n",
       "      <td>1519171200</td>\n",
       "      <td>beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0     False  09 11, 2017  A33PVCHCQ2BTN0  B0010ZBORW   \n",
       "1      4.0     False   09 2, 2017  A2503LT8PZIHAD  B0010ZBORW   \n",
       "2      4.0     False  02 21, 2018  A1MAI0TUIM3R2X  B001LNODUS   \n",
       "\n",
       "                        style       reviewerName  \\\n",
       "0   {'Color:': ' Nail Brush'}                 VW   \n",
       "1    {'Color:': ' Foot File'}            Trouble   \n",
       "2  {'Color:': ' Body Lotion'}  Princess Bookworm   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I really like this nail brush from Urban Spa. ...   \n",
       "1  This is about the same quality foot file as th...   \n",
       "2  Nice lavender lotion that absorbs easily in my...   \n",
       "\n",
       "                                             summary  unixReviewTime category  \\\n",
       "0  Handy nail brush, gets garden dirt out from un...      1505088000   beauty   \n",
       "1                                    Basic foot file      1504310400   beauty   \n",
       "2                           Fragrant Lavender Lotion      1519171200   beauty   \n",
       "\n",
       "  vote image  \n",
       "0  NaN   NaN  \n",
       "1  NaN   NaN  \n",
       "2  NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (1103032, 13)\n"
     ]
    }
   ],
   "source": [
    "#  drop column 'Unnamed: 0' or 'Unnamed: 0.1'\n",
    "amz_rev = amz_rev.drop(columns=['Unnamed: 0.1'])\n",
    "amz_rev = amz_rev.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# initial data view\n",
    "display(amz_rev.head(3))\n",
    "print(\"Shape of the data: \", amz_rev.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Removing Unnecessary Columns](#toc0_)\n",
    "\n",
    "We look at removing columns that are not needed for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the data: \n",
      " Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
      "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'category',\n",
      "       'vote', 'image'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# see columns\n",
    "print(\"Columns in the data: \\n\", amz_rev.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A33PVCHCQ2BTN0</td>\n",
       "      <td>B0010ZBORW</td>\n",
       "      <td>VW</td>\n",
       "      <td>I really like this nail brush from Urban Spa. ...</td>\n",
       "      <td>1505088000</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A2503LT8PZIHAD</td>\n",
       "      <td>B0010ZBORW</td>\n",
       "      <td>Trouble</td>\n",
       "      <td>This is about the same quality foot file as th...</td>\n",
       "      <td>1504310400</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A1MAI0TUIM3R2X</td>\n",
       "      <td>B001LNODUS</td>\n",
       "      <td>Princess Bookworm</td>\n",
       "      <td>Nice lavender lotion that absorbs easily in my...</td>\n",
       "      <td>1519171200</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall      reviewerID        asin       reviewerName  \\\n",
       "0      5.0  A33PVCHCQ2BTN0  B0010ZBORW                 VW   \n",
       "1      4.0  A2503LT8PZIHAD  B0010ZBORW            Trouble   \n",
       "2      4.0  A1MAI0TUIM3R2X  B001LNODUS  Princess Bookworm   \n",
       "\n",
       "                                          reviewText  unixReviewTime category  \n",
       "0  I really like this nail brush from Urban Spa. ...      1505088000   beauty  \n",
       "1  This is about the same quality foot file as th...      1504310400   beauty  \n",
       "2  Nice lavender lotion that absorbs easily in my...      1519171200   beauty  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove certain columns\n",
    "amz_rev.drop(['verified', 'style', 'reviewTime', 'vote', 'summary', 'image'], axis=1, inplace=True)\n",
    "\n",
    "# see updated dataframe\n",
    "display(amz_rev.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>1070236800</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>The classic of Trans-Siberian Orchestra.  This...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>1166745600</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>In the 1980s, Mannheim Steamroller took Christ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>LOVE IT!</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName  unixReviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane      1070236800  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal      1166745600  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock      1438732800  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  The classic of Trans-Siberian Orchestra.  This...  cds_and_vinyl   \n",
       "231082  In the 1980s, Mannheim Steamroller took Christ...  cds_and_vinyl   \n",
       "232494                                           LOVE IT!  cds_and_vinyl   \n",
       "\n",
       "        overall  \n",
       "229835      5.0  \n",
       "231082      5.0  \n",
       "232494      5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort and order the data\n",
    "amz_rev.sort_values(by=['asin', 'overall'], ascending=[True, False], inplace=True)\n",
    "\n",
    "# reorder columns\n",
    "amz_rev = amz_rev[['reviewerID', 'reviewerName', 'unixReviewTime', 'asin', 'reviewText', 'category', 'overall']]\n",
    "\n",
    "# see updated dataframe\n",
    "display(amz_rev.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[NaN/Missing Values in the Data](#toc0_)\n",
    "\n",
    "We look at NaN values in the data. If any review (row) has missing values (NaN) in any column listed here:\n",
    "    - (description, title, brand, price)\n",
    "then we remove that review (row) from the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID          0\n",
       "reviewerName      325\n",
       "unixReviewTime      0\n",
       "asin                0\n",
       "reviewText        436\n",
       "category            0\n",
       "overall             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many nulls in each column\n",
    "amz_rev.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with null values\n",
    "amz_rev = amz_rev.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (1102271, 7)\n",
      "\n",
      "Number of missing values:  0\n",
      "\n",
      "Percentage of missing values in each column: \n",
      " reviewerID        0.0\n",
      "reviewerName      0.0\n",
      "unixReviewTime    0.0\n",
      "asin              0.0\n",
      "reviewText        0.0\n",
      "category          0.0\n",
      "overall           0.0\n",
      "dtype: float64\n",
      "\n",
      "Percentage of missing values in each category: \n",
      " category\n",
      "appliances                    0.0\n",
      "arts_crafts                   0.0\n",
      "automotive                    0.0\n",
      "beauty                        0.0\n",
      "cds_and_vinyl                 0.0\n",
      "cell_phones                   0.0\n",
      "clothing_shoes_and_jewelry    0.0\n",
      "digital_music                 0.0\n",
      "electronics                   0.0\n",
      "fashion                       0.0\n",
      "gift_cards                    0.0\n",
      "grocery_and_gourmet_food      0.0\n",
      "home_and_kitchen              0.0\n",
      "industrial                    0.0\n",
      "kindle_store                  0.0\n",
      "luxury_beauty                 0.0\n",
      "magazine_subscriptions        0.0\n",
      "movies_and_tv                 0.0\n",
      "musical_instruments           0.0\n",
      "office_products               0.0\n",
      "patio_lawn_and_garden         0.0\n",
      "pet_supplies                  0.0\n",
      "prime_pantry                  0.0\n",
      "software                      0.0\n",
      "sports_and_outdoors           0.0\n",
      "tools_and_home_improvement    0.0\n",
      "toys_and_games                0.0\n",
      "video_games                   0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# shape of the data\n",
    "print(\"Shape of the data: \", amz_rev.shape)\n",
    "\n",
    "# see if any missing values\n",
    "print(\"\\nNumber of missing values: \", amz_rev.isnull().sum().sum())\n",
    "\n",
    "# show count columns have missing values (as a percentage)\n",
    "print(\"\\nPercentage of missing values in each column: \\n\", round(amz_rev.isnull().sum()/len(amz_rev)*100,2))\n",
    "\n",
    "# show count of rows with missing data per category (as a percentage)\n",
    "print(\"\\nPercentage of missing values in each category: \\n\", round(amz_rev.groupby(['category']).apply(lambda x: x.isnull().sum()).sum(axis=1)/len(amz_rev)*100,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Duplicates in the Data](#toc0_)\n",
    "\n",
    "We looking at duplicates in the data.\n",
    "\n",
    "A duplicate is defined as a review (row) that has the same values across all columns. We remove duplicates from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  72731\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946377</th>\n",
       "      <td>AWG2O9C42XW5G</td>\n",
       "      <td>Oreo Cookie Cherry Cola 2018</td>\n",
       "      <td>1482710400</td>\n",
       "      <td>0782010792</td>\n",
       "      <td>this is a awesome movie. there is a reason why...</td>\n",
       "      <td>movies_and_tv</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960630</th>\n",
       "      <td>AWG2O9C42XW5G</td>\n",
       "      <td>Oreo Cookie Cherry Cola 2018</td>\n",
       "      <td>1482710400</td>\n",
       "      <td>0782010792</td>\n",
       "      <td>this is a awesome movie. there is a reason why...</td>\n",
       "      <td>movies_and_tv</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979022</th>\n",
       "      <td>AWG2O9C42XW5G</td>\n",
       "      <td>Oreo Cookie Cherry Cola 2018</td>\n",
       "      <td>1482710400</td>\n",
       "      <td>0782010792</td>\n",
       "      <td>this is a awesome movie. there is a reason why...</td>\n",
       "      <td>movies_and_tv</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951096</th>\n",
       "      <td>A16QODENBJVUI1</td>\n",
       "      <td>Robert Moore</td>\n",
       "      <td>1152144000</td>\n",
       "      <td>1424819210</td>\n",
       "      <td>I have an extremely conflicted relationship wi...</td>\n",
       "      <td>movies_and_tv</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID                  reviewerName  unixReviewTime  \\\n",
       "946377   AWG2O9C42XW5G  Oreo Cookie Cherry Cola 2018      1482710400   \n",
       "960630   AWG2O9C42XW5G  Oreo Cookie Cherry Cola 2018      1482710400   \n",
       "979022   AWG2O9C42XW5G  Oreo Cookie Cherry Cola 2018      1482710400   \n",
       "951096  A16QODENBJVUI1                  Robert Moore      1152144000   \n",
       "\n",
       "              asin                                         reviewText  \\\n",
       "946377  0782010792  this is a awesome movie. there is a reason why...   \n",
       "960630  0782010792  this is a awesome movie. there is a reason why...   \n",
       "979022  0782010792  this is a awesome movie. there is a reason why...   \n",
       "951096  1424819210  I have an extremely conflicted relationship wi...   \n",
       "\n",
       "             category  overall  \n",
       "946377  movies_and_tv      5.0  \n",
       "960630  movies_and_tv      5.0  \n",
       "979022  movies_and_tv      5.0  \n",
       "951096  movies_and_tv      5.0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if any duplicates\n",
    "print(\"Number of duplicates: \", amz_rev.duplicated().sum())\n",
    "\n",
    "# see duplicates\n",
    "amz_rev[amz_rev.duplicated(keep=False)].sort_values(by=['asin']).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>1070236800</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>The classic of Trans-Siberian Orchestra.  This...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>1166745600</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>In the 1980s, Mannheim Steamroller took Christ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>LOVE IT!</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName  unixReviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane      1070236800  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal      1166745600  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock      1438732800  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  The classic of Trans-Siberian Orchestra.  This...  cds_and_vinyl   \n",
       "231082  In the 1980s, Mannheim Steamroller took Christ...  cds_and_vinyl   \n",
       "232494                                           LOVE IT!  cds_and_vinyl   \n",
       "\n",
       "        overall  \n",
       "229835      5.0  \n",
       "231082      5.0  \n",
       "232494      5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (1029540, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "amz_rev.drop_duplicates(inplace=True)\n",
    "\n",
    "# see updated dataframe\n",
    "display(amz_rev.head(3))\n",
    "\n",
    "# shape of the data\n",
    "print(\"Shape of the data: \", amz_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(959425, 7)\n"
     ]
    }
   ],
   "source": [
    "# # data set 1\n",
    "amz_rev = amz_rev[amz_rev['asin'].isin(amz_rev.groupby('asin').size().reset_index(name='counts').query('counts >= 10')['asin'])]\n",
    "amz_rev = amz_rev[amz_rev['reviewerID'].isin(amz_rev.groupby('reviewerID').size().reset_index(name='counts').query('counts >= 10')['reviewerID'])]\n",
    "print(amz_rev.shape)\n",
    "\n",
    "# # data set 2\n",
    "# amz_rev = amz_rev[amz_rev['asin'].isin(amz_rev.groupby('asin').size().reset_index(name='counts').query('counts >= 12')['asin'])]\n",
    "# amz_rev = amz_rev[amz_rev['reviewerID'].isin(amz_rev.groupby('reviewerID').size().reset_index(name='counts').query('counts >= 12')['reviewerID'])]\n",
    "# print(amz_rev.shape)\n",
    "\n",
    "# # data set 3\n",
    "# amz_rev = amz_rev[amz_rev['asin'].isin(amz_rev.groupby('asin').size().reset_index(name='counts').query('counts >= 14')['asin'])]\n",
    "# amz_rev = amz_rev[amz_rev['reviewerID'].isin(amz_rev.groupby('reviewerID').size().reset_index(name='counts').query('counts >= 14')['reviewerID'])]\n",
    "# print(amz_rev.shape)\n",
    "\n",
    "# data set 4\n",
    "# amz_rev = amz_rev[amz_rev['asin'].isin(amz_rev.groupby('asin').size().reset_index(name='counts').query('counts >= 20')['asin'])]\n",
    "# amz_rev = amz_rev[amz_rev['reviewerID'].isin(amz_rev.groupby('reviewerID').size().reset_index(name='counts').query('counts >= 20')['reviewerID'])]\n",
    "# print(amz_rev.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Standardizing and Checking Data Types](#toc0_)\n",
    "\n",
    "We turn to standardizing and checking data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>The classic of Trans-Siberian Orchestra.  This...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>2006-12-22</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>In the 1980s, Mannheim Steamroller took Christ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>LOVE IT!</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName reviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane 2003-12-01  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal 2006-12-22  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock 2015-08-05  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  The classic of Trans-Siberian Orchestra.  This...  cds_and_vinyl   \n",
       "231082  In the 1980s, Mannheim Steamroller took Christ...  cds_and_vinyl   \n",
       "232494                                           LOVE IT!  cds_and_vinyl   \n",
       "\n",
       "        overall  \n",
       "229835      5.0  \n",
       "231082      5.0  \n",
       "232494      5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change unixReviewTime to datetime\n",
    "amz_rev['unixReviewTime'] = pd.to_datetime(amz_rev['unixReviewTime'], unit='s')\n",
    "\n",
    "# rename column: unixReviewTime to reviewTime\n",
    "amz_rev.rename(columns={'unixReviewTime': 'reviewTime'}, inplace=True)\n",
    "\n",
    "# see updated dataframe\n",
    "display(amz_rev.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID              object\n",
       "reviewerName            object\n",
       "reviewTime      datetime64[ns]\n",
       "asin                    object\n",
       "reviewText              object\n",
       "category                object\n",
       "overall                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "amz_rev.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[Normalizing Data](#toc0_)\n",
    "\n",
    "We look at normalizing data (price, votes, etc. ) We used min-max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    959425.000000\n",
       "mean          0.860155\n",
       "std           0.247412\n",
       "min           0.000000\n",
       "25%           0.750000\n",
       "50%           1.000000\n",
       "75%           1.000000\n",
       "max           1.000000\n",
       "Name: normalized_rating, dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get min and max for ratings\n",
    "min_rating = amz_rev['overall'].min()\n",
    "max_rating = amz_rev['overall'].max()\n",
    "\n",
    "# Normalize the ratings to a range from 0 to 1\n",
    "amz_rev['normalized_rating'] = (amz_rev['overall'] - min_rating) / (max_rating - min_rating)\n",
    "\n",
    "# see updated dataframe\n",
    "amz_rev.head(3)\n",
    "\n",
    "# see summary of normalized ratings\n",
    "amz_rev['normalized_rating'].describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '`normalized_rating`' column will contain the normalized ratings between 0 and 1, where 0 corresponds to the minimum rating and 1 corresponds to the maximum rating. Note, the '`normalized_rating`' column is created by subtracting the minimum value from each rating and dividing it by the range (maximum value minus minimum value).\n",
    "\n",
    "Ratings which were 1 are now 0 and ratings which were 5 are now 1 etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>The classic of Trans-Siberian Orchestra.  This...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>2006-12-22</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>In the 1980s, Mannheim Steamroller took Christ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>LOVE IT!</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName reviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane 2003-12-01  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal 2006-12-22  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock 2015-08-05  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  The classic of Trans-Siberian Orchestra.  This...  cds_and_vinyl   \n",
       "231082  In the 1980s, Mannheim Steamroller took Christ...  cds_and_vinyl   \n",
       "232494                                           LOVE IT!  cds_and_vinyl   \n",
       "\n",
       "        overall  normalized_rating  \n",
       "229835      5.0                1.0  \n",
       "231082      5.0                1.0  \n",
       "232494      5.0                1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see updated dataframe\n",
    "display(amz_rev.head(3))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Dealing with Text Data](#toc0_)\n",
    "\n",
    "We deal with text data. We have the following columns that contain text data:\n",
    "- description\n",
    "- title\n",
    "- brand\n",
    "- category\n",
    "- reviewText\n",
    "\n",
    "\n",
    "We handle each of these columns separately. We look out for: \n",
    "\n",
    "**Identify special characters or symbols**: Look for any special characters, symbols, or non-alphanumeric characters that may need to be cleaned or removed. These characters can sometimes interfere with downstream analysis or modeling.\n",
    "\n",
    "**Handle HTML tags or formatting**: If the 'description' column contains HTML tags or formatting, you may consider removing them or converting them into plain text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Text Normalization](#toc0_)\n",
    "\n",
    "**Text Normalization**: Text normalization is the process of transforming text into a single canonical form that it might not have had before. This is done by removing unnecessary characters, such as punctuation or special characters; converting all letters to lowercase or uppercase; and/or expanding abbreviations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_5_'></a>[ReviewText](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229835    the classic of trans-siberian orchestra. this ...\n",
       "231082    in the 1980s mannheim steamroller took christm...\n",
       "232494                                             love it!\n",
       "233609    this is one of my favorite cds. ive seen trans...\n",
       "234450    the album tells a story - it is a sweet story ...\n",
       "                                ...                        \n",
       "743429    fun collection. still as creepy as before but ...\n",
       "800044    im relatively new to the current game consoles...\n",
       "671916    bioshock has long been one of my favorite seri...\n",
       "719111    alright first im going to get this part out of...\n",
       "725017    sorry im giving every re-release a 1/5 stars b...\n",
       "Name: reviewText, Length: 959425, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see brand\n",
    "amz_rev['reviewText']\n",
    "\n",
    "# create function to clean brand column\n",
    "def clean_brand(text):\n",
    "    # Remove square brackets, single quotes, HTML tags, double quotes, commas, URLs, and CSS styling\n",
    "    text = re.sub(r\"\\[|\\]|\\'|<[^>]*>|\\\"|,|\\\\https?://[^\\s]+|{[^}]+}\", \"\", text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Remove common update notes\n",
    "    update_regex = r'update \\d+/\\d+/\\d+:'\n",
    "    text = re.sub(update_regex, '', text)\n",
    "\n",
    "    # Remove trailing punctuation\n",
    "    text = re.sub(r\"\\.$\", \"\", text)\n",
    "\n",
    "    # remove dates\n",
    "    text = re.sub(r'\\d{2}/\\d{2}/\\d{2}', '', text)\n",
    "\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# apply function to brand column\n",
    "amz_rev['reviewText'] = amz_rev['reviewText'].apply(clean_brand)\n",
    "\n",
    "# see updated dataframe\n",
    "amz_rev['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/7wlh6jzj03185p7x7ggqb_280000gn/T/ipykernel_41709/4155544511.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  amz_rev['reviewText'] = amz_rev['reviewText'].str.replace(\"[^a-zA-Z0-9\\s]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number records with special character in reviewText: 0\n"
     ]
    }
   ],
   "source": [
    "# check any special characters in title\n",
    "amz_rev[amz_rev['reviewText'].str.contains(\"[^a-zA-Z0-9\\s]\")]\n",
    "\n",
    "# replace special characters in title\n",
    "amz_rev['reviewText'] = amz_rev['reviewText'].str.replace(\"[^a-zA-Z0-9\\s]\", \"\")\n",
    "\n",
    "# count of records with special character in the title\n",
    "print(\"Number records with special character in reviewText:\", amz_rev[amz_rev['reviewText'].str.contains(\"[^a-zA-Z0-9\\s]\")]['asin'].unique().size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <a id='toc4_2_'></a>[Text Cleaning](#toc0_)\n",
    "\n",
    "We specifically explore: \n",
    "1. Tokenization\n",
    "2. Stopword Removal\n",
    "3. Stemming and Lemmatization\n",
    "4. Handling Noise and Irrelevant Information\n",
    "\n",
    "We do this for only the `reviewText` columns and the `description` columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>the classic of transsiberian orchestra this al...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>2006-12-22</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>in the 1980s mannheim steamroller took christm...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>love it</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233609</th>\n",
       "      <td>A1W4O4F225MSKD</td>\n",
       "      <td>Bearlady59</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>this is one of my favorite cds ive seen transs...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234450</th>\n",
       "      <td>A36VOVWL720LJ7</td>\n",
       "      <td>Babs</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>the album tells a story  it is a sweet story a...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236011</th>\n",
       "      <td>A22LU2IH0YX6EY</td>\n",
       "      <td>L. Gold</td>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>wanted it finally got it love the music every ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName reviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane 2003-12-01  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal 2006-12-22  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock 2015-08-05  0005164885   \n",
       "233609  A1W4O4F225MSKD     Bearlady59 2017-02-08  0005164885   \n",
       "234450  A36VOVWL720LJ7           Babs 2015-03-01  0005164885   \n",
       "236011  A22LU2IH0YX6EY        L. Gold 2015-11-21  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  the classic of transsiberian orchestra this al...  cds_and_vinyl   \n",
       "231082  in the 1980s mannheim steamroller took christm...  cds_and_vinyl   \n",
       "232494                                            love it  cds_and_vinyl   \n",
       "233609  this is one of my favorite cds ive seen transs...  cds_and_vinyl   \n",
       "234450  the album tells a story  it is a sweet story a...  cds_and_vinyl   \n",
       "236011  wanted it finally got it love the music every ...  cds_and_vinyl   \n",
       "\n",
       "        overall  normalized_rating  \n",
       "229835      5.0                1.0  \n",
       "231082      5.0                1.0  \n",
       "232494      5.0                1.0  \n",
       "233609      5.0                1.0  \n",
       "234450      5.0                1.0  \n",
       "236011      5.0                1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(amz_rev.head(6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_1_'></a>[Tokenization](#toc0_)\n",
    "\n",
    "**Tokenization**: Tokenization is the process of splitting text into smaller chunks, called tokens. Tokens are usually words, sentences, or individual characters. Tokenization is a crucial step in text analysis, as the meaning of a word can fundamentally change based on the tokens surrounding it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pavansingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Assuming amz_rev.reviewText are Pandas Series\n",
    "# Tokenize the text using a loop\n",
    "\n",
    "tokens_reviewText = []\n",
    "for text in amz_rev.reviewText:\n",
    "    if isinstance(text, str):\n",
    "        tokens_reviewText.append(word_tokenize(text))\n",
    "    else:\n",
    "        tokens_reviewText.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tokens_reviewText: 959425\n",
      "Shape of reviewText: 959425\n"
     ]
    }
   ],
   "source": [
    "# shape of tokens\n",
    "print(\"Shape of tokens_reviewText:\", len(tokens_reviewText))\n",
    "\n",
    "# shape of reviewText\n",
    "print(\"Shape of reviewText:\", len(amz_rev.reviewText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some output of review text tokens: [['the', 'classic', 'of', 'transsiberian', 'orchestra', 'this', 'album', 'is', 'a', 'wonderful', 'mix', 'of', 'christmas', 'favourites', 'and', 'newly', 'made', 'tracks', 'kicked', 'up', 'a', 'notch', 'this', 'is', 'what', 'theatrical', 'orchestral', 'rock', 'is', 'the', 'album', 'starts', 'with', 'an', 'angel', 'sent', 'down', 'from', 'god', 'to', 'bring', 'back', 'all', 'the', 'good', 'his', 'children', 'have', 'done', 'since', 'the', 'birth', 'of', 'jesus', 'the', 'angel', 'visits', 'many', 'places', 'and', 'we', 'are', 'given', 'many', 'stories', 'he', 'visits', 'sarajevo', 'during', 'the', 'war', 'he', 'hears', 'the', 'bombs', 'and', 'sees', 'the', 'fighting', 'but', 'he', 'can', 'still', 'hear', 'people', 'singing', 'the', 'joy', 'of', 'the', 'christmas', 'season', 'my', 'favourite', 'is', 'the', 'story', 'of', 'the', 'little', 'homelessgirl', 'who', 'ran', 'away', 'from', 'home', 'a', 'long', 'time', 'ago', 'she', 'is', 'destitute', 'and', 'has', 'nothing', 'she', 'visits', 'a', 'bar', 'and', 'a', 'bartender', 'and', 'the', 'bartender', 'is', 'moved', 'by', 'this', 'child', 'he', 'calls', 'a', 'cab', 'and', 'emptys', 'out', 'the', 'register', 'drawer', 'and', 'sends', 'the', 'child', 'to', 'her', 'home', 'where', 'she', 'is', 'greeted', 'by', 'her', 'loving', 'family', 'it', 'just', 'brings', 'tears', 'to', 'your', 'eyes', 'it', 'is', 'everyone', 'duty', 'to', 'own', 'this', 'christmas', 'classic'], ['in', 'the', '1980s', 'mannheim', 'steamroller', 'took', 'christmas', 'music', 'and', 'updated', 'it', 'for', 'a', 'new', 'century', 'a', 'decade', 'and', 'a', 'half', 'later', 'transsiberian', 'orchestra', 'continued', 'in', 'that', 'same', 'vein', 'this', 'time', 'adding', 'rock', 'and', 'roll', 'to', 'traditional', 'christmas', 'tunes', 'the', 'first', 'album', 'of', 'the', 'tso', 'trilogy', 'christmas', 'eve', 'and', 'other', 'stories', 'is', 'evidence', 'that', 'guitars', 'and', 'drum', 'kits', 'can', 'and', 'do', 'fit', 'in', 'well', 'with', 'holiday', 'classics', 'about', 'half', 'the', 'tunes', 'on', 'the', 'record', 'are', 'wellknown', 'o', 'come', 'all', 'ye', 'faithful', 'o', 'holy', 'night', 'while', 'the', 'other', 'half', 'are', 'original', 'while', 'all', 'the', 'songs', 'are', 'destined', 'to', 'become', 'holiday', 'classics', 'some', 'simply', 'stand', 'out', 'old', 'city', 'bar', 'an', 'original', 'piece', 'on', 'the', 'album', 'this', 'song', 'is', 'about', 'the', 'loneliness', 'that', 'some', 'people', 'feel', 'during', 'the', 'holidays', 'its', 'at', 'once', 'heartfelt', 'and', 'one', 'that', 'will', 'stay', 'with', 'you', 'the', 'prince', 'of', 'peace', 'transsiberian', 'orchestra', 'added', 'nativityesque', 'lyrics', 'to', 'the', 'holly', 'and', 'the', 'ivy', 'creating', 'a', 'song', 'that', 'reminds', 'all', 'of', 'the', 'reason', 'for', 'the', 'holiday', 'a', 'mad', 'russians', 'christmas', 'featuring', 'several', 'pieces', 'of', 'tchaikovskys', 'nutcracker', 'ballet', 'joined', 'together', 'in', 'a', 'frenzy', 'of', 'energy', 'this', 'song', 'captures', 'the', 'christmas', 'season', 'through', 'electric', 'guitars', 'and', 'the', 'feeling', 'of', 'sledding', 'in', 'the', 'snow', 'christmas', 'evesarajevo', '1224', 'a', 'rock', 'and', 'roll', 'maelstrom', 'of', 'guitars', 'drums', 'and', 'holiday', 'tunes', 'like', 'god', 'rest', 'ye', 'merry', 'gentlemen', 'and', 'carol', 'of', 'the', 'bells', 'woven', 'together', 'this', 'radiofriendly', 'piece', 'truly', 'captures', 'the', 'story', 'of', 'sarajevo', 'and', 'the', 'magic', 'of', 'christmas', 'eve', 'through', 'a', 'nearviolent', 'collision', 'of', 'music', 'and', 'emotion', 'transsiberian', 'picked', 'up', 'modern', 'christmas', 'music', 'where', 'mannheim', 'steamroller', 'left', 'off', 'taking', 'the', 'idea', 'and', 'bringing', 'it', 'to', 'soaring', 'new', 'heights', 'their', 'first', 'album', 'is', 'a', 'perfect', 'example', 'of', 'the', 'style', 'they', 'have', 'made', 'famous', 'ten', 'years', 'later']]\n"
     ]
    }
   ],
   "source": [
    "# Print the tokens\n",
    "print(\"Some output of review text tokens:\", tokens_reviewText[0:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_2_'></a>[ Stopword Removal](#toc0_)\n",
    "\n",
    "**Stopword Removal**: Stopwords are words that are commonly used in the English language, such as \"the,\" \"a,\" \"an,\" \"is,\" and \"are.\" These words are often removed from text during preprocessing as they can negatively impact downstream analysis, such as natural language processing and machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pavansingh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the set of English stopwords\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the tokens\n",
    "filtered_tokens_reviewText = [[word for word in tokens if word.lower() not in stopword_set] for tokens in tokens_reviewText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Text tokens after stop word removal: [['classic', 'transsiberian', 'orchestra', 'album', 'wonderful', 'mix', 'christmas', 'favourites', 'newly', 'made', 'tracks', 'kicked', 'notch', 'theatrical', 'orchestral', 'rock', 'album', 'starts', 'angel', 'sent', 'god', 'bring', 'back', 'good', 'children', 'done', 'since', 'birth', 'jesus', 'angel', 'visits', 'many', 'places', 'given', 'many', 'stories', 'visits', 'sarajevo', 'war', 'hears', 'bombs', 'sees', 'fighting', 'still', 'hear', 'people', 'singing', 'joy', 'christmas', 'season', 'favourite', 'story', 'little', 'homelessgirl', 'ran', 'away', 'home', 'long', 'time', 'ago', 'destitute', 'nothing', 'visits', 'bar', 'bartender', 'bartender', 'moved', 'child', 'calls', 'cab', 'emptys', 'register', 'drawer', 'sends', 'child', 'home', 'greeted', 'loving', 'family', 'brings', 'tears', 'eyes', 'everyone', 'duty', 'christmas', 'classic'], ['1980s', 'mannheim', 'steamroller', 'took', 'christmas', 'music', 'updated', 'new', 'century', 'decade', 'half', 'later', 'transsiberian', 'orchestra', 'continued', 'vein', 'time', 'adding', 'rock', 'roll', 'traditional', 'christmas', 'tunes', 'first', 'album', 'tso', 'trilogy', 'christmas', 'eve', 'stories', 'evidence', 'guitars', 'drum', 'kits', 'fit', 'well', 'holiday', 'classics', 'half', 'tunes', 'record', 'wellknown', 'come', 'ye', 'faithful', 'holy', 'night', 'half', 'original', 'songs', 'destined', 'become', 'holiday', 'classics', 'simply', 'stand', 'old', 'city', 'bar', 'original', 'piece', 'album', 'song', 'loneliness', 'people', 'feel', 'holidays', 'heartfelt', 'one', 'stay', 'prince', 'peace', 'transsiberian', 'orchestra', 'added', 'nativityesque', 'lyrics', 'holly', 'ivy', 'creating', 'song', 'reminds', 'reason', 'holiday', 'mad', 'russians', 'christmas', 'featuring', 'several', 'pieces', 'tchaikovskys', 'nutcracker', 'ballet', 'joined', 'together', 'frenzy', 'energy', 'song', 'captures', 'christmas', 'season', 'electric', 'guitars', 'feeling', 'sledding', 'snow', 'christmas', 'evesarajevo', '1224', 'rock', 'roll', 'maelstrom', 'guitars', 'drums', 'holiday', 'tunes', 'like', 'god', 'rest', 'ye', 'merry', 'gentlemen', 'carol', 'bells', 'woven', 'together', 'radiofriendly', 'piece', 'truly', 'captures', 'story', 'sarajevo', 'magic', 'christmas', 'eve', 'nearviolent', 'collision', 'music', 'emotion', 'transsiberian', 'picked', 'modern', 'christmas', 'music', 'mannheim', 'steamroller', 'left', 'taking', 'idea', 'bringing', 'soaring', 'new', 'heights', 'first', 'album', 'perfect', 'example', 'style', 'made', 'famous', 'ten', 'years', 'later']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the filtered tokens\n",
    "print(\"Review Text tokens after stop word removal:\", filtered_tokens_reviewText[0:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_2_3_'></a>[Stemming and Lemmatization](#toc0_)\n",
    "\n",
    "\n",
    "**Stemming and Lemmatization**: Stemming is the process of reducing a word to its stem, or its root form. For example, \"fishing,\" \"fished,\" \"fisher\" all reduce to the stem \"fish.\" Lemmatization is similar to stemming, but it brings context to the words. So, it links words with similar meaning to one word. For example, \"better\" and \"good\" are lemmatized to \"good.\"\n",
    "\n",
    "Stemming involves removing prefixes and suffixes from words to obtain the root form. For example, the word \"running\" would be stemmed to \"run.\" Stemming is a simpler and faster process but may result in the root form not being an actual word. This can lead to potential loss of meaning or incorrect interpretations.\n",
    "\n",
    "On the other hand, lemmatiation aims to determine the lemma or dictionary form of a word. It takes into account the word's context and part of speech, ensuring that the resulting lemma is a valid word. For example, the word \"running\" would be lemmatized to \"run.\" Lemmatization provides more accurate results but can be computationally more expensive compared to stemming.\n",
    "\n",
    "If preserving the exact meaning and interpretability of words is crucial for your recommender system, lemmatization would be a better choice. However, if speed and simplicity are more important, stemming could be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pavansingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words_revText = [[stemmer.stem(word) for word in tokens] for tokens in filtered_tokens_reviewText]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words_revText = [[lemmatizer.lemmatize(word) for word in tokens] for tokens in filtered_tokens_reviewText]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: [['classic', 'transsiberian', 'orchestra', 'album', 'wonderful', 'mix', 'christmas', 'favourites', 'newly', 'made', 'tracks', 'kicked', 'notch', 'theatrical', 'orchestral', 'rock', 'album', 'starts', 'angel', 'sent', 'god', 'bring', 'back', 'good', 'children', 'done', 'since', 'birth', 'jesus', 'angel', 'visits', 'many', 'places', 'given', 'many', 'stories', 'visits', 'sarajevo', 'war', 'hears', 'bombs', 'sees', 'fighting', 'still', 'hear', 'people', 'singing', 'joy', 'christmas', 'season', 'favourite', 'story', 'little', 'homelessgirl', 'ran', 'away', 'home', 'long', 'time', 'ago', 'destitute', 'nothing', 'visits', 'bar', 'bartender', 'bartender', 'moved', 'child', 'calls', 'cab', 'emptys', 'register', 'drawer', 'sends', 'child', 'home', 'greeted', 'loving', 'family', 'brings', 'tears', 'eyes', 'everyone', 'duty', 'christmas', 'classic'], ['1980s', 'mannheim', 'steamroller', 'took', 'christmas', 'music', 'updated', 'new', 'century', 'decade', 'half', 'later', 'transsiberian', 'orchestra', 'continued', 'vein', 'time', 'adding', 'rock', 'roll', 'traditional', 'christmas', 'tunes', 'first', 'album', 'tso', 'trilogy', 'christmas', 'eve', 'stories', 'evidence', 'guitars', 'drum', 'kits', 'fit', 'well', 'holiday', 'classics', 'half', 'tunes', 'record', 'wellknown', 'come', 'ye', 'faithful', 'holy', 'night', 'half', 'original', 'songs', 'destined', 'become', 'holiday', 'classics', 'simply', 'stand', 'old', 'city', 'bar', 'original', 'piece', 'album', 'song', 'loneliness', 'people', 'feel', 'holidays', 'heartfelt', 'one', 'stay', 'prince', 'peace', 'transsiberian', 'orchestra', 'added', 'nativityesque', 'lyrics', 'holly', 'ivy', 'creating', 'song', 'reminds', 'reason', 'holiday', 'mad', 'russians', 'christmas', 'featuring', 'several', 'pieces', 'tchaikovskys', 'nutcracker', 'ballet', 'joined', 'together', 'frenzy', 'energy', 'song', 'captures', 'christmas', 'season', 'electric', 'guitars', 'feeling', 'sledding', 'snow', 'christmas', 'evesarajevo', '1224', 'rock', 'roll', 'maelstrom', 'guitars', 'drums', 'holiday', 'tunes', 'like', 'god', 'rest', 'ye', 'merry', 'gentlemen', 'carol', 'bells', 'woven', 'together', 'radiofriendly', 'piece', 'truly', 'captures', 'story', 'sarajevo', 'magic', 'christmas', 'eve', 'nearviolent', 'collision', 'music', 'emotion', 'transsiberian', 'picked', 'modern', 'christmas', 'music', 'mannheim', 'steamroller', 'left', 'taking', 'idea', 'bringing', 'soaring', 'new', 'heights', 'first', 'album', 'perfect', 'example', 'style', 'made', 'famous', 'ten', 'years', 'later']]\n",
      "Stemmed words: [['classic', 'transsiberian', 'orchestra', 'album', 'wonder', 'mix', 'christma', 'favourit', 'newli', 'made', 'track', 'kick', 'notch', 'theatric', 'orchestr', 'rock', 'album', 'start', 'angel', 'sent', 'god', 'bring', 'back', 'good', 'children', 'done', 'sinc', 'birth', 'jesu', 'angel', 'visit', 'mani', 'place', 'given', 'mani', 'stori', 'visit', 'sarajevo', 'war', 'hear', 'bomb', 'see', 'fight', 'still', 'hear', 'peopl', 'sing', 'joy', 'christma', 'season', 'favourit', 'stori', 'littl', 'homelessgirl', 'ran', 'away', 'home', 'long', 'time', 'ago', 'destitut', 'noth', 'visit', 'bar', 'bartend', 'bartend', 'move', 'child', 'call', 'cab', 'empti', 'regist', 'drawer', 'send', 'child', 'home', 'greet', 'love', 'famili', 'bring', 'tear', 'eye', 'everyon', 'duti', 'christma', 'classic'], ['1980', 'mannheim', 'steamrol', 'took', 'christma', 'music', 'updat', 'new', 'centuri', 'decad', 'half', 'later', 'transsiberian', 'orchestra', 'continu', 'vein', 'time', 'ad', 'rock', 'roll', 'tradit', 'christma', 'tune', 'first', 'album', 'tso', 'trilog', 'christma', 'eve', 'stori', 'evid', 'guitar', 'drum', 'kit', 'fit', 'well', 'holiday', 'classic', 'half', 'tune', 'record', 'wellknown', 'come', 'ye', 'faith', 'holi', 'night', 'half', 'origin', 'song', 'destin', 'becom', 'holiday', 'classic', 'simpli', 'stand', 'old', 'citi', 'bar', 'origin', 'piec', 'album', 'song', 'loneli', 'peopl', 'feel', 'holiday', 'heartfelt', 'one', 'stay', 'princ', 'peac', 'transsiberian', 'orchestra', 'ad', 'nativityesqu', 'lyric', 'holli', 'ivi', 'creat', 'song', 'remind', 'reason', 'holiday', 'mad', 'russian', 'christma', 'featur', 'sever', 'piec', 'tchaikovski', 'nutcrack', 'ballet', 'join', 'togeth', 'frenzi', 'energi', 'song', 'captur', 'christma', 'season', 'electr', 'guitar', 'feel', 'sled', 'snow', 'christma', 'evesarajevo', '1224', 'rock', 'roll', 'maelstrom', 'guitar', 'drum', 'holiday', 'tune', 'like', 'god', 'rest', 'ye', 'merri', 'gentlemen', 'carol', 'bell', 'woven', 'togeth', 'radiofriendli', 'piec', 'truli', 'captur', 'stori', 'sarajevo', 'magic', 'christma', 'eve', 'nearviol', 'collis', 'music', 'emot', 'transsiberian', 'pick', 'modern', 'christma', 'music', 'mannheim', 'steamrol', 'left', 'take', 'idea', 'bring', 'soar', 'new', 'height', 'first', 'album', 'perfect', 'exampl', 'style', 'made', 'famou', 'ten', 'year', 'later']]\n",
      "Lemmatized words: [['classic', 'transsiberian', 'orchestra', 'album', 'wonderful', 'mix', 'christmas', 'favourite', 'newly', 'made', 'track', 'kicked', 'notch', 'theatrical', 'orchestral', 'rock', 'album', 'start', 'angel', 'sent', 'god', 'bring', 'back', 'good', 'child', 'done', 'since', 'birth', 'jesus', 'angel', 'visit', 'many', 'place', 'given', 'many', 'story', 'visit', 'sarajevo', 'war', 'hears', 'bomb', 'see', 'fighting', 'still', 'hear', 'people', 'singing', 'joy', 'christmas', 'season', 'favourite', 'story', 'little', 'homelessgirl', 'ran', 'away', 'home', 'long', 'time', 'ago', 'destitute', 'nothing', 'visit', 'bar', 'bartender', 'bartender', 'moved', 'child', 'call', 'cab', 'empty', 'register', 'drawer', 'sends', 'child', 'home', 'greeted', 'loving', 'family', 'brings', 'tear', 'eye', 'everyone', 'duty', 'christmas', 'classic'], ['1980s', 'mannheim', 'steamroller', 'took', 'christmas', 'music', 'updated', 'new', 'century', 'decade', 'half', 'later', 'transsiberian', 'orchestra', 'continued', 'vein', 'time', 'adding', 'rock', 'roll', 'traditional', 'christmas', 'tune', 'first', 'album', 'tso', 'trilogy', 'christmas', 'eve', 'story', 'evidence', 'guitar', 'drum', 'kit', 'fit', 'well', 'holiday', 'classic', 'half', 'tune', 'record', 'wellknown', 'come', 'ye', 'faithful', 'holy', 'night', 'half', 'original', 'song', 'destined', 'become', 'holiday', 'classic', 'simply', 'stand', 'old', 'city', 'bar', 'original', 'piece', 'album', 'song', 'loneliness', 'people', 'feel', 'holiday', 'heartfelt', 'one', 'stay', 'prince', 'peace', 'transsiberian', 'orchestra', 'added', 'nativityesque', 'lyric', 'holly', 'ivy', 'creating', 'song', 'reminds', 'reason', 'holiday', 'mad', 'russian', 'christmas', 'featuring', 'several', 'piece', 'tchaikovsky', 'nutcracker', 'ballet', 'joined', 'together', 'frenzy', 'energy', 'song', 'capture', 'christmas', 'season', 'electric', 'guitar', 'feeling', 'sledding', 'snow', 'christmas', 'evesarajevo', '1224', 'rock', 'roll', 'maelstrom', 'guitar', 'drum', 'holiday', 'tune', 'like', 'god', 'rest', 'ye', 'merry', 'gentleman', 'carol', 'bell', 'woven', 'together', 'radiofriendly', 'piece', 'truly', 'capture', 'story', 'sarajevo', 'magic', 'christmas', 'eve', 'nearviolent', 'collision', 'music', 'emotion', 'transsiberian', 'picked', 'modern', 'christmas', 'music', 'mannheim', 'steamroller', 'left', 'taking', 'idea', 'bringing', 'soaring', 'new', 'height', 'first', 'album', 'perfect', 'example', 'style', 'made', 'famous', 'ten', 'year', 'later']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original words:\", filtered_tokens_reviewText[0:2])\n",
    "print(\"Stemmed words:\", stemmed_words_revText[0:2])\n",
    "print(\"Lemmatized words:\", lemmatized_words_revText[0:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <a id='toc6_'></a>[Creating New Dataset and Saving](#toc0_)\n",
    "\n",
    "We create a new dataset using all the cleaning and processing done above and save it as a csv file called `data_clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stemmed_words_revText: 959425\n",
      "Shape of lemmatized_words_revText: 959425\n",
      "Shape of filtered_tokens_reviewText: 959425\n"
     ]
    }
   ],
   "source": [
    "# get shapes of all generated dataframes\n",
    "print(\"Shape of stemmed_words_revText:\", len(stemmed_words_revText))\n",
    "print(\"Shape of lemmatized_words_revText:\", len(lemmatized_words_revText))\n",
    "print(\"Shape of filtered_tokens_reviewText:\", len(filtered_tokens_reviewText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach stemmed words to dataframe\n",
    "amz_rev['stemmed_words_revText'] = stemmed_words_revText\n",
    "\n",
    "# attach lemmitized words to dataframe\n",
    "amz_rev['lemmatized_words_revText'] = lemmatized_words_revText\n",
    "\n",
    "# attach filtered tokens to dataframe\n",
    "amz_rev['filtered_tokens_revText'] = filtered_tokens_reviewText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229835</th>\n",
       "      <td>A1OKMIT8B373YD</td>\n",
       "      <td>djhexane</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>the classic of transsiberian orchestra this al...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[classic, transsiberian, orchestra, album, won...</td>\n",
       "      <td>[classic, transsiberian, orchestra, album, won...</td>\n",
       "      <td>[classic, transsiberian, orchestra, album, won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231082</th>\n",
       "      <td>A1SCJWCMQ3W3KK</td>\n",
       "      <td>Irishgal</td>\n",
       "      <td>2006-12-22</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>in the 1980s mannheim steamroller took christm...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1980, mannheim, steamrol, took, christma, mus...</td>\n",
       "      <td>[1980s, mannheim, steamroller, took, christmas...</td>\n",
       "      <td>[1980s, mannheim, steamroller, took, christmas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232494</th>\n",
       "      <td>AZOILH84GFKHO</td>\n",
       "      <td>L. Beth Stock</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>love it</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233609</th>\n",
       "      <td>A1W4O4F225MSKD</td>\n",
       "      <td>Bearlady59</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>this is one of my favorite cds ive seen transs...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[one, favorit, cd, ive, seen, transsiberian, o...</td>\n",
       "      <td>[one, favorite, cd, ive, seen, transsiberian, ...</td>\n",
       "      <td>[one, favorite, cds, ive, seen, transsiberian,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234450</th>\n",
       "      <td>A36VOVWL720LJ7</td>\n",
       "      <td>Babs</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>the album tells a story  it is a sweet story a...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[album, tell, stori, sweet, stori, music, great]</td>\n",
       "      <td>[album, tell, story, sweet, story, music, great]</td>\n",
       "      <td>[album, tells, story, sweet, story, music, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236011</th>\n",
       "      <td>A22LU2IH0YX6EY</td>\n",
       "      <td>L. Gold</td>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>0005164885</td>\n",
       "      <td>wanted it finally got it love the music every ...</td>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[want, final, got, love, music, everi, time, h...</td>\n",
       "      <td>[wanted, finally, got, love, music, every, tim...</td>\n",
       "      <td>[wanted, finally, got, love, music, every, tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID   reviewerName reviewTime        asin  \\\n",
       "229835  A1OKMIT8B373YD       djhexane 2003-12-01  0005164885   \n",
       "231082  A1SCJWCMQ3W3KK       Irishgal 2006-12-22  0005164885   \n",
       "232494   AZOILH84GFKHO  L. Beth Stock 2015-08-05  0005164885   \n",
       "233609  A1W4O4F225MSKD     Bearlady59 2017-02-08  0005164885   \n",
       "234450  A36VOVWL720LJ7           Babs 2015-03-01  0005164885   \n",
       "236011  A22LU2IH0YX6EY        L. Gold 2015-11-21  0005164885   \n",
       "\n",
       "                                               reviewText       category  \\\n",
       "229835  the classic of transsiberian orchestra this al...  cds_and_vinyl   \n",
       "231082  in the 1980s mannheim steamroller took christm...  cds_and_vinyl   \n",
       "232494                                            love it  cds_and_vinyl   \n",
       "233609  this is one of my favorite cds ive seen transs...  cds_and_vinyl   \n",
       "234450  the album tells a story  it is a sweet story a...  cds_and_vinyl   \n",
       "236011  wanted it finally got it love the music every ...  cds_and_vinyl   \n",
       "\n",
       "        overall  normalized_rating  \\\n",
       "229835      5.0                1.0   \n",
       "231082      5.0                1.0   \n",
       "232494      5.0                1.0   \n",
       "233609      5.0                1.0   \n",
       "234450      5.0                1.0   \n",
       "236011      5.0                1.0   \n",
       "\n",
       "                                    stemmed_words_revText  \\\n",
       "229835  [classic, transsiberian, orchestra, album, won...   \n",
       "231082  [1980, mannheim, steamrol, took, christma, mus...   \n",
       "232494                                             [love]   \n",
       "233609  [one, favorit, cd, ive, seen, transsiberian, o...   \n",
       "234450   [album, tell, stori, sweet, stori, music, great]   \n",
       "236011  [want, final, got, love, music, everi, time, h...   \n",
       "\n",
       "                                 lemmatized_words_revText  \\\n",
       "229835  [classic, transsiberian, orchestra, album, won...   \n",
       "231082  [1980s, mannheim, steamroller, took, christmas...   \n",
       "232494                                             [love]   \n",
       "233609  [one, favorite, cd, ive, seen, transsiberian, ...   \n",
       "234450   [album, tell, story, sweet, story, music, great]   \n",
       "236011  [wanted, finally, got, love, music, every, tim...   \n",
       "\n",
       "                                  filtered_tokens_revText  \n",
       "229835  [classic, transsiberian, orchestra, album, won...  \n",
       "231082  [1980s, mannheim, steamroller, took, christmas...  \n",
       "232494                                             [love]  \n",
       "233609  [one, favorite, cds, ive, seen, transsiberian,...  \n",
       "234450  [album, tells, story, sweet, story, music, great]  \n",
       "236011  [wanted, finally, got, love, music, every, tim...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see resulting dataframe\n",
    "amz_rev.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned data: (959425, 11)\n",
      "\n",
      "Number of unique products: 41182\n",
      "\n",
      "Number of unique users: 51524\n",
      "\n",
      "Number of unique categories: 28\n",
      "\n",
      "Number of reviews per category:\n",
      " video_games                   173032\n",
      "arts_crafts                   124943\n",
      "office_products               111452\n",
      "grocery_and_gourmet_food       77380\n",
      "prime_pantry                   74773\n",
      "patio_lawn_and_garden          64513\n",
      "musical_instruments            51529\n",
      "cds_and_vinyl                  41211\n",
      "movies_and_tv                  40959\n",
      "digital_music                  33103\n",
      "pet_supplies                   32551\n",
      "tools_and_home_improvement     26639\n",
      "industrial                     19966\n",
      "cell_phones                    16098\n",
      "luxury_beauty                  15537\n",
      "automotive                     12350\n",
      "toys_and_games                 10679\n",
      "electronics                     9669\n",
      "sports_and_outdoors             6952\n",
      "home_and_kitchen                6451\n",
      "software                        6096\n",
      "clothing_shoes_and_jewelry       944\n",
      "gift_cards                       839\n",
      "magazine_subscriptions           610\n",
      "beauty                           602\n",
      "kindle_store                     367\n",
      "fashion                          176\n",
      "appliances                         4\n",
      "Name: category, dtype: int64\n",
      "\n",
      "Columns available: Index(['reviewerID', 'reviewerName', 'reviewTime', 'asin', 'reviewText',\n",
      "       'category', 'overall', 'normalized_rating', 'stemmed_words_revText',\n",
      "       'lemmatized_words_revText', 'filtered_tokens_revText'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # save cleaned data\n",
    "amz_rev.to_csv(\"Data/set1_data_cleaned.csv\", index=False)\n",
    "\n",
    "# # save cleaned data\n",
    "# amz_rev.to_csv(\"Data/set2_data_cleaned.csv\", index=False)\n",
    "\n",
    "# # save cleaned data\n",
    "# amz_rev.to_csv(\"Data/set3_data_cleaned.csv\", index=False)\n",
    "\n",
    "# save cleaned data\n",
    "# amz_rev.to_csv(\"Data/set4_data_cleaned.csv\", index=False)\n",
    "\n",
    "\n",
    "# stats of cleaned data\n",
    "print(\"Shape of cleaned data:\", amz_rev.shape)\n",
    "print(\"\\nNumber of unique products:\", amz_rev['asin'].unique().size)\n",
    "print(\"\\nNumber of unique users:\", amz_rev['reviewerID'].unique().size)\n",
    "print(\"\\nNumber of unique categories:\", amz_rev['category'].unique().size)\n",
    "print(\"\\nNumber of reviews per category:\\n\", amz_rev['category'].value_counts())\n",
    "print(\"\\nColumns available:\", amz_rev.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "592720dbed1256d2a23d8b00e5ee6ece89b12c02a81b97be893b807d9576d7c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
