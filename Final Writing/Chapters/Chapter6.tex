% Chapter Template

\chapter{Conclusion} % Main chapter title
\label{Chapter6} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

In Chapter \ref{Chapter5}, we delved into the results from this paper and their implications concerning our research questions, including a deeper discussion of what was observed from our analysis in general. In this chapter, we aim to offer a comprehensive overview of the primary findings derived from this paper, representing the culmination of our research, and outlining their implications moving forward.

The chapter begins with an overview of the results and their alignment with our primary research questions (from \ref{sec:Research Questions and Significance}), encapsulating the key insights gained from the analyses conducted in this study, in Section \ref{sec:Summary of Results and Findings}. Following this, Section \ref{sec:Limitations} addresses the limitations of the paper, both from a perspective of limited experimentation, as well as from a perspective of various assumptions made. These identified shortcomings pave the way for Section \ref{sec:Future Work}, which explores potential avenues for further exploration or enhancement of the methodologies employed. Finally, we draw this paper to a close with Section \ref{sec:Conclusion for Conclusion}, which serves to summarise and raise key points to conclude this paper. 


\section{Summary of Results and Findings}
\label{sec:Summary of Results and Findings}
    
This section aims to provide a comprehensive overview of the main findings and contributions derived from this study. We begin by succinctly summarising the key results from Section \ref{sec:Results}, emphasising their significance with respect to the research questions from Section \ref{sec:Research Questions and Significance}. Moreover, we highlight any unexpected results and their significance, offering insights into limitations and further work, which shall be discussed in Sections \ref{sec:Limitations} and \ref{sec:Future Work}, respectively.


In Section \ref{sec:Results}, we evaluated the results from our study for two problems: rating prediction and Top-N generation. The evaluation of our proposed NCF model against benchmark models revealed notable advancements in predictive accuracy and Top-N evaluation metrics. Across all metrics considered, the NCF model consistently outperformed benchmark models, displaying superior performance in both predictive accuracy and Top-N metrics. Statistical analysis through paired t-tests confirmed the significance of these differences at a significance level of $p<0.01$. Notably, the review-aware NCF model, integrating ratings and review text, exhibited the best performance, achieving an MAE of 0.524 and RMSE of 0.769, while the inclusion of sentiment analysis alongside reviews marginally decreased performance, resulting in marginally higher RMSE and MAE values (MAE of 0.529 and RMSE of 0.779).

Directly addressing our research questions, the incorporation of review text significantly enhanced rating prediction performance within recommender systems. However, the addition of sentiments did not yield further improvements. Moreover, the efficacy of the NCF models was evident, performing better than all the benchmark models across all evaluation metrics used. Furthermore, the efficiency of the NCF models was particularly noteworthy with respect to computation, with shorter run-times compared to benchmark models, even when augmented with additional information such as review text and sentiments. For instance, the NCF model with review text and sentiments required only 112 minutes for model training, outperforming the fastest benchmark model, user-based collaborative filtering, which took 125 minutes. In contrast, non-negative matrix factorization (NMF) exhibited the longest runtime at 457 minutes, whilst item-based collaborative filtering took 140 minutes, as shown in Table \ref{tab:computational-details}.

While the efficiency of NCF models is commendable, it is essential to acknowledge the increased computational expense and model building complexity associated with the incorporation of review text and sentiments. This complexity entails the necessity of text pre-processing, word embeddings and augmentation by adjusting the structure of the neural architecture to accept additional inputs (beside numerical ratings). Furthermore, feature creation processes, including sentiment analysis techniques, add another layer of consideration, highlighting the importance of methodological rigor in incorporating textual information into recommendation models. 


    

\section{Limitations}
\label{sec:Limitations}

In this section, we critically examine the limitations and constraints inherent in our study, aiming to provide a transparent assessment of the factors that may have influenced our results, conclusions, and methodology. We shall begin by identifying and discussing the limitations encountered throughout the research process, acknowledging any constraints that may have impacted the comprehensiveness or generalisability of our findings. This shall be followed by inherent challenges encountered in the study which may have influenced the outcomes of our study, ensuring transparency in our analysis and interpretation. Through this comprehensive discussion, we aim to provide a nuanced understanding of the contextual factors shaping the interpretation of our findings.

In building our recommender system, our primary focus centered on rating predictions aimed at minimising the disparity between actual and predicted ratings. The overarching goal was to develop a recommendation system capable of accurately predicting unknown ratings for items, leveraging a training set to discern user preferences, and assessing the system's efficacy by evaluating its performance on a testing set containing concealed ratings provided by users for various items. This evaluation process involved measuring predictive accuracy metrics such as RMSE and MAE. Having achieved predicted ratings for all unrated items for each user we were able to identify a list of items (Top-N) by sorting the ratings for unrated items to identify a Top-N list of recommendations for each user. We measured this list using metrics such as Recall@K and Precision@K. The results of which were not impressive. In hindsight, these observations shed light on several limitations inherent in our study, prompting a critical reevaluation of our methodologies and approaches.

Firstly, we built the model for a specific goal - rating prediction, however we tested its capability on different task - Top-N generation. Considering we have established that there is no one universal recommender system (Lu et al, 2012) and that a recommender's performance is not transferable from one objective to another. Consequently, the results obtained from the Top-N generation task offer limited insights into the effectiveness of our review-aware NCF model in this specific use case. Indeed, while our recommender system excelled in predicting ratings for unknown products, its performance in generating Top-N recommendations was considerably less satisfactory. That is to say, we observed that the model struggled to recommend relevant (items in test set) products for a users Top-100, let alone Top-10 recommendations. Additionally, the sparse nature of user-item interactions, coupled with the limited data available for training and testing (only 3 items), posed significant challenges for the recommender system in identifying relevant items within a top recommendation list - i.e., it is difficult for the recommender system to identify from over 3000 items, 3 relevant items in a top 10 or top 100 list.

Secondly, our methodology sheds light on the inherent limitations imposed on the scope of evaluating and building our recommenders. Given the evolving understanding that recommendation accuracy alone does not guarantee an effective and satisfying user experience, our approach of generating a recommender solely for predicting unrated items provides a limited scope for building a good or useful recommender system. To address this limitation, it becomes imperative to extend beyond simple accuracy metrics and optimise recommenders for tasks beyond rating prediction. A holistic approach to recommender systems necessitates the incorporation of additional metrics that assess the system's overall performance, moving beyond constrained objectives like rating prediction. For instance, a recommender might achieve high accuracy by only computing predictions for easy-to-predict itemsâ€”but those are the very items for which users are least likely to need predictions. As articulated in recent research, a good recommender system should not only increase user satisfaction and engagement but also offer a superior user experience by reducing search costs and enhancing decision quality. Thus, the evaluation of recommender systems should encompass more than just ratings accuracy predictions, urging us to adopt a holistic view and assess performance across multiple dimensions to ensure a truly effective and user-centric recommendation experience.


Another key challenge and limitation encountered in this study pertained to the computational resources allocated to meet the paper's requirements. The entirety of dataset handling, model building, and training occurred on our local machine, devoid of external computing power, which presented considerable difficulties in managing the data effectively as well as inhibiting the path of additional experimentation. Despite our efforts, both the benchmark models and the constructed Neural Collaborative Filtering (NCF) models were restricted (due to their excessive run-times and memory allocations) in their tuning capabilities, with hyperparameter adjustments limited to only two or three options for each parameter. In the case of benchmark models, hyperparameter tuning was entirely omitted due to the extensive run times and large memory allocations observed during training, rendering grid search techniques impractical. We did, however, tweak the hyper-parameters for the NMF model slightly, as stipulated in Table \ref{tab:hyperparameters}. Consequently, default or arbitrary values were adopted for various other parameter. While it is not expected that the performance will be substantially improved, it could be worthwhile trying to quantify how much improvement can be gained by performing a large hyper-parameter search as compared to using a standard set of hyper- parameters. Although the implementation of NCF was kept simple, utilizing Multi-Layer Perceptron (MLP) and exploring basic variations in layers and optimisers, the exploration of additional or alternative architectures remained unexplored, since it was not of primary concern regarding out research questions to evaluate other deep-learning architectures. Ultimately, the computational constraints as well as the limited time dictated a lot of the decisions made in the methodology. This challenge also touches upon a broader issue of scalability, an aspect that was acknowledged in Section \ref{subsec: Scalability} but was not addressed within the scope of this paper. Nonetheless, given the context of the recommender system within e-commerce, scalability emerges as a primary concern. Addressing this concern could significantly enhance the run-times of benchmark models, particularly matrix factorization approaches, by leveraging packages specifically designed to handle the inherent sparsity of the user-item matrix. The benchmark models, detailed in Section \ref{sec:Benchmark Models}, were constructed from scratch in Python, with minimal effort directed towards mitigating scalability issues or managing the computational overhead of training.

One final limitation inherent in our paper is the omission of addressing the cold start problem and data sparsity. Data sparsity significantly impacted the performance of our models, manifesting in longer run-times and a dearth of interactions to establish larger training or test sets which had implications in the performance of our recommenders.  As outlined in Section \ref{subsec: Sparsity}, we consciously chose to overlook the inherent sparsity of user-item interactions in the dataset. However, this decision came at the expense of Top-N generation accuracy and model run-times. Huang et al. (2004) assert that an effective recommender algorithm must account for data sparsity to yield meaningful recommendations. Additionally, we chose to mitigate the cold start problem, or rather circumvent it entirely, by restricting the dataset to users with 12 or more ratings and items with 12 or more reviews. While this approach provides a starting point, it also presents opportunities for future research to enhance the robustness of our recommender system. Further details on potential avenues for extending the system's capabilities will be elaborated upon in the subsequent section.


\section{Future Work}
\label{sec:Future Work}

In this section, we explore potential avenues for future research, leveraging insights raised from the limitations identified in our study in the previous Section. We commence by emphasizing the importance of embracing a holistic perspective when designing recommender systems (RS), moving beyond the ratings paradigm of metrics to encompass a broader array of evaluation criteria - as discussed in Section \ref{sec: Evaluation Methods}. Following this, we shall discuss extending the NCF (NCF) model by possibly utilising more sophisticated architectures, such as the Neural Matrix Factorisation (NeuMF) architecture introduced by He et al (2017). We shall then look at exploring different pre-processing methods, including advanced word embedding techniques and sentiment analysis methodologies. We also address the potential of conducting a sensitivity analyses to assess the impact of varying test set sizes. Following this, we look at the perennial challenges such as the cold-start problem and data sparsity, which we excluded from the scope of this paper. Beyond these natural extensions to this paper, we shall also discuss the potential of incorporating a further data modality - images, as well as incorporating a temporal dimension. 

In the preceding section, we discussed the imperative for adopting a comprehensive approach to evaluating and (importantly) optimising a recommender to generate useful outcomes given the objective. This holistic perspective urges us to venture beyond conventional metrics and explore novel evaluation criteria, while simultaneously developing recommender system architectures capable of traversing diverse paradigms, including both rating prediction and Top-N recommendation. This is contrast to our methodology, were we built a recommender with the objective of prediction accuracy, however we also evaluated the model on Top-N generation - i.e., a task is what not trained (or optimised) for. Within our particular domain (E-commerce), avenues for generating more accurate recommendations while enhancing elements such as unexpectedness, novelty, serendipity, and diversity paves the way for interesting directions for future research that can take place to extend this model. For instance, although our study primarily focused on understanding user preferences to predict ratings for items, there remains a significant gap in rewarding recommenders for uncovering new products that may pique user interest (Herlocker et al., 1999), a key phenomenon that is pertinent for a recommender in E-commerce. Consequently, there exists ample scope for future work to delve into more user-centric metrics that better gauge the performance of our recommender model and assess the utility of its results. Various strategies can be employed to address this, including direct enhancement of recommendation list diversity and the integration of hybrid recommendation methods to meet different task objectives (Smyth and McClave, 2001; Ziegler et al., 2005; Hurley and Zhang, 2011; Zhou et al., 2010). Ultimately, future endeavors should prioritize the adoption of a more comprehensive approach to evaluating recommender systems, particularly in the context of E-commerce applications, as it promises to yield greater benefits and insights.

In our paper we introduced a neural-network based approach for collaborative filtering, drawing inspiration from the seminal work of He et al. (2017). Our rationale was straightforward: we sought to evaluate the impact of integrating deep learning architectures into the realm of collaborative filtering. The findings of our study  underscore the remarkable improvements in predictive accuracy achieved by the Neural Collaborative Filtering (NCF) model when compared to traditional memory and model-based collaborative filtering approaches, represented by our benchmark models. Building upon the framework laid out by He et al. (2017), further work can be explored to potentially hybridising the architecture of NCF by incorporating Matrix Factorization, resulting in the innovative Neural Matrix Factorization (NeuMF) - as detailed by He et al. (2017). The rationale behind this approach stems from the recognition that traditional Matrix Factorisation can be viewed as a specialized instance of NCF. Therefore, by fusing the neural interpretation of matrix factorisation with Multilayer Perceptron (MLP), NeuMF emerges as a more generalized model harnessing the linearity of Matrix Factorisation and the non-linearity of MLP to enhance recommendation quality. Notably, the empirical findings from studies such as Zhang et al. (2019) and He et al. (2017) corroborate the performance benefits offered by NeuMF over NCF. This naturally extends our comparative analysis, inviting us to integrate and adapt the advancements put forth by He et al. (2017) to incorporate NeuMF into our framework. This avenue for future can further be extended by investigating the augmentation of review text and sentiments within this enhanced framework â€” an area that, to the best of our knowledge, has not yet been explored. 


In our data pre-processing phase outlined in Section \ref{sec:Data Collection and Preprocessing}, we explained the rationale behind specific choices made to prepare our data, with particular emphasis on the treatment of review text. Notably, we delineated the methodology employed for word embedding and sentiment analysis, pivotal steps that warrant further investigation beyond the scope of this paper. While these choices were not directly evaluated within our study, their significance is reflected throughout the literature, underscoring their potential impact on the efficacy of recommender systems (Asudani et al, 2023). Therefore, it stands to reason that exploring additional word embedding techniques beyond the simple implementation undertaken in this paper would represent a natural extension of our research efforts. Furthermore, although our we experimented with several different types of lexicon-based approaches to sentiment analysis, as detailed in Section \ref{subsec:Sentiment Analysis}, there exists a compelling opportunity to explore deep-learning based sentiment analysis methodologies. Such an approach, can perhaps lead to more representative sentiments from the review text, thereby furnishing the model with richer insights into user preferences. Notably, the choice of sentiment analysis technique has been documented as an important determinant in feature creation for subsequent analysis in existing literature (Ahuja et al., 2019). Hence, by experimenting with more sophisticated sentiment analysis methodologies, there is an opportunity to further enhance the effectiveness of our recommender system.

The previous section highlighted a significant limitation stemming from the data constraints inherent in our study. Specifically, we grappled with the challenge of data sparsity and limited user-item interactions. We furthered the issue by imposing an additional constraint, such as sub-setting the data to ensure each user possessed a minimum of 12 reviews â€” a strategy aimed at mitigating the cold start problem. However, this approach led to us having a test set where each user had 3 items held out, when employing the leave-k-out methodology. Consequently, this constraint hindered the performance and utility of top-n generation, as elaborated earlier. To address these limitations and pave the way for more robust future research endeavors, it would be beneficial to conduct a sensitivity analysis to gauge the impact of varying test set sizes. Additionally, concerted efforts aimed at alleviating data sparsity concerns are warranted, as they are pivotal in enhancing the effectiveness and applicability of recommender systems. Likewise, proactive measures aimed at tackling the cold start problem, similarly, would prove to be valuable and support the robustness and versatility of the generated recommender systems. 


Lastly, the Amazon Product Review Data (\ref{subsec:Amazon Review Dataset}) utilised in this study presents additional opportunities for experimentation. Notably, each product within the dataset is accompanied by an image feature â€” an input that has garnered attention in research within several industries, particularly fashion E-commerce, where images have been leveraged to enrich the top-N generation process (Tuinhof et al, 2019; Kurt et al, 2017). By augmenting our recommender system to incorporate an additional data modality, such as images, there is opportunity for enhancing the efficacy of the model, building upon the foundation laid in this paper. Furthermore, the dataset offers a valuable temporal dimension, with each review provided by a user being timestamped, spanning a considerable time frame from 1996 to 2018. Harnessing this temporal aspect and tracking trends in user preferences over time could furnish the recommender system with valuable insights, enabling it to adapt and evolve in response to shifting user preferences. This not only facilitates a more comprehensive evaluation of the recommender system but also ensures its relevance and efficacy under realistic and dynamic conditions. 

\section{Conclusion}
\label{sec:Conclusion for Conclusion}

In the final Section of this paper, we reflect on the broader significance of our work, whilst also reiterating the key findings and contributions uncovered which potentially bear useful implications for the future trajectory of review-aware recommender systems. We begin by recalling the importance and purpose of recommender systems and collaborative filtering in general, highlighting their pivotal role in facilitating personalised recommendations tailored to individual user preferences. We then briefly summarise the key research questions, data and methodology. Building upon this foundation, we shed light on the results and implications, whilst also discussing the important limitations of the work.

Recommender systems play a crucial role in modern digital landscapes, acting as indispensable tools that guide users towards items they are likely to find valuable based on their individual preferences and the vast array of available options. For instance, the online retail giant Amazon, collect and analyse tons of user data, including past purchase behavior and browsing history. Amazon's recommender system constructs a detailed profile of each user's preferences, interests, and shopping habits. Armed with this insight, the system can seamlessly curate personalized recommendations tailored to each user's unique tastes and preferences. In essence, recommender system's leverage a combination of statistical algorithms and knowledge discovery techniques to sift through the overwhelming abundance of choices, effectively mitigating the problem of information overload that plagues modern consumers. By doing so, these systems empower users to efficiently navigate through cmany options, connecting them with products, services, or knowledge that resonate with their needs and interests. This ability to streamline the decision-making process has large implications for businesses, ranging from increased cross-selling opportunities to heightened customer satisfaction, ultimately translating into tangible gains in revenue and market competitiveness.

Collaborative filtering stands as one of the cornerstone paradigms within the realm of recommender systems. At its core, collaborative filtering operates on the principle of leveraging user-generated ratings and feedback to generate personalized recommendations. By harnessing the collective 'wisdom' (history) of users who have rated items they've interacted with, this technique effectively identifies patterns and similarities among user preferences. Through this process, collaborative filtering excels at uncovering latent relationships between users and items, enabling the system to make accurate predictions about items that a user may enjoy based on the preferences of similar users. This approach not only simplifies the recommendation process for users but also fosters a sense of community and interconnected-ness by facilitating the discovery of items based on shared interests and tastes. This approach, traditionally involved calculating and using similarity metrics, or perhaps matrix factorisation methods to build models to predict interest. However, there has been a growing interest in adapting traditional collaborative filtering framework to incorporate deep-learning based approaches - one such approach is neural collaborative filtering. A method introduced by He et al. (2017). 


Thus, the focal point of this paper was centered on harnessing a neural network-based approach for collaborative filtering, known as Neural Collaborative Filtering (NCF), with the objective of adapting the framework provided by He et al. (2017) to accommodate nuanced user preferences by incorporating review text and sentiments. The primary goals of the paper were to assess whether the incorporation of a neural network architecture in collaborative filtering enhances performance and whether augmenting a recommender with review text and sentiments yields similar improvements. Leveraging the Amazon product review dataset, extensive text cleaning and pre-processing, including word embedding and sentiment analysis, were conducted to prepare the data for integration into our neural architectures within the recommender models. Adhering to the widely adopted leave-k-out approach, we partitioned our data and designated 3 items from each user to form the test set. Our evaluation involved comparing the performance of our NCF systems with that of traditional collaborative filtering methods, namely item-based and user-based collaborative filtering, as well as non-negative matrix factorization (NMF). Due to long runtimes, the benchmark models were constrained to using generally default parameters, with minimal hyperparameter tuning for NMF. All recommender models were constructed and trained to excel in the rating prediction task, with the NCF model featuring a relatively simple MLP neural architecture augmented with additional layers to accommodate additional data inputs. Evaluation metrics such as MAE and RMSE were employed to assess the models' rating prediction capabilities. Additionally, we leveraged predicted ratings to generate Top-N recommendations for each user and evaluated the recommender systems' effectiveness using recall@K and precision@K metrics.


The outcomes of this study underscored the  efficacy of enhancing NCF with review text and sentiment analysis, particularly augmenting review text alone. These enhancements yielded remarkable improvements in recommendation performance compared to models exclusively reliant on conventional collaborative filtering methods or those utilizing ratings alone. Notably, the NCF model exhibited remarkable performance gains, manifesting in substantial reductions in RMSE and MAE upon integrating review text. This augmentation propelled the NCF model towards achieving more precise recommendations, surpassing baseline performance metrics and outperforming benchmark models. Such findings underscore the pivotal role of incorporating additional contextual information, such as review text, in enhancing the accuracy and effectiveness of recommender systems.

This paper concluded by addressing both the limitations inherent in the study and outlined potential avenues for future research that could build upon the current efforts. Among these possibilities is the prioritisation of a more comprehensive approach to building and evaluating recommender systems, whilst also emphasizing the importance of aligning the task assigned with the evaluation metrics employed. Additionally, we highlighted the potential for enhancing the NCF model by incorporating insights from the work of He et al. (2017), who introduced a hybrid model termed NeuMF that integrates matrix factorization techniques into the standard NCF architecture. Furthermore, we emphasized the importance of additional care and experimentation in the pre-processing of textual data, advocating for the adoption of more sophisticated methods of word embedding and sentiment analysis. These points represent just a glimpse of the potential areas for exploration and refinement outlined in this section.

In culmination, this thesis aimed to make incremental contributions to the evolving landscape of recommender systems, with a specific focus on harnessing textual information to augment recommendation accuracy. While our endeavor sought to pave the way for enhanced recommendation accuracy, we acknowledge the hurdles and constraints inherent in crafting recommendation systems capable of adeptly catering to user preferences and item characteristics. The avenues for future work lay bare and offer great potential for expanding the scope of our endeavors and enriching recommendation algorithms.