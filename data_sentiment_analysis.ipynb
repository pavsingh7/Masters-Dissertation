{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "# <a id='toc5_'></a>[Sentiment Analysis](#toc0_)\n",
    "\n",
    "We perform sentiment analysis on the reviewText column. We conduct one types of sentiment analysis: \n",
    "\n",
    "1. Sentiment Analysis using Lexicon-based Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from csv file\n",
    "#amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_rev_cleaned.csv')\n",
    "\n",
    "# read in sample file\n",
    "amz_data = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_rev_sample.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category_x</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>stemmed_words_desc</th>\n",
       "      <th>lemmatized_words_desc</th>\n",
       "      <th>filtered_tokens_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1EH1BOGG3K8FG</td>\n",
       "      <td>AndiO</td>\n",
       "      <td>2013-09-24</td>\n",
       "      <td>B0012TDR9E</td>\n",
       "      <td>american weigh scales h110 digital hanging sca...</td>\n",
       "      <td>american weigh scales</td>\n",
       "      <td>the hseries portable hanging scale is a vertic...</td>\n",
       "      <td>this scale is perfect for what we needed i nee...</td>\n",
       "      <td>clothing shoes and jewelry</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>['scale', 'perfect', 'need', 'need', 'easi', '...</td>\n",
       "      <td>['scale', 'perfect', 'needed', 'needed', 'easy...</td>\n",
       "      <td>['scale', 'perfect', 'needed', 'needed', 'easy...</td>\n",
       "      <td>['hseri', 'portabl', 'hang', 'scale', 'vertic'...</td>\n",
       "      <td>['hseries', 'portable', 'hanging', 'scale', 'v...</td>\n",
       "      <td>['hseries', 'portable', 'hanging', 'scale', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A32DEYY4A7EJEW</td>\n",
       "      <td>Sheri Adkins</td>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>B012P73O9O</td>\n",
       "      <td>s6 case galaxy s6 case iluvcell beautifully co...</td>\n",
       "      <td>iluvcell</td>\n",
       "      <td>this case is only compatible with samsung gala...</td>\n",
       "      <td>not a very good protective case but its cute</td>\n",
       "      <td>cell phones</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>['good', 'protect', 'case', 'cute']</td>\n",
       "      <td>['good', 'protective', 'case', 'cute']</td>\n",
       "      <td>['good', 'protective', 'case', 'cute']</td>\n",
       "      <td>['case', 'compat', 'samsung', 'galaxi', 's6', ...</td>\n",
       "      <td>['case', 'compatible', 'samsung', 'galaxy', 's...</td>\n",
       "      <td>['case', 'compatible', 'samsung', 'galaxy', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A25VMR199B567O</td>\n",
       "      <td>pohlcat01</td>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>B001BZ6ZSE</td>\n",
       "      <td>zebra pen 46820 zebra sarasa retractable gel i...</td>\n",
       "      <td>zebra pen</td>\n",
       "      <td>dfgghfhhffg</td>\n",
       "      <td>my wifes favorite pens she has like every color</td>\n",
       "      <td>office products</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>['wife', 'favorit', 'pen', 'like', 'everi', 'c...</td>\n",
       "      <td>['wife', 'favorite', 'pen', 'like', 'every', '...</td>\n",
       "      <td>['wifes', 'favorite', 'pens', 'like', 'every',...</td>\n",
       "      <td>['dfgghfhhffg']</td>\n",
       "      <td>['dfgghfhhffg']</td>\n",
       "      <td>['dfgghfhhffg']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1NWGBDJ06W9BH</td>\n",
       "      <td>Debra A. Huntley</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>B014S24DAI</td>\n",
       "      <td>amazoncom gift card in a red gift box reveal</td>\n",
       "      <td>amazon</td>\n",
       "      <td>amazoncom gift cards are the perfect way to gi...</td>\n",
       "      <td>cant go wrong with a gift card</td>\n",
       "      <td>gift cards</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>['cant', 'go', 'wrong', 'gift', 'card']</td>\n",
       "      <td>['cant', 'go', 'wrong', 'gift', 'card']</td>\n",
       "      <td>['cant', 'go', 'wrong', 'gift', 'card']</td>\n",
       "      <td>['amazoncom', 'gift', 'card', 'perfect', 'way'...</td>\n",
       "      <td>['amazoncom', 'gift', 'card', 'perfect', 'way'...</td>\n",
       "      <td>['amazoncom', 'gift', 'cards', 'perfect', 'way...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID      reviewerName  reviewTime        asin  \\\n",
       "0  A1EH1BOGG3K8FG             AndiO  2013-09-24  B0012TDR9E   \n",
       "1  A32DEYY4A7EJEW      Sheri Adkins  2015-11-08  B012P73O9O   \n",
       "2  A25VMR199B567O         pohlcat01  2015-08-18  B001BZ6ZSE   \n",
       "3  A1NWGBDJ06W9BH  Debra A. Huntley  2016-12-18  B014S24DAI   \n",
       "\n",
       "                                               title                  brand  \\\n",
       "0  american weigh scales h110 digital hanging sca...  american weigh scales   \n",
       "1  s6 case galaxy s6 case iluvcell beautifully co...               iluvcell   \n",
       "2  zebra pen 46820 zebra sarasa retractable gel i...              zebra pen   \n",
       "3       amazoncom gift card in a red gift box reveal                 amazon   \n",
       "\n",
       "                                         description  \\\n",
       "0  the hseries portable hanging scale is a vertic...   \n",
       "1  this case is only compatible with samsung gala...   \n",
       "2                                        dfgghfhhffg   \n",
       "3  amazoncom gift cards are the perfect way to gi...   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  this scale is perfect for what we needed i nee...   \n",
       "1       not a very good protective case but its cute   \n",
       "2    my wifes favorite pens she has like every color   \n",
       "3                     cant go wrong with a gift card   \n",
       "\n",
       "                   category_x  overall  normalized_rating  \\\n",
       "0  clothing shoes and jewelry      4.0               0.75   \n",
       "1                 cell phones      3.0               0.50   \n",
       "2             office products      5.0               1.00   \n",
       "3                  gift cards      5.0               1.00   \n",
       "\n",
       "                               stemmed_words_revText  \\\n",
       "0  ['scale', 'perfect', 'need', 'need', 'easi', '...   \n",
       "1                ['good', 'protect', 'case', 'cute']   \n",
       "2  ['wife', 'favorit', 'pen', 'like', 'everi', 'c...   \n",
       "3            ['cant', 'go', 'wrong', 'gift', 'card']   \n",
       "\n",
       "                            lemmatized_words_revText  \\\n",
       "0  ['scale', 'perfect', 'needed', 'needed', 'easy...   \n",
       "1             ['good', 'protective', 'case', 'cute']   \n",
       "2  ['wife', 'favorite', 'pen', 'like', 'every', '...   \n",
       "3            ['cant', 'go', 'wrong', 'gift', 'card']   \n",
       "\n",
       "                             filtered_tokens_revText  \\\n",
       "0  ['scale', 'perfect', 'needed', 'needed', 'easy...   \n",
       "1             ['good', 'protective', 'case', 'cute']   \n",
       "2  ['wifes', 'favorite', 'pens', 'like', 'every',...   \n",
       "3            ['cant', 'go', 'wrong', 'gift', 'card']   \n",
       "\n",
       "                                  stemmed_words_desc  \\\n",
       "0  ['hseri', 'portabl', 'hang', 'scale', 'vertic'...   \n",
       "1  ['case', 'compat', 'samsung', 'galaxi', 's6', ...   \n",
       "2                                    ['dfgghfhhffg']   \n",
       "3  ['amazoncom', 'gift', 'card', 'perfect', 'way'...   \n",
       "\n",
       "                               lemmatized_words_desc  \\\n",
       "0  ['hseries', 'portable', 'hanging', 'scale', 'v...   \n",
       "1  ['case', 'compatible', 'samsung', 'galaxy', 's...   \n",
       "2                                    ['dfgghfhhffg']   \n",
       "3  ['amazoncom', 'gift', 'card', 'perfect', 'way'...   \n",
       "\n",
       "                                filtered_tokens_desc  \n",
       "0  ['hseries', 'portable', 'hanging', 'scale', 'v...  \n",
       "1  ['case', 'compatible', 'samsung', 'galaxy', 's...  \n",
       "2                                    ['dfgghfhhffg']  \n",
       "3  ['amazoncom', 'gift', 'cards', 'perfect', 'way...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data\n",
    "amz_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data => (49622, 17)\n",
      "Number of unique products => 41013\n",
      "Number of unique users => 46067\n"
     ]
    }
   ],
   "source": [
    "# data summary\n",
    "print(\"Shape of data =>\", amz_data.shape)\n",
    "print(\"Number of unique products =>\", amz_data['asin'].nunique())\n",
    "print(\"Number of unique users =>\", amz_data['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>category_x</th>\n",
       "      <th>overall</th>\n",
       "      <th>normalized_rating</th>\n",
       "      <th>stemmed_words_revText</th>\n",
       "      <th>lemmatized_words_revText</th>\n",
       "      <th>filtered_tokens_revText</th>\n",
       "      <th>stemmed_words_desc</th>\n",
       "      <th>lemmatized_words_desc</th>\n",
       "      <th>filtered_tokens_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1EH1BOGG3K8FG</td>\n",
       "      <td>AndiO</td>\n",
       "      <td>2013-09-24</td>\n",
       "      <td>B0012TDR9E</td>\n",
       "      <td>american weigh scales h110 digital hanging sca...</td>\n",
       "      <td>american weigh scales</td>\n",
       "      <td>the hseries portable hanging scale is a vertic...</td>\n",
       "      <td>this scale is perfect for what we needed i nee...</td>\n",
       "      <td>clothing shoes and jewelry</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[scale, perfect, need, need, easi, hang, scale...</td>\n",
       "      <td>[scale, perfect, needed, needed, easy, hanging...</td>\n",
       "      <td>[scale, perfect, needed, needed, easy, hanging...</td>\n",
       "      <td>[hseri, portabl, hang, scale, vertic, weigh, s...</td>\n",
       "      <td>[hseries, portable, hanging, scale, vertical, ...</td>\n",
       "      <td>[hseries, portable, hanging, scale, vertical, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A32DEYY4A7EJEW</td>\n",
       "      <td>Sheri Adkins</td>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>B012P73O9O</td>\n",
       "      <td>s6 case galaxy s6 case iluvcell beautifully co...</td>\n",
       "      <td>iluvcell</td>\n",
       "      <td>this case is only compatible with samsung gala...</td>\n",
       "      <td>not a very good protective case but its cute</td>\n",
       "      <td>cell phones</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[good, protect, case, cute]</td>\n",
       "      <td>[good, protective, case, cute]</td>\n",
       "      <td>[good, protective, case, cute]</td>\n",
       "      <td>[case, compat, samsung, galaxi, s6, phone, n, ...</td>\n",
       "      <td>[case, compatible, samsung, galaxy, s6, phone,...</td>\n",
       "      <td>[case, compatible, samsung, galaxy, s6, phones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A25VMR199B567O</td>\n",
       "      <td>pohlcat01</td>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>B001BZ6ZSE</td>\n",
       "      <td>zebra pen 46820 zebra sarasa retractable gel i...</td>\n",
       "      <td>zebra pen</td>\n",
       "      <td>dfgghfhhffg</td>\n",
       "      <td>my wifes favorite pens she has like every color</td>\n",
       "      <td>office products</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[wife, favorit, pen, like, everi, color]</td>\n",
       "      <td>[wife, favorite, pen, like, every, color]</td>\n",
       "      <td>[wifes, favorite, pens, like, every, color]</td>\n",
       "      <td>[dfgghfhhffg]</td>\n",
       "      <td>[dfgghfhhffg]</td>\n",
       "      <td>[dfgghfhhffg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1NWGBDJ06W9BH</td>\n",
       "      <td>Debra A. Huntley</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>B014S24DAI</td>\n",
       "      <td>amazoncom gift card in a red gift box reveal</td>\n",
       "      <td>amazon</td>\n",
       "      <td>amazoncom gift cards are the perfect way to gi...</td>\n",
       "      <td>cant go wrong with a gift card</td>\n",
       "      <td>gift cards</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[cant, go, wrong, gift, card]</td>\n",
       "      <td>[cant, go, wrong, gift, card]</td>\n",
       "      <td>[cant, go, wrong, gift, card]</td>\n",
       "      <td>[amazoncom, gift, card, perfect, way, give, ex...</td>\n",
       "      <td>[amazoncom, gift, card, perfect, way, give, ex...</td>\n",
       "      <td>[amazoncom, gift, cards, perfect, way, give, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID      reviewerName  reviewTime        asin  \\\n",
       "0  A1EH1BOGG3K8FG             AndiO  2013-09-24  B0012TDR9E   \n",
       "1  A32DEYY4A7EJEW      Sheri Adkins  2015-11-08  B012P73O9O   \n",
       "2  A25VMR199B567O         pohlcat01  2015-08-18  B001BZ6ZSE   \n",
       "3  A1NWGBDJ06W9BH  Debra A. Huntley  2016-12-18  B014S24DAI   \n",
       "\n",
       "                                               title                  brand  \\\n",
       "0  american weigh scales h110 digital hanging sca...  american weigh scales   \n",
       "1  s6 case galaxy s6 case iluvcell beautifully co...               iluvcell   \n",
       "2  zebra pen 46820 zebra sarasa retractable gel i...              zebra pen   \n",
       "3       amazoncom gift card in a red gift box reveal                 amazon   \n",
       "\n",
       "                                         description  \\\n",
       "0  the hseries portable hanging scale is a vertic...   \n",
       "1  this case is only compatible with samsung gala...   \n",
       "2                                        dfgghfhhffg   \n",
       "3  amazoncom gift cards are the perfect way to gi...   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  this scale is perfect for what we needed i nee...   \n",
       "1       not a very good protective case but its cute   \n",
       "2    my wifes favorite pens she has like every color   \n",
       "3                     cant go wrong with a gift card   \n",
       "\n",
       "                   category_x  overall  normalized_rating  \\\n",
       "0  clothing shoes and jewelry      4.0               0.75   \n",
       "1                 cell phones      3.0               0.50   \n",
       "2             office products      5.0               1.00   \n",
       "3                  gift cards      5.0               1.00   \n",
       "\n",
       "                               stemmed_words_revText  \\\n",
       "0  [scale, perfect, need, need, easi, hang, scale...   \n",
       "1                        [good, protect, case, cute]   \n",
       "2           [wife, favorit, pen, like, everi, color]   \n",
       "3                      [cant, go, wrong, gift, card]   \n",
       "\n",
       "                            lemmatized_words_revText  \\\n",
       "0  [scale, perfect, needed, needed, easy, hanging...   \n",
       "1                     [good, protective, case, cute]   \n",
       "2          [wife, favorite, pen, like, every, color]   \n",
       "3                      [cant, go, wrong, gift, card]   \n",
       "\n",
       "                             filtered_tokens_revText  \\\n",
       "0  [scale, perfect, needed, needed, easy, hanging...   \n",
       "1                     [good, protective, case, cute]   \n",
       "2        [wifes, favorite, pens, like, every, color]   \n",
       "3                      [cant, go, wrong, gift, card]   \n",
       "\n",
       "                                  stemmed_words_desc  \\\n",
       "0  [hseri, portabl, hang, scale, vertic, weigh, s...   \n",
       "1  [case, compat, samsung, galaxi, s6, phone, n, ...   \n",
       "2                                      [dfgghfhhffg]   \n",
       "3  [amazoncom, gift, card, perfect, way, give, ex...   \n",
       "\n",
       "                               lemmatized_words_desc  \\\n",
       "0  [hseries, portable, hanging, scale, vertical, ...   \n",
       "1  [case, compatible, samsung, galaxy, s6, phone,...   \n",
       "2                                      [dfgghfhhffg]   \n",
       "3  [amazoncom, gift, card, perfect, way, give, ex...   \n",
       "\n",
       "                                filtered_tokens_desc  \n",
       "0  [hseries, portable, hanging, scale, vertical, ...  \n",
       "1  [case, compatible, samsung, galaxy, s6, phones...  \n",
       "2                                      [dfgghfhhffg]  \n",
       "3  [amazoncom, gift, cards, perfect, way, give, e...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "# Change to list of words for: filtered_tokens_revText\n",
    "amz_data['filtered_tokens_revText'] = amz_data['filtered_tokens_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: stemmed_words_revText\n",
    "amz_data['stemmed_words_revText'] = amz_data['stemmed_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: lemmatized_words_revText\n",
    "amz_data['lemmatized_words_revText'] = amz_data['lemmatized_words_revText'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: stemmed_words_desc\n",
    "amz_data['stemmed_words_desc'] = amz_data['stemmed_words_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: lemmatized_words_desc\n",
    "amz_data['lemmatized_words_desc'] = amz_data['lemmatized_words_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Change to list of words for: filtered_tokens_desc\n",
    "amz_data['filtered_tokens_desc'] = amz_data['filtered_tokens_desc'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# view data\n",
    "amz_data.head(4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc5_1_'></a>[Sentiment Analysis using Lexicon-based Methods](#toc0_)\n",
    "\n",
    "First we use lexicon-based methods to perform sentiment analysis. Lexicon-based methods use a lexicon, or a collection of words and phrases associated with emotions, to assign sentiment scores to a body of text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[VADER](#toc0_)\n",
    "\n",
    "We use the VADER (Valence Aware Dictionary and Sentiment Reasoner) lexicon to perform sentiment analysis on the reviewText column. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "VADER utilizes a sentiment lexicon containing words with sentiment scores. However, VADER goes beyond simply assigning positive or negative labels to words. It considers the intensity of sentiment and incorporates linguistic rules to handle negations, intensifiers, and other linguistic features. This makes VADER particularly suitable for analyzing sentiment in social media text, where linguistic nuances and context play a significant role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/pavansingh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# instance of the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through tokenized reviews and analyze the sentiment for each one\n",
    "sentiments_vader_revText = []\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):  # Check if the review is a string\n",
    "        sentiment = sia.polarity_scores(review)\n",
    "    else:\n",
    "        sentiment = sia.polarity_scores('')  # Replace NaN with an empty string\n",
    "    sentiments_vader_revText.append(sentiment)\n",
    "\n",
    "# store the sentiment scores in the dataframe\n",
    "amz_data['sentiments_vader_revText'] = sentiments_vader_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'compound': 0.8856},\n",
       "       {'neg': 0.153, 'neu': 0.508, 'pos': 0.339, 'compound': 0.492},\n",
       "       {'neg': 0.0, 'neu': 0.56, 'pos': 0.44, 'compound': 0.6705},\n",
       "       {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6656}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some results\n",
    "amz_data.sentiments_vader_revText.head(4).values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy array containing sentiment analysis results. Each element in the array represents the sentiment scores for a single review. These sentiment scores are generated by VADER (Valence Aware Dictionary and sEntiment Reasoner), which is a popular rule-based model used for sentiment analysis. The scores are typically between -1 and 1, where values closer to 1 indicate more positive sentiment, values closer to -1 indicate more negative sentiment, and values around 0 indicate neutral sentiment. The compound score represents an overall sentiment intensity, combining the individual sentiment scores. The compound score in VADER sentiment analysis typically varies between -1 and 1. A compound score of 1 indicates extremely positive sentiment, while a score of -1 indicates extremely negative sentiment. Scores close to 0 represent more neutral or balanced sentiment.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiments_vader_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1EH1BOGG3K8FG</td>\n",
       "      <td>the hseries portable hanging scale is a vertic...</td>\n",
       "      <td>this scale is perfect for what we needed i nee...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A32DEYY4A7EJEW</td>\n",
       "      <td>this case is only compatible with samsung gala...</td>\n",
       "      <td>not a very good protective case but its cute</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'neg': 0.153, 'neu': 0.508, 'pos': 0.339, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A25VMR199B567O</td>\n",
       "      <td>dfgghfhhffg</td>\n",
       "      <td>my wifes favorite pens she has like every color</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.56, 'pos': 0.44, 'compou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1NWGBDJ06W9BH</td>\n",
       "      <td>amazoncom gift cards are the perfect way to gi...</td>\n",
       "      <td>cant go wrong with a gift card</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0  A1EH1BOGG3K8FG  the hseries portable hanging scale is a vertic...   \n",
       "1  A32DEYY4A7EJEW  this case is only compatible with samsung gala...   \n",
       "2  A25VMR199B567O                                        dfgghfhhffg   \n",
       "3  A1NWGBDJ06W9BH  amazoncom gift cards are the perfect way to gi...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  this scale is perfect for what we needed i nee...      4.0   \n",
       "1       not a very good protective case but its cute      3.0   \n",
       "2    my wifes favorite pens she has like every color      5.0   \n",
       "3                     cant go wrong with a gift card      5.0   \n",
       "\n",
       "                            sentiments_vader_revText  \n",
       "0  {'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...  \n",
       "1  {'neg': 0.153, 'neu': 0.508, 'pos': 0.339, 'co...  \n",
       "2  {'neg': 0.0, 'neu': 0.56, 'pos': 0.44, 'compou...  \n",
       "3  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see dataframe\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall', 'sentiments_vader_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_2_'></a>[TextBlob](#toc0_)\n",
    "\n",
    "We also use the TextBlob library to perform sentiment analysis on the reviewText column. TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob is built on top of NLTK and Pattern and provides an easy-to-use interface to the NLTK library. We use the sentiment analysis functionality of TextBlob to calculate the polarity and subjectivity scores for each review in the reviewText column. \n",
    "\n",
    "TextBlob's sentiment analysis algorithm is based on a pre-trained model that has been trained on a large dataset. The model uses a combination of linguistic rules, pattern matching, and machine learning techniques like Naive Bayes classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiments_textblob_revText = []\n",
    "subjectivities_textblob_revText = []\n",
    "\n",
    "for review in amz_data['reviewText']:\n",
    "    if isinstance(review, str):\n",
    "        blob = TextBlob(review)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "    else:\n",
    "        blob = TextBlob('')\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "    sentiments_textblob_revText.append(sentiment)\n",
    "    subjectivities_textblob_revText.append(subjectivity)\n",
    "\n",
    "amz_data['sentiments_textblob_revText'] = sentiments_textblob_revText\n",
    "amz_data['subjectivities_textblob_revText'] = subjectivities_textblob_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28106061  0.11538462  0.5        -0.5       ]\n",
      "[0.6530303  0.73076923 1.         0.9       ]\n"
     ]
    }
   ],
   "source": [
    "# see some results - sentiment\n",
    "print(amz_data.sentiments_textblob_revText.head(4).values)\n",
    "\n",
    "# see some results - subjectivity\n",
    "print(amz_data.subjectivities_textblob_revText.head(4).values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob's sentiment analysis is based on a machine learning algorithm trained on a large dataset of labeled data. The algorithm learns patterns and linguistic features from the data to classify text into different sentiment categories, such as positive, negative, or neutral.\n",
    "\n",
    "**Polarity**: It indicates the sentiment of the text on a scale from -1 to 1. A polarity score close to -1 indicates negative sentiment, a score close to 1 indicates positive sentiment, and a score around 0 indicates neutral sentiment.\n",
    "\n",
    "**Subjectivity**: It measures the subjectivity of the text on a scale from 0 to 1. A subjectivity score of 0 means the text is objective and factual, while a score of 1 means the text is highly subjective and opinionated.\n",
    "\n",
    "**TextBlob uses a trained model to analyze the sentiment of the input text based on the learned patterns and features. It takes into account not only individual words but also the context and grammar of the text.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc5_1_3_'></a>[Bing, AFINN, and NRC](#toc0_)\n",
    "\n",
    "The BING lexicon, for example, classifies words as either positive or negative. bing assigns a numerical sentiment score to words, where a positive score indicates positive sentiment and a negative score indicates negative sentiment. NRC extends this approach by providing a more comprehensive list of words and associating them with multiple sentiment dimensions, such as anger, joy, fear, etc.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of AFINN: (2477, 2)\n",
      "Unique Sentiments: [-2 -3  2  1 -1  3  4 -4 -5  5  0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  value\n",
       "0    abandon     -2\n",
       "1  abandoned     -2\n",
       "2   abandons     -2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read lexicons in\n",
    "afinn = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/Afinn.csv')\n",
    "\n",
    "# AFINN\n",
    "print(\"Shape of AFINN:\", afinn.shape)\n",
    "print(\"Unique Sentiments:\", afinn.value.unique())\n",
    "display(afinn.head(3))\n",
    "afinn_dict = dict(zip(afinn['word'], afinn['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each description using AFINN\n",
    "sentiment_scores_afinn = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    sentiment_score = sum(afinn_dict.get(word, 0) for word in review_tokens)\n",
    "    sentiment_scores_afinn.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_afinn_desc'] = sentiment_scores_afinn\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using AFINN\n",
    "sentiment_scores_afinn = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(afinn_dict.get(word, 0) for word in review_tokens)\n",
    "    sentiment_scores_afinn.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_afinn_revText'] = sentiment_scores_afinn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_afinn_desc</th>\n",
       "      <th>sentiment_score_afinn_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_afinn_desc  sentiment_score_afinn_revText  \n",
       "0                          -1                              3  \n",
       "1                           4                              6  \n",
       "2                           2                              4  \n",
       "3                           1                             24  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_afinn_desc', 'sentiment_score_afinn_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bing: (6786, 2)\n",
      "Unique Sentiments: ['negative' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faces</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abolish</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word sentiment\n",
       "0     faces  negative\n",
       "1  abnormal  negative\n",
       "2   abolish  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in \n",
    "bing = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/Bing.csv')\n",
    "\n",
    "# BING\n",
    "print(\"Shape of Bing:\", bing.shape)\n",
    "print(\"Unique Sentiments:\", bing.sentiment.unique())\n",
    "display(bing.head(3))\n",
    "bing_dict = dict(zip(bing['word'], bing['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment score for each description using bing\n",
    "sentiment_scores_bing_desc = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    sentiment_score = sum(-1 if bing_dict.get(word, '') == 'negative' else 1 if bing_dict.get(word, '') == 'positive' else 0 for word in review_tokens)\n",
    "    sentiment_scores_bing_desc.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_bing_desc'] = sentiment_scores_bing_desc\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using bing\n",
    "sentiment_scores_bing_revText = []\n",
    "\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    sentiment_score = sum(-1 if bing_dict.get(word, '') == 'negative' else 1 if bing_dict.get(word, '') == 'positive' else 0 for word in review_tokens)\n",
    "    sentiment_scores_bing_revText.append(sentiment_score)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_bing_revText'] = sentiment_scores_bing_revText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \n",
       "0                          0                             2  \n",
       "1                          5                             2  \n",
       "2                          2                             3  \n",
       "3                          3                             5  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_bing_desc', 'sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of NRC: (13901, 2)\n",
      "Unique Sentiments: ['trust' 'fear' 'negative' 'sadness' 'anger' 'surprise' 'positive'\n",
      " 'disgust' 'joy' 'anticipation']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abacus</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word sentiment\n",
       "0   abacus     trust\n",
       "1  abandon      fear\n",
       "2  abandon  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in \n",
    "nrc = pd.read_csv('/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Data/NRC.csv')\n",
    "\n",
    "# NRC\n",
    "print(\"Shape of NRC:\", nrc.shape)\n",
    "print(\"Unique Sentiments:\", nrc.sentiment.unique())\n",
    "display(nrc.head(3))\n",
    "nrc_dict = dict(zip(nrc['word'], nrc['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trust': 5, 'fear': 0, 'negative': 0, 'sadness': 1, 'anger': 0, 'surprise': 1, 'positive': 9, 'disgust': 0, 'joy': 0, 'anticipation': 0}\n",
      "Overall Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# find counts of each sentiment in the review (TESTING for ONE REVIEW)\n",
    "review = amz_data['filtered_tokens_desc'][1]\n",
    "review_sentiment_scores = sentiment_scores_nrc.copy()\n",
    "for word in review:\n",
    "    word_sentiments = nrc_dict.get(word, [])\n",
    "    for sentiment in unique_sentiments:\n",
    "        if sentiment in word_sentiments:\n",
    "            review_sentiment_scores[sentiment] += 1\n",
    "print(review_sentiment_scores)\n",
    "\n",
    "# get the overall sentiment\n",
    "overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "print(\"Overall Sentiment:\", overall_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sentiments = ['trust', 'fear', 'negative', 'sadness', 'anger', 'surprise', 'positive', 'disgust', 'joy', 'anticipation']\n",
    "\n",
    "# Get the sentiment score for each description using NRC\n",
    "sentiment_scores_nrc_desc = []\n",
    "\n",
    "# Calculate sentiment score and overall sentiment for each review using NRC lexicon\n",
    "for review_tokens in amz_data['filtered_tokens_desc']:\n",
    "    review_sentiment_scores = {sentiment: 0 for sentiment in unique_sentiments}\n",
    "    for word in review_tokens:\n",
    "        word_sentiments = nrc_dict.get(word, [])\n",
    "        for sentiment in unique_sentiments:\n",
    "            if sentiment in word_sentiments:\n",
    "                review_sentiment_scores[sentiment] += 1\n",
    "\n",
    "    overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "    sentiment_scores_nrc_desc.append(overall_sentiment)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_nrc_desc'] = sentiment_scores_nrc_desc\n",
    "\n",
    "\n",
    "# Get the sentiment score for each review using NRC\n",
    "sentiment_scores_nrc_revText = []\n",
    "\n",
    "# Calculate sentiment score and overall sentiment for each review using NRC lexicon\n",
    "for review_tokens in amz_data['filtered_tokens_revText']:\n",
    "    review_sentiment_scores = {sentiment: 0 for sentiment in unique_sentiments}\n",
    "    for word in review_tokens:\n",
    "        word_sentiments = nrc_dict.get(word, [])\n",
    "        for sentiment in unique_sentiments:\n",
    "            if sentiment in word_sentiments:\n",
    "                review_sentiment_scores[sentiment] += 1\n",
    "\n",
    "    overall_sentiment = max(review_sentiment_scores, key=review_sentiment_scores.get)\n",
    "    sentiment_scores_nrc_revText.append(overall_sentiment)\n",
    "\n",
    "# Add the sentiment scores to the dataframe\n",
    "amz_data['sentiment_score_nrc_revText'] = sentiment_scores_nrc_revText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3WJELEV137U</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3OJM6TXMK3J53</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14YR7QK3ASFFW</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VE933MFXTG18</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID                                        description  \\\n",
       "0    A3WJELEV137U  steve green hide em in your heart 13 bible mem...   \n",
       "1  A3OJM6TXMK3J53  this is a concept album all the way with tales...   \n",
       "2  A14YR7QK3ASFFW  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3  A1VE933MFXTG18  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \n",
       "0                          0                             2  \n",
       "1                          5                             2  \n",
       "2                          2                             3  \n",
       "3                          3                             5  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_data[['reviewerID','description', 'reviewText', 'overall','sentiment_score_bing_desc', 'sentiment_score_bing_revText']].head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Data Frame with BING, AFINN and NRC Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>description</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment_score_afinn_desc</th>\n",
       "      <th>sentiment_score_afinn_revText</th>\n",
       "      <th>sentiment_score_bing_desc</th>\n",
       "      <th>sentiment_score_bing_revText</th>\n",
       "      <th>sentiment_score_nrc_desc</th>\n",
       "      <th>sentiment_score_nrc_revText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Bennett</td>\n",
       "      <td>steve green hide em in your heart 13 bible mem...</td>\n",
       "      <td>product worked as advertised and am pleased wi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>trust</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samson</td>\n",
       "      <td>this is a concept album all the way with tales...</td>\n",
       "      <td>nice to hear this cd beautiful</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>1 jesus lord of the way i feel 2 jehoshaphat 3...</td>\n",
       "      <td>that one song has to be one of the best in ccm...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>trust</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sj</td>\n",
       "      <td>this is the vhs movie santa claus is comin to ...</td>\n",
       "      <td>i just love these older movies they really are...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>trust</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewerName                                        description  \\\n",
       "0     John Bennett  steve green hide em in your heart 13 bible mem...   \n",
       "1           samson  this is a concept album all the way with tales...   \n",
       "2  Amazon Customer  1 jesus lord of the way i feel 2 jehoshaphat 3...   \n",
       "3               sj  this is the vhs movie santa claus is comin to ...   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  product worked as advertised and am pleased wi...      5.0   \n",
       "1                     nice to hear this cd beautiful      5.0   \n",
       "2  that one song has to be one of the best in ccm...      5.0   \n",
       "3  i just love these older movies they really are...      5.0   \n",
       "\n",
       "   sentiment_score_afinn_desc  sentiment_score_afinn_revText  \\\n",
       "0                          -1                              3   \n",
       "1                           4                              6   \n",
       "2                           2                              4   \n",
       "3                           1                             24   \n",
       "\n",
       "   sentiment_score_bing_desc  sentiment_score_bing_revText  \\\n",
       "0                          0                             2   \n",
       "1                          5                             2   \n",
       "2                          2                             3   \n",
       "3                          3                             5   \n",
       "\n",
       "  sentiment_score_nrc_desc sentiment_score_nrc_revText  \n",
       "0                    trust                    positive  \n",
       "1                 positive                    positive  \n",
       "2                    trust                     sadness  \n",
       "3                    trust                    positive  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data \n",
    "amz_data[['reviewerName', 'description', 'reviewText','overall', 'sentiment_score_afinn_desc', 'sentiment_score_afinn_revText',\n",
    "       'sentiment_score_bing_desc', 'sentiment_score_bing_revText', 'sentiment_score_nrc_desc', 'sentiment_score_nrc_revText']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "amz_data.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti.csv\", index=False)\n",
    "\n",
    "# create a smaller dataframe by randomly sampling 10% of the data\n",
    "amz_rev_sample = amz_data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# save data as csv\n",
    "amz_rev_sample.to_csv(\"/Users/pavansingh/Library/CloudStorage/GoogleDrive-pavansingho23@gmail.com/My Drive/Portfolio/Masters-Dissertation/Code/Data/amz_with_senti_sample.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_4_'></a>[Comparison of Lexicon-based Methods](#toc0_)\n",
    "\n",
    "VADER, BING, AFINN and NRC are some of the most popular lexicons used for sentiment analysis. These lexicons provide a set of words or terms along with their polarity (positive or negative) scores, which are used to estimate the sentiment of a given text.\n",
    "\n",
    "However, VADER incorporates more advanced techniques and rules to handle sentiment analysis in social media text effectively.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
